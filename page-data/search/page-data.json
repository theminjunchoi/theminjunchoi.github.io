{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"\"장애가 발생했습니다. 서버 재시작할까요?\"\n서비스 초기, 개발자라면 누구나 한 번쯤 장애 알림을 보고 무의식적으로 재시작을 한 경험이 있을거다. 하지만 단일 인스턴스에서 강제 재시작은 곧 100% 다운타임을 의미하고, 이걸 어떻게 해결할까 고민했던 과정을 기록해본다. custom_health_check 글에서 커스텀 HealthIndicator와 3단계…","fields":{"slug":"/disability_simulation/"},"frontmatter":{"date":"2026년 02월 21일 03:02","title":"\"재시작하면 고쳐져요\"라는 말을 없애기까지: 3단계 서버 자가 치유기","tags":["ZZOL"]},"rawMarkdownBody":"\"장애가 발생했습니다. 서버 재시작할까요?\"\n서비스 초기, 개발자라면 누구나 한 번쯤 장애 알림을 보고 무의식적으로 재시작을 한 경험이 있을거다. 하지만 단일 인스턴스에서 강제 재시작은 곧 100% 다운타임을 의미하고, 이걸 어떻게 해결할까 고민했던 과정을 기록해본다.\n\n[[custom_health_check]] 글에서 커스텀 HealthIndicator와 3단계 자가복구 계층을 설계했다. 이 글에서는 dev 환경에서 5가지 장애 시나리오를 재현하여 복구 계층이 의도대로 동작하는지 검증한 과정을 남긴다.\n\n## 검증하려는 것\n\n이전 글에서 설계한 복구 계층은 이렇다.\n\n```\n[Failure]\n    |\n    v\nLevel 0: Lettuce auto-reconnect (ms~sec outage)\n    |\n    v  (if Container stopped)\nLevel 1: Recovery container.start() (max 2 attempts)\n    |\n    v  (if Recovery failed)\nLevel 2: Docker restart (last resort)\n```\n\n3개의 레벨이 각자 역할에서만 개입하고, 상위 레벨로 불필요하게 넘어가지 않는 것이 설계 의도다. 단위 테스트로는 Recovery가 `container.start()`를 호출하면 성공을 반환한다는 것까지 검증할 수 있다. 하지만 Lettuce 재연결 → Stream Container 상태 변화 → Recovery 감지 → HealthIndicator 전환 → Docker HEALTHCHECK 반응이라는 **전체 체인**은 실제 인프라에서 돌려봐야 알 수 있다.\n\n시뮬레이션에서 확인하고 싶었던 질문은 세 가지다.\n\n1. Level 0(Lettuce)과 Level 1(Recovery)의 **경계**는 어디인가. Redis가 몇 초간 끊어져야 Stream Container가 멈추는가.\n2. Recovery가 `container.start()`를 호출했을 때, Redis가 아직 안 올라온 상태면 **어떤 일이 벌어지는가.**\n3. Graceful Shutdown 시 OUT_OF_SERVICE가 Docker HEALTHCHECK에서 **실제로 재시작을 방지하는가.**\n\n시나리오 5개는 이 세 가지 질문에 답하기 위해 설계했다.\n\n## 시뮬레이션 방법의 선택\n\n장애를 재현하는 방법에는 세 가지가 있다.\n\n`docker stop`은 Redis에 SIGTERM을 보내서 깨끗하게 종료시킨다. TCP RST 패킷이 전달되므로 Lettuce가 즉시 연결 끊김을 인지한다. `iptables DROP`은 Redis 포트의 패킷을 무조건 버린다. 커넥션은 살아있는데 응답이 안 오는 상황(Network Blackhole)을 만든다. `tc`(Traffic Control)는 지연, 패킷 유실률 등을 세밀하게 조절할 수 있다.\n\n운영에서 가장 무서운 장애는 네트워크 파티션이다. 프로세스가 죽는 건 빠르게 감지되지만, 패킷이 유실되어 응답만 안 오는 상황은 Lettuce command timeout(60초)까지 스레드가 블로킹된다. 하지만 이번 시뮬레이션의 목적은 **Recovery → HealthIndicator → Docker HEALTHCHECK 체인의 동작 검증**이다. `docker stop`은 \"Redis가 죽었다 → Container가 멈췄다 → Recovery가 감지한다\"라는 인과 체인을 깔끔하게 재현할 수 있다. 네트워크 파티션은 Lettuce timeout과 스레드 풀 고갈까지 범위가 확장되므로 별개의 주제로 분리했다.\n\n## 시나리오 설계: 왜 이 5개인가\n\n5개 시나리오는 복구 계층의 각 경계 조건을 하나씩 찌르도록 설계했다.\n\n|시나리오|검증 대상|\n|---|---|\n|1. Redis 3초 중단|Level 0 → Level 1 경계. 짧은 중단에서 Recovery가 개입하지 않는가?|\n|2. Redis 30초 중단 후 복구|Level 1 정상 동작. Recovery가 Container를 재시작하는가?|\n|3. Redis 2분+ 장기 중단|Level 1 → Level 2 전환. Recovery 실패 후 Docker 재시작이 트리거되는가?|\n|4. Graceful Shutdown|OUT_OF_SERVICE가 Docker 재시작을 방지하는가?|\n|5. Redis 40초 중단 후 복구|Recovery 연속 실패 카운트 초기화. 1차 실패 후 2차 성공 시 DOWN에 도달하지 않는가?|\n\n시나리오 1과 2는 Level 0과 Level 1의 경계를 확인한다. 시나리오 2와 3은 Level 1과 Level 2의 경계를 확인한다. 시나리오 5는 시나리오 3의 변형으로, \"Recovery 실패가 항상 Docker 재시작으로 이어지는 건 아니다\"라는 것을 보여준다.\n\n## 시나리오 1: Redis 3초 중단 — Level 0과 Level 1의 경계\n\nRedis를 3초간 중단했다가 재시작했다.\n\n```bash\ndocker stop dev-redis && sleep 3 && docker start dev-redis\n```\n\n|시각|이벤트|\n|---|---|\n|T+0s|`docker stop dev-redis`|\n|T+3s|`docker start dev-redis`|\n|T+5s|Lettuce `Reconnected to dev-redis`|\n|T+30s|Recovery 주기 도달. `container.isRunning()` = true. 개입 없음|\n\nRecovery가 개입하지 않았다. `docker stop`으로 Redis 프로세스가 종료되면 TCP RST 패킷이 전달되고, Lettuce는 command timeout(60초)을 기다리지 않고 즉각 재연결을 시도한다. Redis가 3초 만에 다시 띄워졌고 Lettuce가 재연결을 완료했으므로, Stream Container는 일시적 에러를 겪었을 뿐 STOPPED 상태로 빠지지 않았다. 30초 주기로 도는 Recovery 스케줄러가 감지했을 때는 이미 정상이었다.\n\n이 결과로 Level 0과 Level 1의 경계가 드러났다. Redis가 수 초간 중단되는 수준에서는 Lettuce 자체 재연결로 충분하다. Stream Container가 실제로 STOPPED에 빠지려면, Lettuce의 재연결 시도를 넘어서는 시간 동안 Redis가 죽어있어야 한다.\n\n## 시나리오 2: Redis 30초 중단 → Recovery 자가복구 성공\n\nRedis를 30초간 중단한 뒤 재시작.\n\n```bash\ndocker stop dev-redis\n# ... 30초 대기 ...\ndocker start dev-redis\n# ... 30초 대기 (Recovery 다음 주기) ...\n```\n\n|시각|이벤트|\n|---|---|\n|T+0s|`docker stop dev-redis`|\n|T+1s|Lettuce `Reconnecting` 반복|\n|T+~10s|Stream Container의 `xRead` 에러 반복 → Container STOPPED|\n|T+30s|`docker start dev-redis`|\n|T+32s|Lettuce `Reconnected`|\n|T+60s|Recovery: Stream Container STOPPED 감지 → `container.start()` 성공|\n|T+60s|`recoveryFailureCounts` 초기화. HealthIndicator UP 유지|\n\n시나리오 1과 결정적으로 다른 지점이 T+32s와 T+60s 사이에 있다. T+32s에 Lettuce가 재연결됐지만, **Stream Container는 여전히 STOPPED다.** Lettuce는 Redis 커넥션을 복구할 뿐, `StreamMessageListenerContainer`의 생명주기까지 관리하지 않는다. Container가 STOPPED 상태로 빠진 뒤에는 누군가가 명시적으로 `container.start()`를 호출해야 한다.\n\n이것이 Recovery(Level 1)가 존재하는 핵심 이유다. Lettuce(Level 0)가 해결하는 것은 커넥션 복구다. Stream Container의 이벤트 소비 재개는 별개의 문제이고, 이 격차를 Recovery가 메운다.\n\nRecovery가 `container.start()`를 성공한 뒤 `recoveryFailureCounts`를 초기화한다. 이 초기화가 없으면 이전 장애의 failure count가 남아서, 다음 장애 시 Recovery가 1회만 시도하고 포기할 수 있다. Recovery는 \"지금 이 순간\"의 연속 실패만 판단한다. 과거 장애 이력은 개입하지 않는다.\n\n## 시나리오 3: Redis 장기 중단 → Recovery 실패 → Docker 재시작\n\nRedis를 2분 이상 중단한 채로 유지.\n\n```bash\ndocker stop dev-redis\n# ... 2분+ 대기 ...\n```\n\n|시각|이벤트|\n|---|---|\n|T+0s|`docker stop dev-redis`|\n|T+60s|Recovery 1차: `container.start()` → 실패 (1/2)|\n|T+90s|Recovery 2차: `container.start()` → 실패 (2/2)|\n|T+90s|`failedRecoveryStreams` 등록 → HealthIndicator DOWN|\n|T+120~180s|Docker HEALTHCHECK 3회 연속 unhealthy → 컨테이너 재시작|\n\nreadiness 응답이 바뀌었다.\n\n```json\n{\n  \"status\": \"DOWN\",\n  \"components\": {\n    \"redisStream\": {\n      \"status\": \"DOWN\",\n      \"details\": {\n        \"unrecoverable\": [\"minigame\", \"racinggame\", \"room\", \"room:join\", \"cardgame:select\"],\n        \"action\": \"Internal recovery failed. Docker restart required.\"\n      }\n    }\n  }\n}\n```\n\nRecovery 1차에서 `container.start()`를 호출하지만, Redis가 죽어있으니 Container가 시작 직후 다시 멈춘다. 2차도 동일. 2회 연속 실패로 HealthIndicator가 DOWN을 반환하고, Docker HEALTHCHECK가 3회 연속 unhealthy를 감지한 뒤 컨테이너를 재시작한다.\n\n이 시나리오는 Level 2(Docker 재시작)가 **last resort로서 동작하는 것**을 확인하기 위한 것이다. 하지만 동시에 하나의 의문이 생긴다. Redis가 완전히 죽어있으면 Recovery의 2회 시도가 결국 헛수고다. 이 60초가 낭비 아닌가?\n\n이 질문의 답은 시나리오 5에서 나온다. 운영에서 Redis가 \"완전히 죽어서 안 돌아오는\" 상황보다 \"잠깐 죽었다가 수십 초 후에 돌아오는\" 상황이 훨씬 흔하다. Recovery의 2회 시도가 확보하는 60초는 \"Redis가 곧 살아날 가능성\"에 베팅하는 것이다.\n\n## 시나리오 4: Graceful Shutdown — OUT_OF_SERVICE 확인\n\nSIGTERM을 전송하여 Graceful Shutdown 시작.\n\n```bash\ndocker kill --signal=SIGTERM dev-app-blue\n```\n\n|시각|이벤트|\n|---|---|\n|T+0s|SIGTERM 수신. readiness: UP → OUT_OF_SERVICE|\n|T+1s|WebSocket 세션 드레이닝 시작|\n|T+~30s|활성 세션 없음 → 종료 완료|\n\nDOWN이 아니라 OUT_OF_SERVICE다. 이 구분이 실제로 의미 있는지 확인하려면, \"DOWN이었다면 어떻게 됐을까\"를 생각해봐야 한다.\n\nGraceful Shutdown이 DOWN을 반환했다면, Docker HEALTHCHECK는 \"장애 발생\"으로 판단하고 재시작을 시도한다. 그런데 서버는 SIGTERM에 의한 종료를 진행 중이다. **재시작과 종료가 경합한다.** 세션 드레이닝이 중단되고 게임 중인 플레이어의 WebSocket 연결이 강제로 끊긴다.\n\nOUT_OF_SERVICE는 Spring Boot에서 HTTP 503을 반환한다. 여기서 한 가지 더 판단이 필요하다. Docker HEALTHCHECK가 `wget --spider`를 사용하면 503에서 exit 1을 반환하므로 unhealthy로 처리될 수 있다. 그래서 HEALTHCHECK 스크립트를 `wget -qO-`로 바꾸고, HTTP 상태 코드가 아니라 응답 본문의 `status` 필드를 파싱해서 `DOWN`일 때만 unhealthy로 판정하도록 구성했다. OUT_OF_SERVICE는 \"트래픽을 보내지 마라\"이지 \"서버를 죽여라\"가 아니기 때문이다.\n\n## 시나리오 5: Recovery 1차 실패 → Redis 복구 → 2차 성공\n\n시나리오 3에서 제기된 \"Recovery 2회 시도가 낭비 아닌가?\"에 답하는 시나리오.\n\n```bash\ndocker stop dev-redis\n# ... 40초 대기 (Recovery 1차 실패 유도) ...\ndocker start dev-redis\n# ... 30초 대기 (Recovery 2차 주기) ...\n```\n\n|시각|이벤트|\n|---|---|\n|T+0s|`docker stop dev-redis`|\n|T+60s|Recovery 1차: 실패 (1/2)|\n|T+70s|`docker start dev-redis`|\n|T+90s|Recovery 2차: `container.start()` → 성공. failureCount 초기화|\n\nRecovery 1차(T+60s)에는 Redis가 없어서 실패한다. 하지만 T+70s에 Redis가 돌아왔고, 2차(T+90s)에는 성공한다. `recoveryFailureCounts`가 0으로 초기화되면서 HealthIndicator는 DOWN에 도달하지 않는다.\n\n만약 `MAX_RECOVERY_ATTEMPTS`가 1이었다면, 이 상황에서 Docker 재시작이 트리거됐을 것이다. Redis가 10초 뒤에 살아날 건데, 서버 전체를 재시작하는 것이다. 단일 인스턴스에서 이건 100% 다운타임이다.\n\n`MAX_RECOVERY_ATTEMPTS` 값의 선택지는 셋이었다.\n\n```\nMAX_RECOVERY_ATTEMPTS=1: Too aggressive. No room for Redis restart delay.\nMAX_RECOVERY_ATTEMPTS=2: ~60s buffer. Docker restart within ~2.5 min.\nMAX_RECOVERY_ATTEMPTS=3: ~90s buffer. But 3+ min total downtime if unrecoverable.\n```\n\n1은 Recovery가 존재하는 의미를 없앤다. 3은 복구 불가능한 상황에서 3분 이상 장애가 지속된다. 2는 60초의 복구 대기 시간을 확보하면서, 진짜 안 되면 약 2분 30초 이내에 Docker 재시작으로 넘어간다. 2로 결정했다.\n\n## 종합\n\n|시나리오|Recovery|HealthIndicator|Docker 재시작|\n|---|---|---|---|\n|Redis 3초 중단|미개입 (Lettuce)|UP|없음|\n|Redis 30초 중단 후 복구|1차 성공|UP|없음|\n|Redis 2분+ 장기 중단|2차 연속 실패|DOWN|발생|\n|Graceful Shutdown|미개입|OUT_OF_SERVICE|없음|\n|Redis 40초 중단 후 복구|1차 실패, 2차 성공|UP|없음|\n\n5개 시나리오 중 Docker 재시작(Level 2)이 발생한 건 1개뿐이다. 나머지 4개는 Level 0 또는 Level 1에서 흡수됐다.\n\n처음에 던졌던 세 가지 질문에 대한 답:\n\nLevel 0과 Level 1의 경계는 \"Redis 중단이 수 초 vs 수십 초\"에서 갈린다. 수 초 중단은 Lettuce가 흡수하고, 수십 초 이상 중단돼서 Stream Container가 STOPPED에 빠지면 Recovery가 개입한다(시나리오 1, 2).\n\nRedis가 안 올라온 상태에서 `container.start()`를 호출하면, Container가 시작 직후 다시 멈추고 failure count가 증가한다. 하지만 다음 시도 전에 Redis가 돌아오면 성공하고 count가 초기화된다(시나리오 3, 5).\n\nOUT_OF_SERVICE는 HEALTHCHECK 스크립트에서 DOWN과 구분 처리함으로써 Docker 재시작을 방지한다(시나리오 4).\n\n## 정리\n\n시뮬레이션의 목적은 \"복구 계층이 설계대로 동작하는지 확인\"이었다. `docker stop`이라는 단순한 방법이었지만, 각 레벨의 경계 조건과 전환 동작을 확인하기에 충분했다.\n\n`docker stop`으로 검증하지 못한 영역은 남아있다. 네트워크 파티션 상황에서 Lettuce가 command timeout(60초)까지 블로킹되는 동안 WebSocket 스레드 풀이 고갈되는지, 그 상태에서 Recovery의 `@Scheduled` 태스크가 별도 스케줄러 스레드에서 제때 실행되는지는 `iptables` 기반의 별도 시뮬레이션이 필요하다.\n\nRecovery가 개입한 사실 자체를 사람이 알 수 있는 방법이 현재는 로그뿐이라는 점도 과제다. Recovery가 성공하면 HealthIndicator는 UP을 유지하고, Docker 재시작도 발생하지 않는다. \"자동 복구는 하되, 그 사실은 통보받는다\"가 완전한 운영 사이클이다. Recovery 개입 횟수를 Micrometer Counter로 수집하고 알림을 추가하는 것이 다음 단계다."},{"excerpt":"ZZOL 서비스에 커스텀 HealthIndicator와 자가복구(Self-Recovery) 로직을 추가하고, Health Group을 분리했다. Spring Boot의 기본 헬스체크가 어디까지 커버하고, 어디서부터 커스텀이 필요한지, 장애 감지 후 Docker 재시작 전에 애플리케이션 내부에서 먼저 복구를 시도해야 하는 이유, 그리고 DOWN과 OUT_O…","fields":{"slug":"/custom_health_check/"},"frontmatter":{"date":"2026년 02월 19일 09:02","title":"HealthIndicator에는 무엇을 담아야 하는가: 상태 판별부터 자가 치유까지","tags":["ZZOL"]},"rawMarkdownBody":"ZZOL 서비스에 커스텀 HealthIndicator와 자가복구(Self-Recovery) 로직을 추가하고, Health Group을 분리했다. Spring Boot의 기본 헬스체크가 어디까지 커버하고, 어디서부터 커스텀이 필요한지, 장애 감지 후 Docker 재시작 전에 애플리케이션 내부에서 먼저 복구를 시도해야 하는 이유, 그리고 DOWN과 OUT_OF_SERVICE를 왜 구분해야 하는지에 대한 판단 과정을 기록한다.\n\n## 기본 헬스체크가 못 잡는 것\n\nSpring Boot Actuator는 `/actuator/health`를 통해 서버 상태를 제공한다. Spring Boot가 자동으로 등록하는 HealthIndicator는 DataSource(DB 연결), Redis(PING 명령), DiskSpace(디스크 여유 공간) 등이 있다. ZZOL에서는 `show-details: always`로 상세 정보를 노출하고 있었고, Docker HEALTHCHECK가 이 엔드포인트를 30초마다 호출해서 컨테이너 상태를 판단하고 있었다.\n\n문제는 이것만으로는 **ZZOL 도메인에서 의미 있는 장애를 감지할 수 없다**는 것이었다.\n\n두 가지 시나리오가 기본 헬스체크를 통과하면서도 서비스에 문제를 일으킨다.\n\n첫째, **서버가 Graceful Shutdown 중일 때.** ZZOL은 배포 시 활성 WebSocket 세션이 모두 종료될 때까지 최대 5분간 대기한다. 이 5분 동안 서버는 살아있고, DB도 연결돼 있고, Redis도 응답한다. 기본 헬스체크는 UP을 반환한다. 하지만 이 서버에 새로운 트래픽을 보내면 안 된다. 기존 연결을 드레이닝하는 중이기 때문이다. 로드밸런서가 이 상태를 감지하지 못하면 종료 중인 서버에 새 플레이어가 접속하게 된다.\n\n둘째, **Redis Stream의 ListenerContainer가 멈췄을 때.** ZZOL은 방 생성, 방 참여, 미니게임, 레이싱 게임 등 5개 Redis Stream을 통해 이벤트를 비동기로 처리한다. `StreamMessageListenerContainer`가 예외로 인해 멈추면 이벤트 소비가 중단된다. 하지만 Redis 자체는 살아있으므로 기본 Redis HealthIndicator(PING)는 UP을 반환한다. DB도 정상이다. 그러나 이벤트 소비가 멈춘 서버는 실질적으로 절반의 기능이 죽은 상태다.\n\n## 첫 번째 판단: 뭘 HealthIndicator에 넣을 것인가\n\n처음에는 \"서비스에 문제가 될 수 있는 모든 것\"을 HealthIndicator에 넣으려고 했다. WebSocket 세션 수가 갑자기 0으로 떨어지면 DOWN, DB 커넥션 풀 사용률이 90%를 넘으면 DOWN, 이런 식이었다.\n\n하지만 한 가지 중요한 제약을 간과하고 있었다. **Docker HEALTHCHECK에서 DOWN이 반환되면 컨테이너가 재시작된다.** HealthIndicator는 \"이 상태가 비정상인가\"를 판단하는 게 아니라, **\"이 서버를 재시작하면 문제가 해결되는가\"**를 판단해야 한다.\n\nWebSocket 세션 수가 0인 건 서버를 재시작한다고 해결되는 문제가 아니다. 클라이언트가 접속하지 않은 것뿐이다. DB 커넥션 풀 사용률이 높은 것도 재시작으로 순간적으로 해소되지만, 근본 원인(슬로우 쿼리 등)이 해결되지 않으면 재시작 후 다시 올라간다. 이런 것들은 HealthIndicator가 아니라 **알림(Alerting)**으로 가야 한다.\n\n이 기준을 적용하면 HealthIndicator에 넣어야 하는 항목이 명확해진다.\n\n|상태|재시작으로 복구 가능?|HealthIndicator에 넣는가?|\n|---|---|---|\n|Redis Stream Container 중단|ㅇㅇ. 재시작 시 container 재생성|넣음|\n|Graceful Shutdown 진행 중|재시작이 아니라 트래픽 차단이 필요|넣음 (단, DOWN이 아닌 OUT_OF_SERVICE)|\n|WebSocket 세션 수 급감|재시작으로 해결 안 됨|안 넣음. 알림으로 처리|\n|DB 커넥션 풀 고갈|일시적 해소만 가능|안 넣음. 알림으로 처리|\n\n## 두 번째 판단: DOWN과 OUT_OF_SERVICE는 왜 다른가\n\nRedis Stream Container가 멈추면 DOWN을 반환한다. Graceful Shutdown 중에는 OUT_OF_SERVICE를 반환한다. 둘 다 \"이 서버에 트래픽을 보내면 안 된다\"는 건 같은데, 왜 구분해야 하는가.\n\n**DOWN은 \"장애\"를 의미한다.** Docker HEALTHCHECK에서 DOWN을 연속으로 받으면(`retries` 횟수만큼) 컨테이너를 재시작한다. Redis Stream Container가 멈춘 건 장애이고, 재시작으로 복구 가능하므로 DOWN이 맞다.\n\n**OUT_OF_SERVICE는 \"의도적인 서비스 중단\"을 의미한다.** Graceful Shutdown은 배포를 위한 의도적인 종료 과정이다. 이 상태에서 컨테이너를 재시작하면 세션 드레이닝이 중단되고, 게임 중인 플레이어의 WebSocket 연결이 강제로 끊긴다. Graceful Shutdown을 구현한 의미가 사라진다.\n\n```\nRedis Stream Container stopped → DOWN → Docker restarts → Container recovered ✓\nGraceful Shutdown in progress → OUT_OF_SERVICE → Docker does NOT restart → Session draining continues ✓\n```\n\n처음에는 Graceful Shutdown에도 DOWN을 썼다가 이 문제를 발견했다. Graceful Shutdown이 시작되면 Docker가 \"장애\"로 판단하고 컨테이너를 재시작하려는데, 서버는 종료 중이므로 재시작과 종료가 충돌한다. OUT_OF_SERVICE로 바꾸면 Docker HEALTHCHECK는 이 상태를 unhealthy로 판단하지 않으면서, 로드밸런서는 이 인스턴스를 트래픽 분배 대상에서 제외할 수 있다.\n\n단, 이 동작은 Docker HEALTHCHECK 설정에 따라 다르다. Docker의 기본 HEALTHCHECK는 \"healthy 또는 unhealthy\"만 구분하고, HTTP 상태 코드를 직접 해석하지 않는다. `wget --spider`가 200이 아닌 503(OUT_OF_SERVICE의 기본 HTTP 상태)을 받으면 exit 1을 반환하므로, Docker 입장에서는 unhealthy로 처리될 수 있다. 이 부분은 로드밸런서(ALB 등)의 Health Check 설정에서 200만 healthy로 인식하도록 구성해야 한다.\n\n## 세 번째 판단: 재시작이 정말 첫 번째 선택지인가\n\n초기 설계에서는 Redis Stream Container가 멈추면 즉시 DOWN을 반환해서 Docker가 컨테이너를 재시작하도록 했다. 코드 리뷰에서 중요한 지적이 들어왔다.\n\n**\"단일 인스턴스 구조에서 컨테이너 재시작은 곧 100% 다운타임이다. ListenerContainer가 예외로 멈췄다면, 서버 전체를 죽이는 대신 해당 Container 빈만 다시 시작하는 Fallback 로직을 먼저 구현해야 하지 않나?\"**\n\n맞는 지적이었다. Container 하나 멈춘 건데 서버 전체를 재시작하는 건 과한 대응이다. 외부 인프라(Docker)에 의한 강제 재시작은 항상 최후의 보루(Last Resort)여야 한다.\n\n이 원칙을 적용해서 복구 흐름을 3단계로 재설계했다.\n\n```\nContainer stopped\n       |\n       v\n[1] Recovery: container.start() 시도 (30초 주기)\n       |\n    성공? ──→ 정상 복귀. HealthIndicator는 UP.\n       |\n       no\n       |\n       v\n[2] Recovery: 재시도 (최대 2회)\n       |\n    성공? ──→ 정상 복귀\n       |\n       no\n       |\n       v\n[3] HealthIndicator: DOWN 반환 → Docker 재시작 (Last Resort)\n```\n\n여기서 중요한 설계 결정이 하나 있었다. **HealthIndicator 안에서 복구 로직을 실행하면 안 된다.** HealthIndicator는 \"상태를 보고하는 역할\"이지 \"상태를 고치는 역할\"이 아니다. Docker가 30초마다 헬스체크를 호출하는데, 매번 부수효과(side effect)가 발생하면 책임이 섞인다.\n\n그래서 두 컴포넌트를 분리했다.\n\n`RedisStreamContainerRecovery`는 30초 주기의 스케줄 태스크로, 모든 container 상태를 감시하고 멈춘 container에 `start()`를 호출한다. 2회 연속 실패하면 \"복구 불가\"로 판정한다.\n\n`RedisStreamHealthIndicator`는 Recovery의 결과만 읽어서 보고한다. \"복구 불가\" 판정이 난 스트림이 있으면 DOWN을 반환한다.\n\n```java\n// Recovery: 상태 감시 + 복구 시도 (쓰기)\n@Scheduled(fixedDelay = 30_000, initialDelay = 60_000)\npublic void checkAndRecover() {\n    for (String streamKey : STREAM_KEYS) {\n        StreamMessageListenerContainer<?, ?> container = getContainer(streamKey);\n\n        if (container.isRunning()) {\n            recoveryFailureCounts.remove(streamKey);\n            failedRecoveryStreams.remove(streamKey);\n            continue;\n        }\n\n        // 멈춘 container → start() 시도\n        container.start();\n\n        if (!container.isRunning()) {\n            int failCount = recoveryFailureCounts.merge(streamKey, 1, Integer::sum);\n            if (failCount >= MAX_RECOVERY_ATTEMPTS) {\n                failedRecoveryStreams.add(streamKey);  // 복구 포기\n            }\n        }\n    }\n}\n```\n\n```java\n// HealthIndicator: Recovery 결과만 읽기 (읽기 전용)\n@Override\npublic Health health() {\n    if (containerRecovery.hasUnrecoverableStreams()) {\n        return Health.down()\n                .withDetail(\"unrecoverable\", containerRecovery.getFailedRecoveryStreams())\n                .withDetail(\"action\", \"Internal recovery failed. Docker restart required.\")\n                .build();\n    }\n    return Health.up().withDetails(details).build();\n}\n```\n\nRecovery가 복구를 시도하는 동안에는 container가 STOPPED여도 HealthIndicator는 UP을 반환한다. 아직 내부에서 복구 중이니까 Docker가 개입할 단계가 아니다. 2회 연속 실패해서 \"복구 불가\"가 확정돼야 비로소 DOWN을 반환하고, Docker 재시작이 last resort로 트리거된다.\n\n## 네 번째 판단: Health Group을 왜 분리하는가\n\nSpring Boot Actuator는 Health Group 기능을 제공한다. 하나의 `/actuator/health` 아래에 여러 그룹을 만들 수 있다.\n\n```yaml\nmanagement:\n  endpoint:\n    health:\n      group:\n        liveness:\n          include: \"ping\"\n        readiness:\n          include: \"db,redis,gracefulShutdown,redisStream\"\n```\n\n**Liveness**(`/actuator/health/liveness`)는 \"이 프로세스가 살아있는가\"만 판단한다. PING 하나면 충분하다. JVM이 죽었거나 응답 불가 상태인지만 체크한다.\n\n**Readiness**(`/actuator/health/readiness`)는 \"이 서버가 트래픽을 받을 준비가 됐는가\"를 판단한다. DB 연결, Redis 연결, Graceful Shutdown 상태, Redis Stream Container 상태를 모두 확인한다.\n\n이 분리가 중요한 이유는 **Docker HEALTHCHECK와 로드밸런서가 서로 다른 관심사를 갖기 때문**이다. Docker는 \"컨테이너를 재시작할지\"를 결정해야 하고, 로드밸런서는 \"이 인스턴스에 트래픽을 보낼지\"를 결정해야 한다. 하나의 엔드포인트로 두 가지를 모두 판단하면 의도하지 않은 동작이 발생할 수 있다.\n\nZZOL에서는 Docker HEALTHCHECK가 readiness 엔드포인트를 사용하도록 설정했다. 이유는 단순하다. 현재 단일 인스턴스 구조이기 때문에, liveness 체크만으로는 부족하고, readiness 수준의 체크가 컨테이너 재시작 판단에 더 적합하다고 판단했다. 멀티 인스턴스 + 로드밸런서 구조로 전환하면, Docker는 liveness를, 로드밸런서는 readiness를 사용하도록 분리할 수 있다.\n\n## 결과: /actuator/health/readiness 응답\n\n적용 후 readiness 엔드포인트의 응답은 다음과 같은 구조가 된다.\n\n```json\n{\n  \"status\": \"UP\",\n  \"components\": {\n    \"db\": { \"status\": \"UP\" },\n    \"redis\": { \"status\": \"UP\" },\n    \"gracefulShutdown\": { \"status\": \"UP\" },\n    \"redisStream\": {\n      \"status\": \"UP\",\n      \"details\": {\n        \"room\": \"RUNNING\",\n        \"room:join\": \"RUNNING\",\n        \"cardgame:select\": \"RUNNING\",\n        \"minigame\": \"RUNNING\",\n        \"racinggame\": \"RUNNING\"\n      }\n    }\n  }\n}\n```\n\n기본 헬스체크만 사용할 때와 비교하면, Graceful Shutdown 진행 여부와 Redis Stream 이벤트 처리 상태를 추가로 감지할 수 있게 됐다.\n\n|Before|After|\n|---|---|\n|DB 연결, Redis PING, 디스크만 체크|+ Graceful Shutdown 상태, Redis Stream Container 상태|\n|종료 중에도 UP → 새 트래픽 유입|종료 중 OUT_OF_SERVICE → 트래픽 차단|\n|Stream Container 멈추면 즉시 서버 재시작|내부 복구 2회 시도 → 실패 시에만 재시작|\n|단일 엔드포인트|liveness/readiness 그룹 분리|\n\n## 정리\n\nHealthIndicator에 뭘 넣을지의 기준은 \"재시작으로 복구 가능한가\"였다. 재시작으로 해결되는 문제는 HealthIndicator가 DOWN을 반환해서 자동 복구를 트리거하고, 재시작으로 해결 안 되는 문제는 알림으로 사람에게 알려야 한다. 그리고 의도적인 서비스 중단(Graceful Shutdown)은 DOWN도 아니고 UP도 아닌 OUT_OF_SERVICE로 표현해야, 재시작과 종료가 충돌하지 않는다.\n\n단, Docker 재시작은 최후의 보루여야 한다. 단일 인스턴스에서 컨테이너 재시작은 100% 다운타임이다. 애플리케이션 내부에서 먼저 복구를 시도하고, 그래도 안 될 때만 외부 인프라에 의한 재시작을 허용하는 구조가 올바른 단계적 복구 전략이다."},{"excerpt":"ZZOL 서비스에 Rate Limiting을 적용했다. 단순히 \"요청을 제한하자\"가 아니라, 같은 서버 보호인데 HTTP와 WebSocket에서 왜 다른 전략을 써야 하는지, 각 설정값을 왜 그렇게 잡았는지에 대한 판단 과정을 기록한다. 왜 서버 자기보호가 필요했는가 ZZOL은 실시간 멀티플레이어 게임 서비스다. 점심시간에 한 팀이 모여서 미니게임을 하고…","fields":{"slug":"/rate_limiting/"},"frontmatter":{"date":"2026년 02월 18일 12:02","title":"ZZOL의 효율적인 서버 자기보호 전략","tags":["ZZOL"]},"rawMarkdownBody":"ZZOL 서비스에 Rate Limiting을 적용했다. 단순히 \"요청을 제한하자\"가 아니라, 같은 서버 보호인데 HTTP와 WebSocket에서 왜 다른 전략을 써야 하는지, 각 설정값을 왜 그렇게 잡았는지에 대한 판단 과정을 기록한다.\n\n## 왜 서버 자기보호가 필요했는가\n\nZZOL은 실시간 멀티플레이어 게임 서비스다. 점심시간에 한 팀이 모여서 미니게임을 하고, 룰렛으로 당첨자를 뽑는다. 사용 패턴이 극단적으로 몰리는 서비스인데, 12시 50분~1시 10분 사이에 전사 동시 접속이 발생하고, 이 20분 동안 방 생성 + 입장 + 게임 시작이 한꺼번에 일어난다.\n\n지금까지 구현한 것들은 \"서버가 정상일 때 잘 돌아가게 하는 것\"이었다. 스레드풀 튜닝으로 처리량을 최적화하고, 서킷 브레이커로 외부 의존성 장애를 격리하고, Graceful Shutdown으로 배포 시 세션을 보호했다. 하지만 한 가지 시나리오에 대한 답이 없었다.\n\n**서버 자체가 감당 못할 트래픽이 들어오면 어떻게 할 것인가.**\n\n방 생성 API(`POST /rooms`) 하나를 호출하면 Redis에 방 데이터를 저장하고, DB에 insert하고, QR 코드를 비동기로 생성하고, Redis Stream에 이벤트를 발행한다. 비용이 가벼운 API가 아니다. 이 API를 초당 100번 호출하면 서버 리소스가 빠르게 고갈된다. WebSocket도 마찬가지다. 한 세션에서 초당 수백 건의 STOMP 메시지를 쏘면, inbound 채널의 스레드풀이 점유되어 정상 사용자의 메시지 처리가 밀린다.\n\n## 첫 번째 판단: 어디서 제한할 것인가\n\nRate Limiting을 구현할 때 가장 먼저 내린 결정은 제한 위치였다.\n\n처음에는 애플리케이션에서 전부 처리하려고 했다. Resilience4j에 RateLimiter 모듈이 이미 있으니까, HTTP API에도 WebSocket에도 일관되게 적용할 수 있을 것 같았다. 그런데 한 가지 문제가 있었다. 애플리케이션에서 Rate Limiting을 한다는 건, **요청이 이미 Tomcat 스레드를 점유한 상태에서 거절한다**는 뜻이다.\n\n`POST /rooms`를 예로 들면, 애플리케이션까지 도달한 요청은 이미 서블릿 스레드를 잡고 있다. Rate Limiter가 거절하더라도, Spring의 필터 체인을 타고, 요청 파싱을 하고, 429 응답을 만들어 돌려보내는 비용이 발생한다. 악의적 요청 1000건이 들어오면, 1000개의 스레드가 \"거절하기 위해\" 점유된다. 서버 보호가 목적인데, 보호하는 과정 자체가 서버에 부하를 준다.\n\nNginx에서 먼저 자르면 이 비용이 0이다. 앱 서버까지 트래픽이 아예 도달하지 않는다.\n\n그렇다면 WebSocket 메시지도 Nginx에서 처리할 수 있을까? 결론은 **불가능하다.** Nginx가 제한할 수 있는 건 WebSocket 핸드셰이크(HTTP Upgrade 요청)까지다. 핸드셰이크 이후에는 TCP 스트림이 흐를 뿐이고, 그 위에서 오가는 STOMP 프레임의 내용을 Nginx는 파싱하지 못한다. \"이 메시지가 게임 액션인지, 초당 몇 건 보내고 있는지\"는 STOMP을 이해하는 애플리케이션만 판단할 수 있다.\n\n결론은 이렇게 정리됐다.\n\n```\nClient → Nginx (HTTP Rate Limit) → Spring Boot (WebSocket Msg Rate Limit)\n           |                              |\n           +-- IP 기반                     +-- 세션 기반\n           +-- 요청 단위 제한                +-- 메시지 단위 제한\n           +-- 차단 비용: 거의 0             +-- 비즈니스 컨텍스트 필요\n```\n\n|제한 대상|Nginx|애플리케이션|\n|---|---|---|\n|HTTP API 요청 빈도|가능, 여기서 처리|불필요|\n|WebSocket 핸드셰이크 빈도|가능, 여기서 처리|불필요|\n|WebSocket 메시지 빈도|불가능|**여기서만 가능**|\n\n## Nginx Rate Limiting: 설정값을 어떻게 잡았는가\n\nNginx의 `limit_req_zone`으로 API별 Rate Limiting을 설정했다. 여기서 중요한 건 설정 문법이 아니라 **각 값을 왜 그렇게 잡았는가**다.\n\n### 방 생성 API — rate=2r/s, burst=4\n\nZZOL의 사용 패턴은 \"점심시간에 한 팀이 방 하나를 만들어서 게임 한 판 하는 것\"이다. 한 사람이 방을 초당 2개 이상 만들 이유가 없다. burst=4는 네트워크 지연으로 클라이언트가 버튼을 연타하는 경우를 허용한다.\n\n### 방 참여 API — rate=5r/s, burst=10\n\n방 생성보다 여유 있게 잡았다. 이유가 있다. 같은 회사 Wi-Fi를 사용하면 팀원 여러 명이 같은 IP로 잡힌다. burst=10은 한 방의 최대 인원(9명)이 거의 동시에 입장하는 케이스를 허용하기 위한 값이다.\n\n### WebSocket 핸드셰이크 — rate=3r/s, burst=5\n\nWebSocket 연결은 한 번 맺으면 유지된다. 초당 3회 이상 핸드셰이크를 시도하는 건 비정상이거나 SockJS fallback 재연결 폭풍이다.\n\n### 응답 코드: 503 대신 429\n\nNginx의 기본 Rate Limit 초과 응답은 503(Service Unavailable)이다. 이걸 429(Too Many Requests)로 변경했다. 503은 \"서버가 죽었다\"는 의미이고, 429는 \"네가 너무 많이 보냈다\"는 의미다. 클라이언트가 429를 받으면 자신의 요청 빈도가 문제라는 것을 알고 재시도 간격을 늘릴 수 있다. 의미적으로 정확한 응답 코드를 써야 클라이언트 쪽 에러 핸들링도 제대로 동작한다.\n\n## 두 번째 판단: WebSocket Rate Limiter 알고리즘 선택\n\n### 왜 Fixed Window인가\n\nRate Limiting 알고리즘에는 Fixed Window, Sliding Window Log, Token Bucket 등이 있다. 각각 트레이드오프가 다르다.\n\n|방식|장점|단점|\n|---|---|---|\n|Fixed Window|구현 단순, 메모리 O(1)/세션|윈도우 경계에서 2×limit 버스트 가능|\n|Sliding Window Log|버스트 완전 차단|요청 히스토리 저장, 메모리 O(N)|\n|Token Bucket|버스트 완화 + 평균 속도 보장|구현 복잡도|\n\nFixed Window를 선택했다. 알려진 한계가 있다. 윈도우 경계(예: t=0.999s와 t=1.000s 사이)에서 순간적으로 2×limit 메시지가 통과할 수 있다. 하지만 이 서비스에서 이게 실질적 위협인지를 따져봐야 한다.\n\nZZOL의 부하 테스트 실측 데이터에서 정상 사용자 1명의 최대 초당 요청은 1.3건이다. Rate Limit을 20으로 잡았을 때, 경계에서 40건이 통과하는 것과 20건이 통과하는 것의 서버 부하 차이는 무시할 수준이다. 반면 Sliding Window를 적용하면 메시지마다 타임스탬프를 저장해야 하고, 레이싱 게임 중 초당 수십 건의 메시지에 대해 매번 이 비용을 지불해야 한다. 이 서비스 규모에서 Sliding Window의 정밀도는 과잉이라고 판단했다.\n\n### 왜 Lazy Reset인가\n\n일반적인 Fixed Window 구현은 1초마다 스케줄러를 돌려서 모든 세션의 카운터를 리셋한다. 동시 접속 250명이면 250개를 매초 순회하는데, 당장은 비용이 크지 않지만 설계적으로 깔끔하지 않다. 연결이 0개일 때도 스케줄러가 돌고, 메시지를 보내지 않는 세션까지 매초 건드린다.\n\n대신 Lazy Reset 방식을 사용했다. `tryAcquire()` 호출 시점에 \"마지막 윈도우 시작 시간으로부터 1초가 지났는가?\"만 체크하고, 지났으면 그때 리셋한다. 메시지가 오지 않는 세션은 비용이 0이다. 리셋 타이밍이 메시지 도착에 의해 결정되므로 별도 스케줄러가 필요 없다.\n\n```java\nsynchronized boolean tryAcquire(int limit, long now) {\n    lastAccessTime = now;\n\n    // 윈도우 만료 시 리셋 (Lazy Reset)\n    if (now - windowStart >= 1000) {\n        count = 0;\n        windowStart = now;\n    }\n\n    return ++count <= limit;\n}\n```\n\n### 세 번째 판단: 레이스 컨디션과 synchronized\n\n처음 구현에서는 `AtomicInteger`와 `AtomicLong`을 사용했다. 각 필드의 연산은 원자적이니까 동시성 문제가 없을 거라고 생각했다. 하지만 코드 리뷰에서 문제가 발견됐다.\n\n`clientInboundChannel`은 스레드 풀 기반으로 동작한다. 동일 세션의 SEND 메시지 두 건이 서로 다른 스레드에서 동시에 `tryAcquire`를 실행할 수 있다. \"윈도우 만료 체크 → 리셋 → 카운트 증가\"가 세 단계로 분리되어 있기 때문에, `AtomicInteger`/`AtomicLong`이 각 연산을 개별로 보호하더라도 세 단계를 하나의 임계 구역으로 묶지 못한다.\n\n```\nThread A: 윈도우 만료 체크 → false (리셋 스킵)\nThread B: 윈도우 만료 체크 → true  (막 만료됨)\nThread B: count = 0, windowStart = now\nThread A: ++count → 1  ← 이전 윈도우에서 거절되어야 할 요청이 새 윈도우로 스며듦\n```\n\n이전 윈도우에서 거절되어야 할 요청이 새 윈도우의 슬롯을 소비하면서 Rate Limit을 우회하게 된다.\n\n해결 방법으로 `synchronized` + primitive 필드를 선택했다. `SessionCounter`는 세션 단위 인스턴스이므로, `synchronized`를 사용해도 락 경합 범위가 해당 세션에 한정된다. 세션 A의 메시지를 처리할 때 세션 B의 처리가 블로킹되는 일은 없다. CAS(Compare-And-Swap) 기반 lock-free 방식도 고려했지만, 세션 단위 락에서 경합이 거의 발생하지 않는 상황에서 코드 복잡도를 올릴 이유가 없었다.\n\n## 네 번째 판단: 초과 시 에러를 보낼 것인가\n\nRate Limit을 초과한 메시지를 어떻게 처리할지 두 가지 선택지가 있었다.\n\n첫째, 클라이언트에 에러 메시지를 보내는 방식. \"Rate Limit 초과\"라는 에러를 STOMP 에러 프레임으로 전송하면, 클라이언트가 상황을 인지하고 전송 빈도를 줄일 수 있다.\n\n둘째, 조용히 메시지를 드롭하는 방식. 인터셉터에서 `null`을 반환하면 메시지가 폐기되고, 클라이언트는 아무 응답도 받지 못한다.\n\n**두 번째를 선택했다.** 이유는 서버 보호라는 목적에 있다. 초당 수십~수백 건의 비정상 메시지가 오는 상황에서, 매 건마다 에러 응답을 보내면 outbound 스레드풀이 에러 응답 처리에 점유된다. Rate Limiting이 서버를 보호하기 위한 장치인데, 그 장치가 서버를 추가로 부하시키면 본말전도다.\n\n정상 사용자가 Rate Limit에 걸릴 가능성은 현실적으로 없다. 초당 1.3건이 최대인 사용 패턴에서 20건 제한에 걸리려면 스크립트를 써야 한다. 스크립트에 에러 메시지를 정중하게 보내줄 필요는 없다.\n\n## 인터셉터 체인 설계\n\nRate Limiter는 기존 메트릭 수집 인터셉터와 분리해서 별도 인터셉터로 구현했다. 메트릭 수집과 Rate Limiting은 책임이 다르고, 실행 순서에 의미가 있기 때문이다.\n\n```\nStompPrincipalInterceptor → WebSocketRateLimitInterceptor → WebSocketInboundMetricInterceptor\n```\n\nPrincipal 설정이 먼저 되어야 Rate Limiter에서 세션을 식별할 수 있고, Rate Limit에서 걸러진 메시지가 메트릭에 잡히면 안 된다. 차단된 메시지까지 메트릭에 포함되면 실제 처리량 수치가 왜곡된다. Rate Limiter가 메트릭 수집보다 앞에 있어야 하는 이유가 이것이다.\n\n## 정리\n\n서버 자기보호를 위한 Rate Limiting을 두 레이어로 나눠 구현했다.\n\n|구분|HTTP API|WebSocket 메시지|\n|---|---|---|\n|제한 위치|Nginx|Spring 인터셉터|\n|제한 기준|IP 기반|세션 기반|\n|차단 비용|거의 0 (앱 도달 전 차단)|인터셉터 실행 비용|\n|초과 시 동작|429 응답|메시지 드롭 (무응답)|\n\n같은 \"서버 보호\"라는 목적이지만, HTTP와 WebSocket의 프로토콜 특성 때문에 전략이 달라야 했다. HTTP는 요청-응답 기반이니까 앞단에서 자르는 게 효율적이고, WebSocket은 지속 연결 위의 메시지 스트림이니까 메시지 내용을 파싱할 수 있는 애플리케이션에서 처리해야 한다.\n\n설정값은 전부 도메인 사용 패턴과 부하 테스트 데이터에서 도출했다. \"점심시간에 한 팀이 방 하나 만들어서 게임 한 판 하는 것\"이 정상 사용이고, 그 범위를 벗어나면 비정상이다. Rate Limiting의 핵심은 이 경계를 데이터 기반으로 정의하는 것이었다.\n"},{"excerpt":"에서 외부 서비스 장애 대응 작업을 했다. Oracle Object Storage에 QR 코드를 업로드하는 과정에서, 외부 서비스가 불안정할 때 시스템 전체가 영향을 받는 문제가 있었다. 이 글에서는 Circuit Breaker와 Retry를 도입하면서 고민한 과정을 기록해본다. 문제 상황 ZZOL에서는 방을 생성할 때 QR 코드를 만든다. 이 QR 코드…","fields":{"slug":"/circuit_breaker/"},"frontmatter":{"date":"2026년 02월 17일 09:02","title":"외부 서비스 장애로부터 살아남기","tags":["ZZOL"]},"rawMarkdownBody":"`ZZOL`에서 외부 서비스 장애 대응 작업을 했다. Oracle Object Storage에 QR 코드를 업로드하는 과정에서, 외부 서비스가 불안정할 때 시스템 전체가 영향을 받는 문제가 있었다. 이 글에서는 Circuit Breaker와 Retry를 도입하면서 고민한 과정을 기록해본다.\n\n## 문제 상황\n\nZZOL에서는 방을 생성할 때 QR 코드를 만든다. 이 QR 코드로 다른 플레이어들이 방에 참여할 수 있다. 흐름은 이렇다.\n\n```\nCreate Room Request\n    |\n    v\nRoom created (Redis)\n    |\n    v\nQR Code image generated (ZXing)\n    |\n    v\nUpload to Oracle Object Storage    <-- external service call\n    |\n    v\nGenerate Public URL\n    |\n    v\nBroadcast QR Code URL via WebSocket\n```\n\nQR 코드 생성은 비동기(`@Async`)로 처리하고 있었다. 방 생성 자체는 바로 완료되고, QR 코드는 백그라운드에서 생성된 뒤 WebSocket으로 클라이언트에 전달되는 구조다. 그래서 Oracle Object Storage 장애가 방 생성 응답 자체를 막지는 않았다.\n\n하지만 문제가 없는 건 아니었다.\n\n### Oracle Object Storage가 불안정하면?\n\nOracle Object Storage는 외부 서비스다. 네트워크 문제, Oracle Cloud 측 장애, DNS 이슈 등 다양한 이유로 실패할 수 있다. 실제로 운영 중에 간헐적으로 업로드가 실패하는 로그가 찍히고 있었다.\n\n도입 전 코드를 보면 문제가 바로 보인다.\n\n```java\n@Override\npublic String upload(@NonNull String contents, byte[] data) {\n    try {\n        return uploadQrCodeToObjectStorage(contents, data);\n    } catch (Exception e) {\n        throw new StorageServiceException(\n            RoomErrorCode.QR_CODE_UPLOAD_FAILED,\n            RoomErrorCode.QR_CODE_UPLOAD_FAILED.getMessage(), e);\n    }\n}\n```\n\n단순히 한 번 시도하고, 실패하면 바로 예외를 던진다. 여기서 두 가지 문제가 있었다.\n\n첫째, **일시적 장애에도 바로 실패한다.** 네트워크 순단 같은 일시적 문제는 한두 번 더 시도하면 성공할 수 있다. 하지만 재시도 로직이 없으니 한 번 실패하면 그냥 끝이다. 사용자는 QR 코드 없이 방 참여 코드를 직접 입력해야 한다.\n\n둘째, **지속적 장애 시 리소스가 낭비된다.** Oracle Object Storage가 완전히 죽어 있는 상황에서도, 방이 생성될 때마다 업로드를 시도한다. 어차피 실패할 호출을 매번 보내면서 비동기 스레드를 점유하고, 타임아웃까지 대기하는 시간이 낭비된다. 동시에 방이 많이 생성되면 비동기 스레드풀이 고갈될 수도 있다.\n\n정리하면 이렇다.\n\n```\n+-------------------------------------------------------------------+\n|               Failure Type vs Behavior                            |\n+-------------------------------------------------------------------+\n|                                                                   |\n|  Failure Type         Before              After                   |\n|  -----------------------------------------------------------------|\n|                                                                   |\n|  Transient            Fail immediately    Retry and recover       |\n|  (network blip,       -> no QR code       -> QR code delivered    |\n|   timeout)                                                        |\n|                                                                   |\n|  -----------------------------------------------------------------|\n|                                                                   |\n|  Persistent           Retry every time    Fail fast               |\n|  (Oracle Cloud        -> wasted resource  -> protect resources    |\n|   outage)             -> thread pool busy -> fast response        |\n|                                                                   |\n+-------------------------------------------------------------------+\n```\n\n일시적 장애에는 재시도(Retry)로 복구하고, 지속적 장애에는 서킷 브레이커(Circuit Breaker)로 빠르게 차단하는 게 필요했다.\n\n## 왜 Circuit Breaker와 Retry인가\n\n### 다른 선택지는 없었는가\n\n사실 단순한 재시도만으로도 일시적 장애는 해결된다. for 루프로 2번 돌리면 되지 않나? 맞다. 하지만 그것만으로는 부족하다.\n\n지속적 장애 상황을 생각해보자. Oracle Object Storage가 30분 동안 완전히 죽어 있다고 가정하면, 그 30분 동안 생성되는 모든 방에 대해 2번씩 업로드를 시도한다. 방이 100개 생성되면 200번의 실패 호출이 발생한다. 각 호출마다 타임아웃(보통 수 초)까지 대기하니까, 비동기 스레드풀에 걸리는 부하가 상당하다.\n\n서킷 브레이커는 이 문제를 해결한다. 실패가 일정 비율 이상 누적되면, 아예 호출을 차단해버린다. \"어차피 실패할 거 시도도 하지 마\"라는 전략이다. 그리고 일정 시간이 지나면 조심스럽게 다시 시도해서, 서비스가 복구됐는지 확인한다.\n\n### 왜 Resilience4j인가\n\nSpring Cloud Circuit Breaker는 Resilience4j, Hystrix, Sentinel, Spring Retry 등 여러 구현체를 지원한다. 이 중에서 Resilience4j를 선택했다.\n\nHystrix는 Netflix가 개발했고 한때 사실상 표준이었지만, 2018년에 유지보수 모드로 전환됐다. 새로운 기능 추가가 없고, Spring Boot 3.x와의 호환성도 보장되지 않는다. Sentinel은 Alibaba가 만든 라이브러리로 Flow Control에 강점이 있지만, 국내에서는 사용 사례가 적고 커뮤니티가 상대적으로 작다. Spring Retry는 단순 재시도에는 좋지만, 서킷 브레이커의 세밀한 상태 관리(슬라이딩 윈도우, HALF_OPEN 등)에는 한계가 있다.\n\nResilience4j는 Java 17+ 지원, Spring Boot 3.x 공식 지원, 가볍고 모듈화된 설계 등 현재 시점에서 가장 적합했다. 서킷 브레이커, 리트라이, 레이트 리미터, 벌크헤드 등을 독립적인 모듈로 제공해서, 필요한 것만 골라 쓸 수 있다. 이번에는 서킷 브레이커와 리트라이 두 가지만 사용했다.\n\n## Retry 설계\n\n### 설정값 결정\n\n```yaml\nresilience4j:\n  retry:\n    retry-aspect-order: 2\n    instances:\n      oracleStorage:\n        maxAttempts: 2\n        waitDuration: 500ms\n        retryExceptions:\n          - java.io.IOException\n          - com.oracle.bmc.model.BmcException\n          - java.lang.RuntimeException\n```\n\n**maxAttempts: 2**\n\n처음에는 3으로 설정했다가 2로 줄였다. QR 코드 업로드는 비동기로 처리되기 때문에, 사용자가 직접 대기하는 건 아니다. 하지만 비동기 스레드를 점유하는 시간은 줄이고 싶었다. Oracle Object Storage 업로드는 이미지 하나당 수백 ms가 걸린다. maxAttempts가 3이면 최악의 경우 `500ms(대기) + 업로드 시간` × 2번의 추가 시도가 발생한다.\n\n실제로 일시적 장애(네트워크 순단 등)는 대부분 1번의 재시도로 복구된다. 2번째 시도에서도 실패하면 일시적 장애가 아니라 지속적 장애일 가능성이 높다. 그때는 서킷 브레이커가 처리하는 게 맞다.\n\n**waitDuration: 500ms**\n\n재시도 간격이다. 너무 짧으면 같은 문제가 아직 해결되지 않은 상태에서 재시도하게 되고, 너무 길면 비동기 스레드 점유 시간이 길어진다. Oracle Object Storage 업로드의 평균 응답 시간이 200~400ms인 점을 고려해서 500ms로 설정했다.\n\n**retryExceptions**\n\n어떤 예외에서 재시도할 것인가도 중요한 결정이었다. 처음에는 `IOException`과 `BmcException`만 넣었다가, `RuntimeException`도 추가했다. Oracle OCI SDK가 내부적으로 RuntimeException을 던지는 케이스가 있었기 때문이다.\n\n다만 모든 예외에서 재시도하는 건 위험하다. `IllegalArgumentException` 같은 프로그래밍 오류는 몇 번을 재시도해도 결과가 같다. retryExceptions에 명시한 예외만 재시도하고, 나머지는 바로 실패 처리된다.\n\n### 재시도하면 안 되는 예외를 구분한 이유\n\n이건 테스트 코드에서도 검증했다.\n\n```java\n@Test\n@DisplayName(\"retryExceptions에 없는 예외는 리트라이하지 않는다\")\nvoid retryExceptions에_없는_예외는_리트라이_안함() {\n    when(objectStorage.putObject(any(PutObjectRequest.class)))\n            .thenThrow(new IllegalArgumentException(\"Invalid argument\"));\n\n    Supplier<String> decoratedSupplier = Retry.decorateSupplier(\n            retry,\n            () -> storageService.upload(\"test\", \"data\".getBytes())\n    );\n\n    assertThatThrownBy(decoratedSupplier::get)\n            .isInstanceOf(IllegalArgumentException.class);\n\n    // 1번만 호출됨 (리트라이 안 함)\n    verify(objectStorage, times(1)).putObject(any(PutObjectRequest.class));\n}\n```\n\n`IllegalArgumentException`은 retryExceptions에 없으니 재시도 없이 바로 실패한다. 잘못된 인자를 넣은 건 재시도한다고 고쳐지지 않기 때문이다.\n\n## Circuit Breaker 설계\n\n### 설정값 결정\n\n```yaml\nresilience4j:\n  circuitbreaker:\n    circuit-breaker-aspect-order: 1\n    instances:\n      oracleStorage:\n        slidingWindowType: COUNT_BASED\n        slidingWindowSize: 10\n        failureRateThreshold: 50\n        waitDurationInOpenState: 30s\n        permittedNumberOfCallsInHalfOpenState: 3\n        automaticTransitionFromOpenToHalfOpenEnabled: true\n        recordExceptions:\n          - java.io.IOException\n          - com.oracle.bmc.model.BmcException\n          - java.lang.RuntimeException\n```\n\n서킷 브레이커의 상태 전이를 정리하면 이렇다.\n\n```\n                    failure rate < 50%\n              +------------------------+\n              |                        |\n              v                        |\n         +---------+             +-----------+\n  ------>| CLOSED  |------------>|   OPEN    |\n         +---------+ failure    +-----------+\n              ^       rate >= 50%      |\n              |                        | after 30s\n              |                        v\n              |                 +------------+\n              +-----------------|  HALF_OPEN |\n                success rate    +------------+\n                 sufficient      3 trial calls\n```\n\n각 설정값을 왜 이렇게 잡았는지 설명한다.\n\n**slidingWindowType: COUNT_BASED**\n\n시간 기반(TIME_BASED)이 아니라 횟수 기반(COUNT_BASED)을 선택했다. QR 코드 업로드는 방 생성 시에만 발생하기 때문에, 호출 빈도가 일정하지 않다. 시간 기반이면 한가한 시간대에 1~2건만 실패해도 실패율 100%로 계산돼서 서킷이 열릴 수 있다. 횟수 기반이면 최소 10건의 샘플이 모여야 판단하기 때문에 더 안정적이다.\n\n**slidingWindowSize: 10 + failureRateThreshold: 50**\n\n최근 10건 중 5건 이상 실패하면 서킷을 연다. \"10건 중 5건\"이라는 기준이 적절한지 고민했다.\n\n너무 작게 잡으면(예: 5건 중 3건) 일시적 장애에도 서킷이 열려서 과민 반응한다. 너무 크게 잡으면(예: 50건 중 25건) 이미 장애가 충분히 진행된 뒤에야 차단되니까 리소스 보호 효과가 줄어든다.\n\nZZOL의 트래픽을 고려했다. 동시 접속자가 많은 시간대에 분당 10~20개의 방이 생성된다. 10건이면 약 30초~1분 분량의 호출이다. 이 정도면 \"일시적 문제인지 지속적 장애인지\"를 판단하기에 충분한 샘플이라고 봤다.\n\n**waitDurationInOpenState: 30s**\n\n서킷이 OPEN 상태가 되면 30초 동안 모든 호출을 차단한다. 30초 후 HALF_OPEN 상태로 전환되면서 시험 호출을 보낸다.\n\n왜 30초인가? Oracle Object Storage 장애가 발생하면 보통 수 분 내에 복구되거나, 아니면 장기 장애로 이어진다. 30초면 짧은 장애는 복구될 시간이고, 장기 장애라면 HALF_OPEN에서 다시 실패해서 OPEN으로 돌아간다.\n\n**permittedNumberOfCallsInHalfOpenState: 3**\n\nHALF_OPEN 상태에서 3건의 시험 호출을 허용한다. 1건만 허용하면 네트워크 지터 같은 일시적 문제로 잘못 판단할 수 있고, 너무 많으면 아직 불안정한 서비스에 부하를 줄 수 있다. 3건이면 2건 이상 성공해야 CLOSED로 전환되니까, 복구 여부를 합리적으로 판단할 수 있다.\n\n**automaticTransitionFromOpenToHalfOpenEnabled: true**\n\nOPEN → HALF_OPEN 전환을 자동으로 한다. 이걸 `false`로 두면 OPEN 상태에서 새로운 호출이 들어와야 HALF_OPEN으로 전환된다. 하지만 서킷이 열린 상태에서 호출이 한동안 안 들어올 수도 있다. 자동 전환을 켜두면 30초 후 알아서 HALF_OPEN으로 전환되고, 다음 호출에서 바로 시험할 수 있다.\n\n### aspect-order: 왜 순서가 중요한가\n\n```yaml\ncircuit-breaker-aspect-order: 1\nretry-aspect-order: 2\n```\n\n여기서 숫자가 작을수록 바깥쪽 AOP다. 즉 호출 순서가 이렇다.\n\n```\nRequest --> CircuitBreaker (order=1) --> Retry (order=2) --> actual method\n```\n\n서킷이 OPEN이면 Retry까지 가지 않고 바로 차단된다. 서킷이 CLOSED면 Retry가 안쪽에서 재시도하고, 최종 결과(성공 or 실패)만 CircuitBreaker에 기록된다.\n\n만약 반대로 Retry가 바깥이면 어떻게 될까?\n\n```\n+-------------------------------------------------------------------+\n|                   Aspect Order Comparison                         |\n+-------------------------------------------------------------------+\n|                                                                   |\n|  Order            Circuit OPEN         Circuit CLOSED             |\n|  -----------------------------------------------------------------|\n|                                                                   |\n|  CB -> Retry      Block immediately,   Retry first, then record  |\n|  (correct)        no retry attempt     final result to CB         |\n|                                                                   |\n|  -----------------------------------------------------------------|\n|                                                                   |\n|  Retry -> CB      CallNotPermitted     Each attempt recorded     |\n|  (wrong)          thrown twice,         to CB separately,         |\n|                   pointless retry      failure count inflated    |\n|                                                                   |\n+-------------------------------------------------------------------+\n```\n\n서킷이 열려 있으면 재시도해봤자 소용없다. CircuitBreaker를 바깥에 두면, 서킷이 OPEN일 때 Retry까지 가지 않고 바로 차단된다.\n\n반대로 서킷이 CLOSED일 때는 Retry가 안쪽에서 재시도한다. 재시도까지 해서 최종적으로 성공하면 CircuitBreaker에는 \"성공\"으로 기록된다. 재시도까지 해서도 실패하면 그때 \"실패\"로 기록된다. 서킷 브레이커 입장에서는 Retry까지 포함한 최종 결과만 보는 것이다.\n\n## 구현\n\n### Fallback 메서드 설계\n\n```java\n@Override\n@CircuitBreaker(name = \"oracleStorage\", fallbackMethod = \"uploadFallback\")\n@Retry(name = \"oracleStorage\")\npublic String upload(@NonNull String contents, byte[] data) {\n    if (data.length == 0) {\n        throw new StorageServiceException(\n            RoomErrorCode.QR_CODE_UPLOAD_FAILED, \"QR 이미지 바이트가 비어 있습니다.\");\n    }\n    return doUpload(contents, data);\n}\n```\n\n기존 코드에서 달라진 점은 두 가지다. `@CircuitBreaker`와 `@Retry` 어노테이션이 추가됐고, try-catch가 사라졌다.\n\ntry-catch를 제거한 이유가 있다. Resilience4j는 메서드가 던지는 예외 타입을 보고 \"이건 재시도할 예외인가\", \"이건 서킷 브레이커에 실패로 기록할 예외인가\"를 판단한다. 만약 메서드 내부에서 모든 예외를 잡아서 `StorageServiceException`으로 감싸버리면, Resilience4j는 원본 예외 타입을 알 수 없다. `IOException`인지 `BmcException`인지 구분이 안 되는 것이다.\n\n그래서 **원본 예외는 그대로 던지고, 예외 래핑은 fallback에서 한다.**\n\n```java\nprivate String uploadFallback(String contents, byte[] data, Exception e) {\n    meterRegistry.counter(\"oracle.objectstorage.qr.upload.failed\",\n            \"error\", e.getClass().getSimpleName()).increment();\n\n    if (e instanceof CallNotPermittedException) {\n        log.warn(\"서킷 브레이커 OPEN 상태 - Oracle Storage 호출 차단됨: contents={}\", contents);\n        throw new StorageServiceException(RoomErrorCode.QR_CODE_UPLOAD_FAILED,\n                \"스토리지 서비스가 일시적으로 사용 불가능합니다. 잠시 후 다시 시도해주세요.\");\n    }\n\n    log.error(\"Oracle Object Storage QR 코드 업로드 실패: contents={}, error={}\",\n            contents, e.getMessage(), e);\n    throw new StorageServiceException(RoomErrorCode.QR_CODE_UPLOAD_FAILED,\n            \"QR 코드 업로드에 실패했습니다. 잠시 후 다시 시도해주세요.\", e);\n}\n```\n\nfallback에서 `CallNotPermittedException`을 분기한 이유는, 서킷이 OPEN일 때와 실제 호출이 실패했을 때의 로그 레벨과 메시지를 다르게 하기 위해서다. 서킷이 열려서 차단된 건 예상된 동작이니 `warn`이고, 실제 업로드 실패는 `error`다.\n\n### 호출 흐름 정리\n\n전체 흐름을 정리하면 이렇다.\n\n```\nRoomService.createRoom()\n  |\n  v\nQrCodeService.generateQrCodeAsync()  (@Async)\n  |\n  v\nOracleObjectStorageService.upload()\n  |\n  v\n[CircuitBreaker: oracleStorage]\n  |\n  +-- OPEN\n  |     |\n  |     v\n  |   uploadFallback()\n  |     -> \"service temporarily unavailable\" exception\n  |     -> QrCodeService broadcasts ERROR status\n  |\n  +-- CLOSED / HALF_OPEN\n        |\n        v\n      [Retry: oracleStorage]\n        |\n        +-- 1st attempt SUCCESS\n        |     -> return QR code URL\n        |     -> QrCodeService broadcasts SUCCESS\n        |\n        +-- 1st attempt FAIL --> wait 500ms --> 2nd attempt\n              |\n              +-- SUCCESS: return URL\n              |\n              +-- FAIL: uploadFallback()\n                    -> record failure metric\n                    -> record failure to CircuitBreaker\n                    -> QrCodeService broadcasts ERROR\n```\n\n## 테스트\n\n### 단위 테스트와 통합 테스트를 나눈 이유\n\n서킷 브레이커 테스트는 두 가지 레벨로 작성했다.\n\n**단위 테스트**는 Resilience4j API를 직접 사용해서 서킷 브레이커와 리트라이의 동작을 검증한다. Spring 컨텍스트 없이 순수하게 Resilience4j 로직만 테스트한다. 서킷 상태 전이, 리트라이 횟수, 예외별 동작 같은 핵심 로직을 빠르게 검증할 수 있다.\n\n**통합 테스트**는 실제 Spring 컨텍스트에서 `@CircuitBreaker`, `@Retry` 어노테이션이 AOP 프록시를 통해 정상 동작하는지 검증한다. 어노테이션 기반이라 프록시가 안 타면 아무 의미가 없기 때문에, 이 부분은 통합 테스트로 검증해야 했다.\n\n통합 테스트에서 한 가지 주의할 점이 있었다. `OracleObjectStorageService`에 `@Profile(\"!local & !test\")` 조건이 걸려 있어서, 테스트 프로필에서는 이 빈이 로드되지 않는다. 그래서 `@TestConfiguration`으로 수동 등록했다.\n\n```java\n@TestConfiguration\nstatic class TestConfig {\n    @Bean\n    @Primary\n    public OracleObjectStorageService oracleObjectStorageService(\n            ObjectStorage objectStorage,\n            OracleObjectStorageProperties oracleProperties,\n            QrProperties qrProperties,\n            MeterRegistry meterRegistry\n    ) {\n        return new OracleObjectStorageService(\n            objectStorage, oracleProperties, qrProperties, meterRegistry);\n    }\n}\n```\n\n### 핵심 테스트 케이스\n\n통합 테스트에서 가장 중요한 건 \"리트라이 실패 후 fallback이 `StorageServiceException`을 던지는가\"다.\n\n```java\n@Test\n@DisplayName(\"재시도 횟수를 초과하는 지속적인 실패 발생 시, fallback이 StorageServiceException을 던진다\")\nvoid 지속적_실패_시_StorageServiceException_발생() {\n    when(objectStorage.putObject(any(PutObjectRequest.class)))\n            .thenThrow(new BmcException(500, \"ServiceCode\", \"Persistent failure\", \"requestId\"));\n\n    assertThatThrownBy(() ->\n        oracleObjectStorageService.upload(\"test-contents\", \"test-data\".getBytes()))\n            .isInstanceOf(StorageServiceException.class)\n            .hasMessageContaining(\"QR 코드 업로드에 실패했습니다\");\n\n    // maxAttempts(2)만큼 호출됨\n    verify(objectStorage, times(2)).putObject(any(PutObjectRequest.class));\n}\n```\n\n이 테스트가 검증하는 건 세 가지다. 리트라이가 maxAttempts(2)만큼 동작했는지, fallback이 실행됐는지, 최종 예외 타입이 `StorageServiceException`인지.\n\n단위 테스트에서는 `@CircuitBreaker` 어노테이션의 fallback이 동작하지 않기 때문에, 이 테스트는 통합 테스트에서만 가능하다. 어노테이션 기반 AOP는 Spring 프록시를 통해서만 동작하기 때문이다.\n\n## 모니터링\n\n서킷 브레이커를 도입했으면 모니터링이 되어야 한다. 서킷 상태를 모르면 도입한 의미가 없다.\n\nActuator 엔드포인트에 `circuitbreakers`와 `retries`를 노출시켰다.\n\n```yaml\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"health,info,metrics,prometheus,circuitbreakers,retries\"\n```\n\nPrometheus 메트릭도 자동 수집된다. Resilience4j가 Micrometer와 통합되어 있어서, 서킷 브레이커 상태 전이, 실패율, 호출 횟수 등이 자동으로 메트릭에 잡힌다. 여기에 추가로 업로드 성공/실패를 커스텀 메트릭으로 기록해서 Grafana 대시보드에서 확인할 수 있게 했다.\n\n## 핵심 포인트\n\n- **Retry**: 일시적 장애를 복구한다. 단, 모든 예외에 재시도하면 안 된다. retryExceptions로 재시도 대상을 명확히 제한해야 한다.\n- **Circuit Breaker**: 지속적 장애에서 리소스를 보호한다. slidingWindowSize와 failureRateThreshold는 서비스의 트래픽 패턴에 맞게 설정해야 한다.\n- **aspect-order**: CircuitBreaker가 Retry보다 바깥에 있어야 한다. 서킷이 열린 상태에서 무의미한 재시도를 방지한다.\n- **예외 래핑은 fallback에서**: 원본 예외를 그대로 던져야 Resilience4j가 예외 타입을 정확히 판단할 수 있다. 래핑은 fallback 한 곳에서 처리한다.\n- **단위 테스트 + 통합 테스트**: Resilience4j 로직은 단위 테스트로, 어노테이션 기반 AOP 동작은 통합 테스트로 검증한다. 둘 다 필요하다."},{"excerpt":"실시간 멀티플레이어 게임을 개발하면서 마주친 문제가 있다. 특정 상황에서 유저가 게임 흐름에서 이탈하는 현상이었다. 이 글에서는 문제를 분석하고 해결한 과정을 공유한다. 문제 인식 유저 피드백 ZZOL은 실시간으로 여러 명이 함께 플레이하는 게임 서비스다. 배포와 동시에 여러 사람들에게 피드백을 받아왔었는데, 예상치 못한 불만이 있었다. \"게임 중에 카톡…","fields":{"slug":"/message_recovery/"},"frontmatter":{"date":"2026년 02월 14일 09:02","title":"네트워크 불안정 상황에서도 메시지 유실 없는 견고한 게임 서버 설계","tags":["ZZOL"]},"rawMarkdownBody":"실시간 멀티플레이어 게임을 개발하면서 마주친 문제가 있다. 특정 상황에서 유저가 게임 흐름에서 이탈하는 현상이었다. 이 글에서는 문제를 분석하고 해결한 과정을 공유한다.\n## 문제 인식\n### 유저 피드백\nZZOL은 실시간으로 여러 명이 함께 플레이하는 게임 서비스다. 배포와 동시에 여러 사람들에게 피드백을 받아왔었는데, 예상치 못한 불만이 있었다.\n\n> \"게임 중에 카톡 확인하고 돌아왔는데, 저만 다른 화면에 있어요\"\n\n> \"친구들은 룰렛 돌리고 있는데 저는 아직 결과 화면이에요\"\n\n처음에는 단순한 버그인 줄 알았다. 하지만 피드백이 반복되면서 특정 패턴이 있다는 걸 인식하게 됐다.\n### 모니터링 분석\n문제를 파악하기 위해 모니터링 로그를 분석했다. 이탈이 발생하는 시점을 추적해보니 공통점이 있었다. 대부분 **화면 전환 직후**에 이탈이 발생하고 있었다. 더 파고들어보니 이탈 직전에 WebSocket 연결이 끊겼다가 재연결되는 로그가 있었다. 연결이 끊기는 원인은 다양했다.\n\n- 앱 간 이동 (크롬에서 카카오톡으로 전환 후 복귀)\n- 모바일 네트워크 순단 (WiFi ↔ LTE 전환, 일시적 신호 불안정)\n- 브라우저 백그라운드 전환 (모바일에서 다른 앱 사용 후 복귀)\n\n이런 상황들이 화면 전환 타이밍과 겹치면 문제가 발생했다. 게임이라는 도메인 특성상, 한 명이라도 흐름에서 이탈하면 전체 게임 진행이 어색해지기 때문에 꽤 치명적인 문제였다.\n\n### 도메인 분석\n\n문제를 제대로 이해하려면 먼저 ZZOL의 게임 흐름을 알아야 한다.\n\nZZOL은 여러 명이 방에 모여서 미니게임을 하고, 결과에 따라 룰렛을 돌려 당첨자를 정하는 서비스다. 흐름을 단순화하면 이렇다.\n\n```\n방 입장 → 대기실 → 미니게임 → 결과 발표 → 룰렛 → 당첨자 발표\n```\n\n여기서 핵심 제약이 있다. **모든 플레이어가 항상 같은 화면을 보고 있어야 한다.** 호스트가 \"다음 단계로\" 버튼을 누르면, 모든 플레이어의 화면이 동시에 전환되어야 한다. 한 명이라도 다른 화면에 있으면 게임이 성립하지 않는다.\n\n이 동기화를 WebSocket으로 구현했다. 호스트가 버튼을 누르면 서버가 모든 클라이언트에게 화면 전환 메시지를 브로드캐스트하고, 각 클라이언트는 메시지를 받으면 해당 화면으로 이동한다.\n\n### 문제 발생 시나리오\n\n그런데 WebSocket은 **연결된 클라이언트에게만** 메시지를 전달한다. 연결이 끊긴 클라이언트는 메시지를 받지 못하고, 나중에 재연결해도 이미 지나간 메시지는 다시 오지 않는다.\n\n구체적인 시나리오를 보자. 플레이어1(호스트)과 플레이어2가 결과 화면에 있다. 이때 플레이어2가 카카오톡 알림을 확인하러 앱을 전환한다. 모바일 브라우저는 백그라운드로 전환되면서 WebSocket 연결이 끊긴다. 그 사이에 호스트가 룰렛 버튼을 누른다. 서버는 화면 전환 메시지를 브로드캐스트하고, 플레이어1은 룰렛 화면으로 이동한다. 하지만 플레이어2는 연결이 끊겨 있었기 때문에 이 메시지를 받지 못한다.\n\n플레이어2가 다시 브라우저로 돌아온다. WebSocket이 재연결된다. 하지만 서버는 이미 메시지를 보낸 상태라 다시 보내주지 않는다. 결과적으로 플레이어2만 결과 화면에 남게 되고, 이후 게임 진행을 따라갈 수 없게 된다.\n\n이게 단순히 화면만 다른 게 아니라, 게임 진행 자체가 꼬인다. 룰렛 결과도 못 보고, 다음 단계 진행도 못 따라간다. 새로고침을 해도 이미 진행된 게임 상태와 동기화가 안 되기 때문에 해결되지 않는다. 결국 방을 나갔다가 다시 들어오거나, 게임을 처음부터 다시 시작해야 한다.\n\n## 해결 방법 탐색\n\n### RabbitMQ 도입 검토\n\n첫 번째로 고려한 방법은 RabbitMQ 같은 메시지 브로커 도입이었다. Durable Queue를 사용하면 클라이언트가 연결되어 있지 않아도 메시지를 쌓아뒀다가, 재연결 시 자동으로 전달해줄 수 있다.\n\n하지만 검토 결과 우리 상황에는 적합하지 않았다.\n\n첫째, 기존 아키텍처와 맞지 않았다. 이미 Redis를 세션 관리, 캐싱, 분산락 등 여러 용도로 사용하고 있었다. 메시지 복구 하나를 위해 새로운 인프라를 도입하면 관리 포인트가 늘어난다. 또한 현재 WebSocket 메시지 흐름을 전면 수정해야 했다.\n\n둘째, 게임 특성상 \"메시지 쏟아짐\" 문제가 있었다. 레이싱 게임을 예로 들면, 플레이어 위치가 실시간으로 업데이트되면서 초당 수십 개의 메시지가 오간다. 만약 3초간 연결이 끊겼다가 재연결되면, 그동안 쌓인 수백 개의 위치 업데이트 메시지가 한꺼번에 쏟아진다. 클라이언트는 이 과거 데이터를 순차적으로 처리하느라 버벅이게 되고, 사실 과거 위치 정보는 어차피 의미가 없다.\n\nRabbitMQ는 \"메시지 유실 방지\"에 최적화되어 있다. 모든 메시지를 빠짐없이 순서대로 전달하는 게 목표다. 하지만 실시간 게임은 다르다. 과거 데이터보다 현재 상태가 중요하다. 우리에게 필요한 건 \"모든 메시지 재전달\"이 아니라 \"현재 상태 동기화\"였다.\n\n셋째, 게임의 생명주기가 짧았다. 방 하나가 생성되고 게임이 끝나면 삭제된다. 길어야 1시간. 방마다 큐를 만들었다가 정리하는 오버헤드가 있고, 이런 짧은 생명주기에는 과한 솔루션이었다.\n\n### Redis Stream 기반 직접 구현\n\n결국 기존에 사용하던 Redis Stream을 활용해서 직접 구현하기로 했다.\n\n핵심 아이디어는 단순하다. 중요한 메시지는 Redis Stream에 저장해두고, 클라이언트는 마지막으로 받은 메시지의 ID를 기억해둔다. 재연결 시 \"이 ID 이후로 놓친 메시지가 있으면 달라\"고 서버에 요청한다.\n\nRabbitMQ와 다른 점은 두 가지다. 모든 메시지가 아니라 **선택적으로** 저장한다. 그리고 서버가 자동으로 쏟아붓는 게 아니라 **클라이언트가 필요할 때** 요청한다.\n\n## 구현\n\n### 전체 아키텍처\n\n**정상 상태 (메시지 전송)**\n\n```\n[ Server ]\n    |\n    +-- WebSocket message ----+--------------+\n    |                         |              |\n    v                         v              v\n[ Redis Stream ]        [ Client A ]   [ Client B ]\n(save message +         (received)     (received)\n generate streamId)          |              |\n                             v              v\n                        localStorage    localStorage\n                        save streamId   save streamId\n```\n\n**복구 상태 (재연결 시)**\n\n```\n[ Client B ] -- reconnect detected\n    |\n    v\nget lastStreamId from localStorage\n    |\n    v\ncall Recovery API --------------------------> [ Server ]\n\"give me messages after lastStreamId\"              |\n                                                   v\n                                             [ Redis Stream ]\n                                              XRANGE query\n                                                   |\n    <-------- return missed messages --------------+\n    |\n    v\nprocess by message type\n    |\n    +-- screen transition --> process only last one --> navigate\n    |\n    +-- state sync ---------> dispatch to subscribers\n```\n\n### 백엔드\n\n백엔드에서는 세 가지를 구현했다.\n\n첫째, 메시지 저장 로직이다. WebSocket 메시지를 보낼 때 Redis Stream에 함께 저장한다. 이때 모든 메시지를 저장하는 게 아니라, 복구가 필요한 메시지만 선택적으로 저장한다. 화면 전환 메시지나 게임 결과처럼 놓치면 안 되는 것들만 대상이다. 레이싱 게임 위치 업데이트 같은 빈도 높은 메시지는 저장하지 않는다.\n\n둘째, streamId 전달이다. Redis Stream에 메시지를 저장하면 고유한 ID가 생성된다. 이 ID를 클라이언트에게 함께 내려준다. 클라이언트는 이 ID를 저장해뒀다가 재연결 시 사용한다.\n\n셋째, Recovery API다. 클라이언트가 \"이 ID 이후로 놓친 메시지 달라\"고 요청하면, Redis Stream에서 해당 ID 이후의 메시지들을 조회해서 반환한다.\n\n### 프론트엔드\n\n프론트엔드에서는 네 가지를 구현했다.\n\n첫째, streamId 저장이다. WebSocket 메시지를 받을 때마다 streamId를 localStorage에 저장한다. 키는 `joinCode`와 `playerName` 조합으로 했다. 같은 브라우저에서 탭을 여러 개 띄워 다른 플레이어로 테스트하는 경우가 있는데, 이때 streamId가 섞이면 안 되기 때문이다.\n\n둘째, 재연결 감지다. WebSocket 연결이 끊겼다가 다시 연결되는 시점을 감지한다. 이때 저장해둔 streamId를 가지고 Recovery API를 호출한다.\n\n셋째, 복구 메시지 처리다. Recovery API에서 받은 메시지들을 처리한다. 여기서 중요한 설계 결정이 있다. 화면 전환 메시지는 **마지막 것만** 처리한다. 연결이 끊긴 동안 화면 전환이 여러 번 일어났을 수 있다. 결과 화면에서 룰렛으로, 룰렛에서 당첨자 화면으로. 이때 중간 과정을 다 거칠 필요 없이, 최종 상태인 당첨자 화면으로 바로 이동하면 된다.\n\n넷째, 구독자 라우팅이다. 화면 전환이 아닌 상태 동기화 메시지는 해당 화면의 구독자에게 전달한다. 예를 들어 카드 게임 상태 메시지는 카드 게임 화면 컴포넌트가 처리하도록 라우팅한다.\n\n### 복구 메시지 처리 흐름\n\n```\n+---------------------------------------------------------------+\n|                  Recovery Message Processing                   |\n+---------------------------------------------------------------+\n|                                                               |\n|   Recovery API response (3 messages)                          |\n|      |                                                        |\n|      |   +-----------------+                                  |\n|      +-->| SHOW_ROULETTE   |-- screen transition ---- save    |\n|      |   +-----------------+                           |      |\n|      |                                                 v      |\n|      |   +-----------------+                    lastScreenMsg |\n|      +-->| GAME_STATE      |-- state sync -- dispatch to subs |\n|      |   +-----------------+                                  |\n|      |                                                 |      |\n|      |   +-----------------+                           v      |\n|      +-->| SHOW_WINNER     |-- screen transition ---- save    |\n|          +-----------------+                           |      |\n|                                                        v      |\n|                                                 lastScreenMsg |\n|                                                        |      |\n|   ----------------------------------------------------------  |\n|   after loop                                                  |\n|      |                                                        |\n|      v                                                        |\n|   process lastScreenMsg (SHOW_WINNER)                         |\n|      |                                                        |\n|      v                                                        |\n|   navigate('/winner') --> jump to final screen                |\n|                                                               |\n|   * SHOW_ROULETTE is ignored (intermediate step)              |\n|                                                               |\n+---------------------------------------------------------------+\n```\n\n## 복구 전략\n\n모든 메시지를 똑같이 처리하는 건 비효율적이다. 메시지 특성에 따라 저장 여부를 다르게 가져갔다.\n\n```\n+---------------------------------------------------------------+\n|                    Message Storage Strategy                    |\n+---------------------------------------------------------------+\n|                                                               |\n|   Message Type            Characteristics      Storage        |\n|   ----------------------------------------------------------  |\n|                                                               |\n|   Screen Transition       - frequency: low     O Save         |\n|   (SHOW_ROULETTE,         - importance: high   (Redis Stream) |\n|    SHOW_WINNER)           - critical if missed                |\n|                                                               |\n|   ----------------------------------------------------------  |\n|                                                               |\n|   Game Progress           - frequency: high    X Don't Save   |\n|   (racing position,       - importance: low                   |\n|    realtime updates)      - only latest needed                |\n|                                                               |\n+---------------------------------------------------------------+\n```\n\n### 화면 전환 메시지 → 저장\n\n화면 전환 메시지는 Redis Stream에 저장하고, 재연결 시 복구한다.\n\n이런 메시지는 빈도가 낮다. 게임 한 판에 3~5개 정도. 하지만 놓치면 치명적이다. 한 번 놓치면 이후 게임 진행을 전혀 따라갈 수 없다. 그래서 반드시 복구해야 한다.\n\n### 게임 진행 상태 → 저장 안 함\n\n레이싱 게임 위치 업데이트 같은 메시지는 저장하지 않는다.\n\n이런 메시지는 빈도가 높다. 프레임마다 위치가 업데이트된다. 이걸 전부 저장했다가 재생하면 앞서 말한 \"메시지 쏟아짐\" 문제가 생긴다. 게다가 과거 위치를 순차적으로 재생해봤자 의미가 없다. 현재 위치만 알면 된다.\n\n현재는 이런 메시지에 대한 복구는 구현하지 않았다. 실시간 게임 특성상 잠깐 끊겼다가 돌아오면 자연스럽게 다음 업데이트부터 받게 되기 때문에, 치명적인 문제는 아니라고 판단했다.\n\n## 마무리\n\n정리하면 핵심은 세 가지다.\n\n첫째, 선택적 저장이다. 모든 메시지가 아니라 복구가 필요한 메시지만 저장한다. 화면 전환처럼 놓치면 치명적인 메시지만 대상이다.\n\n둘째, 클라이언트 주도 복구다. 서버가 자동으로 쏟아붓는 게 아니라, 클라이언트가 필요할 때 요청한다.\n\n셋째, 마지막 상태로 점프다. 화면 전환 메시지는 중간 과정을 다 거칠 필요 없이 최종 상태로 바로 이동한다.\n\nRabbitMQ 같은 메시지 브로커를 도입하면 자동으로 해결될 것 같지만, 도메인 특성을 고려하면 오히려 문제가 될 수 있다. \"모든 메시지 유실 방지\"가 아니라 \"현재 상태 동기화\"가 목표라면, 필요한 만큼만 직접 구현하는 게 더 적합한 선택이었다."},{"excerpt":"우테코 프로젝트 에서 대시보드 API 성능 개선 작업을 했다. 레이싱 게임 TOP 플레이어 조회 API가 너무 느려서 원인을 파악하고 개선하는 과정을 기록해본다. 문제 상황 dev 환경에 데이터를 넣고 API를 호출해보니 응답이 너무 느렸다. 로 쿼리 실행 계획을 확인해봤다. 문제는 두 가지였다.  테이블 풀스캔 (20만 건) 60만 건짜리 임시 테이블 …","fields":{"slug":"/query_improvement/"},"frontmatter":{"date":"2026년 02월 05일 09:02","title":"쿼리 최적화, 36초를 1초로 줄이기까지","tags":["ZZOL"]},"rawMarkdownBody":"우테코 프로젝트 `ZZOL(구 커피빵)`에서 대시보드 API 성능 개선 작업을 했다. 레이싱 게임 TOP 플레이어 조회 API가 너무 느려서 원인을 파악하고 개선하는 과정을 기록해본다.\n\n## 문제 상황\n\ndev 환경에 데이터를 넣고 API를 호출해보니 응답이 너무 느렸다. `EXPLAIN ANALYZE`로 쿼리 실행 계획을 확인해봤다.\n\n```\n-> Table scan on mg (cost=20588 rows=199800) (actual time=0.238..463 rows=200000 loops=1)\n-> Aggregate using temporary table (actual time=34947..34947 rows=599999 loops=1)\n```\n\n문제는 두 가지였다.\n\n1. `mini_game_play` 테이블 풀스캔 (20만 건)\n2. 60만 건짜리 임시 테이블 생성 후 정렬\n\n120만 건 데이터에서 3개 테이블 JOIN하고 있으니 당연히 느릴 수밖에 없었다.\n\n## 최적화 전 쿼리 흐름\n\n```\nmini_game_result (120만 건)\n    ↓\nJOIN mini_game_play (20만 건 풀스캔)\n    ↓\nJOIN player (60만 건)\n    ↓\nGROUP BY + ORDER BY (임시 테이블 60만 건)\n    ↓\nLIMIT 5\n```\n\n**실행 시간: 36,050ms (36초)**\n\n## 적용한 최적화\n\n### 1. 비정규화\n\n`mini_game_type`을 `mini_game_result` 테이블에 중복 저장했다.\n\n```sql\n-- Before: JOIN 필요\nSELECT ... FROM mini_game_result mr\nJOIN mini_game_play mg ON mr.mini_game_play_id = mg.id\nWHERE mg.mini_game_type = 'RACING_GAME'\n\n-- After: JOIN 제거\nSELECT ... FROM mini_game_result mr\nWHERE mr.mini_game_type = 'RACING_GAME'\n```\n\n**왜 비정규화를 선택했는가?**\n\n무조건 비정규화가 답은 아니라고 생각했다. 도메인 특성과 데이터 분포를 분석하고 나서 결정했다.\n\n첫째, **mini_game_type은 변경되지 않는 값이다.** 한 번 생성된 미니게임의 타입은 절대 바뀌지 않는다. 레이싱 게임이 카드 게임으로 바뀌는 일은 없다. 비정규화의 가장 큰 단점은 데이터 정합성 관리인데, 변경이 없는 값이라면 이 문제가 사라진다.\n\n둘째, **mini_game_type의 카디널리티가 낮다.** 현재 게임 타입은 `RACING_GAME`, `CARD_GAME` 두 가지뿐이다. 새로운 게임 타입이 추가되더라도 수십 개 수준일 것이다. 이런 경우 중복 저장해도 저장 공간 증가가 미미하다. varchar(20) × 120만 건 = 약 20MB 정도.\n\n셋째, **조회 빈도가 압도적으로 높다.** 대시보드 API는 관리자가 수시로 호출하는 조회성 API다. 반면 mini_game_result 데이터는 게임이 끝날 때 한 번 INSERT되고 끝이다. 조회 100번에 쓰기 1번 수준이라면, 조회 성능을 위해 쓰기 시 약간의 오버헤드를 감수하는 게 합리적이다.\n\n넷째, **JOIN 제거 효과가 크다.** 기존 쿼리는 `mini_game_play` 테이블을 풀스캔해서 `mini_game_type`을 가져왔다. 20만 건 풀스캔 후 필터링. 비정규화하면 이 JOIN 자체가 사라지고, `mini_game_result` 테이블 하나에서 바로 필터링할 수 있다.\n\n### 2. 복합 인덱스 추가\n\n```sql\nCREATE INDEX idx_mini_game_result_type_created \nON mini_game_result (mini_game_type, created_at);\n```\n\n**왜 복합 인덱스인가?**\n\n단일 컬럼 인덱스가 아니라 복합 인덱스를 선택한 이유가 있다.\n대시보드 API의 쿼리 조건을 보면 항상 두 가지 조건이 함께 쓰인다.\n\n```sql\nWHERE mini_game_type = 'RACING_GAME'\n  AND created_at BETWEEN '2026-01-01' AND '2026-01-31'\n```\n\n`mini_game_type` 단일 인덱스만 있으면? RACING_GAME 60만 건을 먼저 찾고, 그 안에서 created_at 조건으로 다시 필터링해야 한다.\n\n`created_at` 단일 인덱스만 있으면? 이번 달 데이터 12만 건을 먼저 찾고, 그 안에서 mini_game_type으로 다시 필터링해야 한다.\n\n복합 인덱스 `(mini_game_type, created_at)`가 있으면? B-Tree에서 RACING_GAME이면서 이번 달인 데이터를 **한 번에** 찾는다. 6만 건만 정확히 읽으면 된다.\n\n**컬럼 순서도 중요하다.** `mini_game_type`을 앞에 둔 이유는 등호(=) 조건이기 때문이다. `created_at`은 범위(BETWEEN) 조건이다. 등호 조건 → 범위 조건 순서로 인덱스를 구성해야 효율적으로 탄다. 반대로 하면 범위 조건에서 인덱스 스캔이 끊긴다.\n\n## 최적화 후 쿼리 흐름\n\n```\nmini_game_result (인덱스 레인지 스캔 → 6만 건만 조회)\n    ↓\nJOIN player (PK lookup)\n    ↓\nGROUP BY + ORDER BY (임시 테이블 6만 건)\n    ↓\nLIMIT 5\n```\n\n**실행 시간: 1,173ms (1.2초)**\n\n## Before vs After\n\n|항목|Before|After|개선율|\n|---|---|---|---|\n|실행 시간|36,050ms|1,173ms|**96.7%**|\n|JOIN 수|3개|2개|33% 감소|\n|스캔 방식|풀스캔 (120만 건)|인덱스 레인지 스캔 (6만 건)|-|\n|임시 테이블|60만 건|6만 건|90% 감소|\n\n## 삽질했던 부분\n\n### 1. k6 부하 테스트 결과가 이상했다\n\nBefore/After 모두 5~6ms로 차이가 없었다. 알고 보니 InnoDB 버퍼풀 캐시 히트 때문이었다. 같은 쿼리 반복하면 메모리에서 읽어서 빠르게 응답함.\n\n→ 진짜 성능은 `EXPLAIN ANALYZE`로 측정한 콜드 쿼리 시간으로 비교해야 했다.\n\n### 2. 인덱스를 만들어도 안 탔다\n\n처음에 데이터를 전부 이번 달(1월)에 몰아넣었더니 인덱스를 만들어도 옵티마이저가 풀스캔을 선택했다. \"어차피 다 읽어야 하니까 풀스캔이 낫다\"고 판단한 것.\n\n→ 데이터 분포를 1년치로 분산시키고 이번 달은 10%만 넣어서 해결했다. `ANALYZE TABLE`로 통계 정보 갱신도 필요했다.\n\n## 핵심 포인트\n\n- **비정규화**: 무조건 답이 아니다. 변경 가능성, 카디널리티, 조회/쓰기 비율을 따져보고 결정해야 한다.\n- **복합 인덱스**: WHERE 조건에 자주 함께 쓰이는 컬럼 조합으로 생성. 등호 조건 → 범위 조건 순서로.\n- **EXPLAIN ANALYZE**: 병목 구간이 어디인지 실제 실행 시간으로 확인 가능.\n- **데이터 분포**: 테스트 데이터도 실제 운영 환경과 유사하게 구성해야 의미 있는 결과가 나온다.\n\n"},{"excerpt":"지난 회고: retrospect-2024-2 돌아보기 2025년은 유독 기억에 많이 남을 한 해로 남을 것 같다. 할 말이 너무 많은데 이 글에 다 담길지 모르겠다. 우아한테크코스를 마치며 IMG_7091.jpeg\n올해는 우테코가 차지하는 비중이 정말 크다. 정말 몰입을 즐겼던 1년이었고, 다 끝난 지금 허전함과 섭섭함이 들 정도로 재미있고 좋은 사람들을…","fields":{"slug":"/retrospect-2025/"},"frontmatter":{"date":"2026년 01월 01일 09:01","title":"2025년 회고","tags":["회고","우아한테크코스"]},"rawMarkdownBody":"지난 회고: [[retrospect-2024-2]]\n\n## 돌아보기\n2025년은 유독 기억에 많이 남을 한 해로 남을 것 같다. 할 말이 너무 많은데 이 글에 다 담길지 모르겠다. \n### 우아한테크코스를 마치며\n![[IMG_7091.jpeg]]\n올해는 우테코가 차지하는 비중이 정말 크다. 정말 몰입을 즐겼던 1년이었고, 다 끝난 지금 허전함과 섭섭함이 들 정도로 재미있고 좋은 사람들을 많이 만날 수 있었던 시간들이었다. \n\n우테코에 지원할 때까지만 해도, 내가 이 교육과정을 따라가면 정말 많이 배울 수 있을 줄 알았다. 수료만 하면 나도 어디가서 쫌 친다~라고 말할 수 있을만한 그런 사람이 될 수 있을 줄 알았는데, 수료를 하고 1달이나 넘게 지난 지금 시점에서 생각해보면 말도 안된다.\n\n막상 과정을 따라갈 땐 양이 너무 많아서 허겁지겁 소화하기 바빴던 것 같은데, 어느날 뒤를 돌아보면 내가 공부한 건 정말 새발의 피였다는 걸 느꼈던 순간들이 많았다. 아는 게 1개 생길 때 알아야할 것들 10개가 눈 앞에 보인다. \n\n그래도 10개월동안 얻는 게 적지 않다. 너무 많다. \n#### 1. 나는 개발자를 해도 괜찮겠다.\n거의 매일 8시간 이상씩 개발을 해왔지만, 그 하루하루가 너무 재미있었다. 내가 이토록 개발에만 집중할 수 있는 시간이 언제 있을지 모르겠지만, 힘든 줄도 모르고 정말 재밌게 사람들과 토론하고 고민하고 개발한 시간들을 보내면서 다시 한 번 더 개발자라는 걸 업으로 삼아도 되겠다는 생각이 들었다. \n\n사실 코딩을 하는 시간은 중요하지 않다. 현실의 문제를 풀어가는 과정에서 팀원들과 이야기를 하는 그 순간이 재밌다. 정답이 없는 문제를 이런저런 아이디어로 푸는 그 짜릿함 때문에 힘듦을 모르고 몰입을 할 수 있지 않았을까 싶다.\n#### 2. 같이 일하고 싶은 사람은 어떤 사람일까.\n우테코 하반기에 가장 많이 했던 고민이다. 책임감, 연락 빈도, 이해력, 피드백 속도, 의사소통 능력, 유머 감각, 솔직함, 주도성, 친화력... 좋은 동료의 조건은 끝도 없다. 당연한 것들 투성이지만 '과연 나는 이 모든 걸 갖추고 있나?'라고 자문해보면 자신이 없어지기도 했다.\n\n그중에서도 지금까지 가장 마음에 새기고 있는 건, '말하는 것보다 듣는 것을 잘해야 한다'는 것이다. 의욕 넘치는 사람들이 모인 곳에서는 다들 본인의 생각을 말하고 싶어 입이 근질근질한 경우가 많았던 것 같다. 처음엔 자기주장이 뚜렷한 모습이 좋아 보였지만, 겪어보니 말을 잘하는 사람보다 '잘 들을 줄 아는 사람'이 있는 팀이 훨씬 잘 굴러간다는 걸 깨달았고, 그런 모습들을 보며 나 자신을 돌아보고 지금도 입보다 귀를 더 잘 사용하는 사람이 되자고 수시로 되뇌곤 한다. \n#### 3. 함께 성장가는 기분\n개발을 잘하고 싶다는 개인의 사리사욕을 채우기 위해 시작했던 우테코였는데, 시간이 지날 수록 개인의 성장보단, 같이 공부를 하는 팀원들이 성장했을 때 오는 뿌듯함과 만족감이 컸다. 내 주변 사람들을 같이 성장시키는 게 막상 해보면 여러모로 어려운 점이 있는데 내년은 잘 할지 모르겠다.\n\n## 내년은?\n### 3년만에 복학\n졸업까지 2년이나 남았다. 다시 학교로 돌아가는 기분이 긴장되기도 하고 설레기도 하고 답답하기도 하고 미묘 복잡하다. 내가 부족하다고 느꼈던 것들을 채우고 내가 얻었던 것들을 나눠줄 수 있는 한 해가 되었으면 좋겠다. 부지런히 겸손히 살아보자."},{"excerpt":"ZZOL 서비스에 Graceful Shutdown을 구현했다. 단순히 \"서버를 안전하게 끄자\"가 아니라, WebSocket 기반 실시간 게임 서비스에서 \"게임 중인 유저의 세션을 어떻게 보호할 것인가\"에 대한 이야기다. OS의 SIGTERM 시그널부터 Spring의 SmartLifecycle, 그리고 WebSocket 세션 드레이닝까지의 전체 과정을 기록…","fields":{"slug":"/graceful_shutdown/"},"frontmatter":{"date":"2025년 12월 29일 11:12","title":"WebSocket 서비스에서 Graceful Shutdown이 필요한 이유와 구현","tags":["ZZOL"]},"rawMarkdownBody":"ZZOL 서비스에 Graceful Shutdown을 구현했다. 단순히 \"서버를 안전하게 끄자\"가 아니라, WebSocket 기반 실시간 게임 서비스에서 \"게임 중인 유저의 세션을 어떻게 보호할 것인가\"에 대한 이야기다. OS의 SIGTERM 시그널부터 Spring의 SmartLifecycle, 그리고 WebSocket 세션 드레이닝까지의 전체 과정을 기록한다.\n\n## 왜 Graceful Shutdown이 필요한가\n\nZZOL은 실시간 멀티플레이어 게임 서비스다. 여러 명이 WebSocket으로 연결된 상태에서 미니게임을 하고, 결과에 따라 룰렛으로 당첨자를 뽑는다. 핵심은 **모든 게임 진행이 WebSocket 연결에 의존한다**는 것이다.\n\n서버를 재시작하면 어떤 일이 벌어지는가? 일반적인 HTTP API 서버라면 요청-응답 사이클이 짧아서, 처리 중인 요청만 마무리하면 된다. 하지만 WebSocket 서비스는 다르다. 클라이언트와 서버 사이에 지속적인 연결이 유지되고 있고, 이 연결 위에서 게임 상태가 실시간으로 동기화된다.\n\n서버를 즉시 종료(kill -9)하면 이런 일이 발생한다.\n\n```\nBefore Graceful Shutdown (kill -9)\n===========================================\n\n  Player A --WebSocket--> [Server]\n  Player B --WebSocket-->    |     <-- racing game in progress\n  Player C --WebSocket-->    |\n                             |\n                          kill -9\n                             |\n                             v\n  Player A --WebSocket--X  DEAD\n  Player B --WebSocket--X   (all connections lost)\n  Player C --WebSocket--X   (game state lost)\n\n  Result: Game interrupted, players see error\n```\n\n5명이 레이싱 게임을 하고 있는데 서버가 갑자기 죽으면, 5명 전원의 WebSocket 연결이 끊기고 게임 상태가 유실된다. 클라이언트는 아무 예고 없이 연결이 끊겼다는 에러만 받는다. ZZOL에서 레이싱 게임 한 라운드는 약 30초다. 배포 타이밍이 게임 중에 걸리면, 고작 30초를 못 기다려서 진행 중이던 게임 전체가 날아가는 셈이다.\n\n배포는 정기적으로 일어난다. 기능 추가, 버그 수정 때마다 서버를 재시작해야 한다. 그때마다 게임 중인 유저가 피해를 보면 안 된다.\n\nGraceful Shutdown이 해결해야 하는 문제는 세 가지다.\n\n첫째, **진행 중인 게임이 끝날 때까지 기다려야 한다.** 서버가 종료 시그널을 받더라도, 활성 WebSocket 세션이 모두 정리될 때까지 프로세스를 유지해야 한다.\n\n둘째, **종료 중에 새로운 연결을 받으면 안 된다.** Graceful Shutdown이 시작된 후에 새 플레이어가 접속하면, 그 플레이어의 게임이 시작되고 또 끝나길 기다려야 한다. 기존 연결만 드레이닝하고, 신규 연결은 차단해야 종료 시점이 예측 가능해진다.\n\n셋째, **무한정 기다릴 수는 없다.** 클라이언트가 연결을 끊지 않거나, 예상치 못한 상황이 발생할 수 있다. 타임아웃이 필요하다.\n\n## 종료 시그널부터 프로세스 종료까지: 전체 흐름\n\nGraceful Shutdown의 전체 과정을 이해하려면, OS 레벨부터 Spring 레벨까지 어떤 일이 순서대로 일어나는지 알아야 한다.\n\n### 1단계: OS → JVM (SIGTERM)\n\n배포 시 서버를 종료하면, 운영체제는 프로세스에 **SIGTERM(15)** 시그널을 보낸다. `docker stop`, `kill`, AWS CodeDeploy의 종료 명령 등이 모두 SIGTERM을 사용한다.\n\n```\nOS sends SIGTERM (signal 15) to JVM process\n    |\n    v\nJVM catches SIGTERM via shutdown hook\n    |\n    v\nJVM begins shutdown sequence\n```\n\nSIGTERM은 \"종료해달라\"는 요청이지 강제 종료가 아니다. 프로세스가 시그널을 받고 정리 작업을 수행할 시간을 준다. 반면 SIGKILL(9)은 프로세스가 핸들링할 수 없는 강제 종료다. `kill -9`를 쓰면 JVM이 아무것도 정리하지 못하고 즉시 죽는다.\n\nJVM은 SIGTERM을 받으면 등록된 **Shutdown Hook**을 실행한다. Spring Boot는 이 Shutdown Hook에 자신의 종료 로직을 등록해놓는다.\n\n### 2단계: JVM → Spring (ApplicationContext 종료)\n\nJVM의 Shutdown Hook이 실행되면 Spring의 `ApplicationContext`가 종료 절차를 시작한다.\n\n```\nJVM Shutdown Hook triggered\n    |\n    v\nSpring ApplicationContext.close()\n    |\n    v\nSmartLifecycle beans stop (ordered by phase, highest first)\n    |\n    +-- Phase MAX_VALUE (highest = stops first)\n    |     |\n    |     v\n    |   WebSocketGracefulShutdownHandler.stop()\n    |     -> set shuttingDown = true\n    |     -> reject new WebSocket connections\n    |     -> wait for active sessions to drain\n    |     -> timeout after 5 minutes\n    |\n    +-- Phase 0 (default)\n    |     |\n    |     v\n    |   Tomcat connector paused\n    |     -> stop accepting new HTTP requests\n    |     -> wait for in-flight requests\n    |\n    +-- Bean destruction\n          |\n          v\n        ThreadPoolTaskExecutor.shutdown()\n        ThreadPoolTaskScheduler.shutdown()\n        DataSource connections closed\n        Redis connections closed\n```\n\n여기서 핵심은 **SmartLifecycle의 phase 값**이다. phase가 클수록 먼저 stop()이 호출된다. `WebSocketGracefulShutdownHandler`의 phase를 `Integer.MAX_VALUE`로 설정한 이유는, WebSocket 세션 드레이닝이 **가장 먼저** 시작되어야 하기 때문이다.\n\n왜 먼저여야 하는가? WebSocket 세션을 정리하는 과정에서 Redis에 접근해서 방 상태를 업데이트하고, DB에 게임 결과를 저장해야 할 수 있다. 만약 Redis 커넥션이나 DB 커넥션이 먼저 끊기면, 세션 정리 과정에서 예외가 발생한다. 그래서 WebSocket 드레이닝을 먼저 시작하고, 모든 세션이 정리된 뒤에 인프라 리소스를 닫는 순서가 되어야 한다.\n\n### 3단계: Spring → WebSocket (세션 드레이닝)\n\nSpring의 Graceful Shutdown 설정(`server.shutdown: graceful`)은 Tomcat의 HTTP 요청 처리를 대상으로 한다. **WebSocket 연결은 이 메커니즘의 대상이 아니다.** HTTP 요청은 요청-응답 사이클이 끝나면 처리가 완료되지만, WebSocket은 연결이 지속되기 때문이다.\n\n그래서 WebSocket 세션 드레이닝은 직접 구현해야 했다.\n\n```\nWebSocketGracefulShutdownHandler.stop()\n    |\n    v\nCheck active WebSocket sessions\n    |\n    +-- sessions == 0\n    |     -> shutdown immediately\n    |\n    +-- sessions > 0\n          |\n          v\n        Set shuttingDown = true\n          |\n          +-- ShutdownAwareHandshakeInterceptor\n          |     rejects new WebSocket handshakes\n          |\n          v\n        Schedule status check (every 5s)\n          |\n          v\n        Wait on CompletableFuture\n          |\n          +-- All sessions closed naturally\n          |     -> complete future -> shutdown done\n          |\n          +-- Timeout (5 minutes)\n                -> log warning with remaining count\n                -> force shutdown\n```\n\n## 구현 상세\n\n### 신규 연결 차단: ShutdownAwareHandshakeInterceptor\n\nGraceful Shutdown이 시작되면 새로운 WebSocket 연결을 받으면 안 된다. STOMP 엔드포인트(`/ws`)에 `HandshakeInterceptor`를 등록해서, 모든 WebSocket 핸드셰이크 직전에 서버의 종료 상태를 확인하도록 했다. `isShuttingDown`이 true이면 핸드셰이크를 거부하고, 클라이언트는 연결 오류를 받는다. ZZOL은 SockJS를 사용하고 있기 때문에, 클라이언트는 자동으로 재연결을 시도한다. 이때 로드밸런서가 다른 인스턴스(혹은 새로 뜬 인스턴스)로 라우팅하면 된다.\n\n### 세션 드레이닝: WebSocketGracefulShutdownHandler\n\n핵심 구현체인 `WebSocketGracefulShutdownHandler`는 `SmartLifecycle`을 구현한다.\n\n```java\n@Override\npublic void stop(@NonNull Runnable callback) {\n    if (isShuttingDown) {\n        callback.run();\n        return;\n    }\n\n    final int currentConnections = getWebSocketSessionCount();\n\n    // 활성 연결이 없으면 즉시 종료\n    if (currentConnections == 0) {\n        isRunning = false;\n        callback.run();\n        return;\n    }\n\n    // Shutdown 모드 활성화 → 이 시점부터 신규 연결 차단됨\n    isShuttingDown = true;\n    shutdownFuture.set(new CompletableFuture<>());\n\n    // 5초 간격으로 남은 세션 수 확인\n    scheduleStatusLogging();\n\n    // 타임아웃과 함께 대기\n    try {\n        final CompletableFuture<Void> future = shutdownFuture.get();\n        if (future != null) {\n            future.get(shutdownWaitDuration.toMillis(), TimeUnit.MILLISECONDS);\n        }\n    } catch (TimeoutException e) {\n        log.warn(\"Graceful Shutdown 타임아웃: 활성 연결 {} 개가 남아있습니다.\",\n                getWebSocketSessionCount());\n    } finally {\n        cleanup();\n        callback.run();\n    }\n}\n```\n\n`SmartLifecycle.stop(Runnable callback)`에서 `callback.run()`을 호출해야 Spring이 다음 종료 단계로 진행한다. 이 콜백을 호출하지 않으면 Spring의 종료 프로세스 전체가 멈춘다.\n\n`CompletableFuture`를 사용한 이유가 있다. 폴링(Thread.sleep + 루프)으로 구현할 수도 있지만, CompletableFuture를 사용하면 세션이 모두 종료된 시점에 **즉시** shutdown을 완료할 수 있다. 예를 들어 타임아웃이 5분이더라도, 게임이 1분 만에 끝나서 모든 클라이언트가 나가면 4분을 낭비하지 않고 바로 종료된다. 5초마다 실행되는 상태 체크 스케줄러가 `remaining == 0`을 감지하면 `future.complete(null)`을 호출해서 대기를 해제한다.\n\n## 설정값과 도메인 기반 근거\n\n### shutdown 타임아웃: 5분\n\n```yaml\nspring:\n  lifecycle:\n    timeout-per-shutdown-phase: 5m\n```\n\nZZOL의 게임 흐름은 이렇다. 방에 입장한 참여자들이 미니게임을 하고, 결과에 따라 룰렛을 돌린다. 현재 구현된 미니게임은 레이싱 게임과 카드 게임이 있고, 레이싱 게임 한 라운드가 약 30초다. 라운드는 반복되지 않으며, 현재 구현된 모든 게임을 처음부터 끝까지 다 즐겨도 5분 이내에 끝난다.\n\n따라서 5분이면 **어떤 시점에 종료 시그널이 오더라도, 진행 중인 모든 게임이 자연스럽게 끝나기에 충분한 시간**이다. 이 값을 너무 짧게 잡으면 게임 중에 강제 종료되고, 너무 길게 잡으면 배포가 지연된다. 5분은 \"최악의 경우(모든 게임을 다 하는 중)\"에도 커버되는 상한선이다.\n\n### 상태 체크 간격: 5초\n\n```java\nprivate static final Duration STATUS_CHECK_INTERVAL = Duration.ofSeconds(5);\n```\n\n세션 드레이닝 중에 남은 연결 수를 확인하는 주기다. 5초인 이유는, ZZOL의 WebSocket 하트비트가 4초 간격이기 때문이다.\n\n```java\nconfig.enableSimpleBroker(\"/topic/\", \"/queue/\")\n        .setHeartbeatValue(new long[]{4000, 4000})\n```\n\n하트비트 간격보다 짧게 체크하면, 하트비트 타임아웃으로 끊기는 세션을 감지하기 전에 불필요한 체크가 반복된다. 하트비트 간격(4초)보다 약간 길게(5초) 잡으면, 하트비트 한 주기가 지난 뒤에 세션 상태가 갱신된 것을 확인할 수 있다.\n\n### 게임 스케줄러 awaitTermination: 30초\n\n```java\n// RacingGameSchedulerConfig.java\nscheduler.setWaitForTasksToCompleteOnShutdown(true);\nscheduler.setAwaitTerminationSeconds(30);\n```\n\n`setWaitForTasksToCompleteOnShutdown(true)`는 스케줄러 종료 시 `ExecutorService.shutdown()`을 호출한다. 대기 중인 작업이 완료될 때까지 기다린다. `false`면 `shutdownNow()`가 호출되어 실행 중인 작업까지 즉시 중단시킨다.\n\n30초로 잡은 이유는, 레이싱 게임 한 라운드가 약 30초이기 때문이다. 게임 스케줄러는 라운드 진행 중에 일정 간격으로 게임 상태를 업데이트하는 작업을 실행한다. 현재 라운드가 끝날 때까지 기다려주려면 최소 30초가 필요하다. Graceful Shutdown의 5분 타임아웃 안에서 동작하므로, 30초 대기는 전체 종료 시간에 큰 영향을 주지 않는다.\n\n### Redis Stream 스레드풀 awaitTermination: 10초\n\n```java\n// RedisStreamThreadPoolConfig.java\nexecutor.setWaitForTasksToCompleteOnShutdown(true);\nexecutor.setAwaitTerminationSeconds(10);\n```\n\nRedis Stream 이벤트 리스너는 방 참여, 게임 시작 같은 이벤트를 처리한다. 이 작업들은 단건 처리이고, 개별 이벤트의 처리 시간은 수십 ms 수준이다. 10초면 대기 중인 이벤트를 모두 처리하기에 충분하다.\n\n게임 스케줄러(30초)보다 짧은 이유는 작업의 성격이 다르기 때문이다. 게임 스케줄러는 \"진행 중인 라운드가 끝날 때까지\" 기다려야 하지만, Redis Stream 이벤트는 큐에 쌓인 이벤트를 순서대로 소비하기만 하면 되므로 훨씬 빠르게 정리된다.\n\n### 지연 삭제 스케줄러 awaitTermination: 30초\n\n```java\n// DelayRemovalSchedulerConfig.java\nscheduler.setWaitForTasksToCompleteOnShutdown(true);\nscheduler.setAwaitTerminationSeconds(30);\n```\n\n지연 삭제 스케줄러는 플레이어가 WebSocket 연결이 끊겼을 때, 즉시 방에서 제거하지 않고 **15초 후에 제거하는 작업**을 스케줄링한다. 일시적인 네트워크 끊김인 경우 재연결할 시간을 주기 위해서다.\n\n30초로 잡은 이유는, 지연 삭제 대기 시간이 15초이기 때문이다. Graceful Shutdown 시점에 이미 스케줄링된 지연 삭제 작업이 있을 수 있다. 최대 15초 후에 실행되는 작업 + 실행 시간을 고려하면 30초면 충분하다.\n\n## 전체 종료 시퀀스\n\nOS부터 프로세스 종료까지 전체 시퀀스를 정리하면 이렇다.\n\n```\n[OS]  docker stop / kill / CodeDeploy stop\n  |\n  v\n[OS]  SIGTERM (signal 15) --> JVM process\n  |\n  v\n[JVM] Shutdown Hook triggered\n  |\n  v\n[Spring] ApplicationContext.close()\n  |\n  v\n[Spring] SmartLifecycle.stop() -- phase MAX_VALUE first\n  |\n  +--[WebSocket] GracefulShutdownHandler.stop()\n  |    |\n  |    +-- shuttingDown = true\n  |    |   (HandshakeInterceptor rejects new connections)\n  |    |\n  |    +-- Wait for active sessions to drain\n  |    |   (check every 5s, timeout 5min)\n  |    |\n  |    +-- All sessions closed OR timeout reached\n  |         |\n  |         v\n  |       callback.run() --> Spring continues\n  |\n  v\n[Spring] Tomcat connector paused\n  |       (stop accepting new HTTP requests)\n  |       (wait for in-flight requests)\n  |\n  v\n[Spring] Bean destruction phase\n  |\n  +-- Game scheduler shutdown (await 30s)\n  |     -> wait for current racing round to finish\n  |\n  +-- Delay removal scheduler shutdown (await 30s)\n  |     -> wait for pending player removals\n  |\n  +-- Redis Stream thread pool shutdown (await 10s)\n  |     -> drain queued events\n  |\n  +-- DataSource.close()\n  +-- RedisConnectionFactory.close()\n  |\n  v\n[JVM] All shutdown hooks completed\n  |\n  v\n[OS] Process exits (exit code 0)\n```\n\nSIGTERM → JVM Shutdown Hook → Spring ApplicationContext.close() → SmartLifecycle(phase 순서) → Bean destruction → 프로세스 종료. 이 체인에서 WebSocket 세션 드레이닝은 가장 앞단(phase MAX_VALUE)에서 시작되고, 인프라 리소스 정리(Redis, DB)는 가장 뒷단에서 이뤄진다.\n\n## 핵심 포인트\n\n- **WebSocket은 Spring의 `server.shutdown: graceful` 대상이 아니다.** 이 설정은 Tomcat의 HTTP 요청만 처리한다. WebSocket 세션 드레이닝은 SmartLifecycle을 구현해서 직접 처리해야 한다.\n- **SmartLifecycle의 phase를 MAX_VALUE로 설정하면, 가장 먼저 stop()이 호출된다.** WebSocket 세션 정리가 Redis, DB보다 먼저 시작되어야, 정리 과정에서 데이터에 접근할 수 있다.\n- **종료 중 신규 연결 차단은 HandshakeInterceptor에서 처리한다.** `isShuttingDown` 플래그를 확인하고 `return false`로 핸드셰이크를 거부하면 된다. 이게 없으면 종료가 무한정 지연될 수 있다.\n- **타임아웃은 도메인의 최대 게임 시간을 기준으로 설정한다.** ZZOL의 모든 게임이 5분 이내에 끝나므로, shutdown 타임아웃도 5분이다. 근거 없는 타임아웃은 짧으면 게임을 끊고, 길면 배포를 지연시킨다.\n- **SIGTERM과 SIGKILL의 차이를 이해해야 한다.** SIGTERM은 프로세스가 핸들링할 수 있는 종료 요청이고, SIGKILL은 불가능하다. Graceful Shutdown은 SIGTERM에서만 작동한다. `kill -9`를 쓰면 전부 무의미해진다."},{"excerpt":"","fields":{"slug":"/우아한테크코스_7기_BE_최종_회고/"},"frontmatter":{"date":"2025년 11월 28일 09:11","title":"우아한테크코스 최종 회고","tags":["우아한테크코스","회고"]},"rawMarkdownBody":"\n\n"},{"excerpt":"우테코 프로젝트에서 서비스 기획을 전면 수정했다. 원래 \"커피 내기\" 서비스였던 커피빵(CoffeeShout)을, \"똥손도 즐기는 게임 기반 추첨 서비스\" ZZOL(쫄)로 바꿨다. 왜 바꿨고, 뭘 바꿨는지 기록한다. 원래 기획: 커피빵(CoffeeShout) 커피빵의 출발점은 단순했다. \"점심 먹고 커피 누가 살래?\"라는 상황이다. 직장인이면 매일 한 번…","fields":{"slug":"/coffeeshout_to_zzol/"},"frontmatter":{"date":"2025년 11월 19일 15:11","title":"커피빵에서 ZZOL로, 유저가 알려준 진짜 서비스","tags":["ZZOL","우아한테크코스"]},"rawMarkdownBody":"우테코 프로젝트에서 서비스 기획을 전면 수정했다. 원래 \"커피 내기\" 서비스였던 커피빵(CoffeeShout)을, \"똥손도 즐기는 게임 기반 추첨 서비스\" ZZOL(쫄)로 바꿨다. 왜 바꿨고, 뭘 바꿨는지 기록한다.\n\n## 원래 기획: 커피빵(CoffeeShout)\n\n커피빵의 출발점은 단순했다. \"점심 먹고 커피 누가 살래?\"라는 상황이다. 직장인이면 매일 한 번쯤 겪는 장면이고, 대부분 가위바위보로 정한다. 이걸 좀 더 재미있게 만들어보자는 게 기획 의도였다.\n\n핵심 기능은 미니게임 기반 룰렛 시스템이었다. 참여자들이 미니게임을 하면 결과에 따라 룰렛 가중치가 조정되고, 그 확률로 당첨자를 뽑는 구조다. 게임을 잘하면 당첨 확률이 낮아지니까, \"운\"만이 아니라 \"실력\"도 개입할 수 있다.\n\n페르소나도 커피에 초점이 맞춰져 있었다. \"매일같이 아메리카노를 달고 사는 직장인\"이 메인 타겟이었고, 서비스 이름부터 CoffeeShout(커피빵)이었다. 프로젝트 주제도 \"똥손도 즐기는 커피빵 전쟁\"이었다.\n\n## 유저가 보여준 진짜 사용 패턴\n\n배포 후 유저 피드백을 받으면서 예상과 다른 패턴이 보이기 시작했다.\n\n유저들은 커피 내기에만 쓰지 않았다. 점심 메뉴 정할 때, 팀 내 잡일 담당 정할 때, 심지어 술자리에서 벌칙 당첨자 정할 때도 쓰고 있었다. \"커피\"라는 맥락은 우리가 상정한 것이지, 유저에게는 그냥 \"누가 걸릴지 정하는 도구\"였다.\n\n이 시점에서 두 가지 문제가 보였다.\n\n첫째, **서비스 이름이 사용 범위를 제한하고 있었다.** \"커피빵\"이라는 이름은 커피 내기가 아닌 상황에서 쓰기에 어색하다. 술자리에서 \"커피빵으로 정하자\"라고 하면 맥락이 안 맞는다. 이름이 곧 서비스의 정체성인데, 그 정체성이 유저의 실제 사용 방식보다 좁았다.\n\n둘째, **기능 세부사항에 불필요한 제약이 있었다.** 기존 기획에는 \"메뉴 선택\"이라는 단계가 있었다. 참여자가 방에 입장한 뒤 자기가 마실 메뉴를 고르는 기능이다. 커피 내기라면 의미 있는 기능이지만, 범용 추첨 서비스에서는 오히려 흐름을 복잡하게 만드는 불필요한 단계였다.\n\n## 바꾸기로 한 기준\n\n기획을 바꾸는 건 비용이 크다. 이미 구현한 기능도 있고, 팀원들과 합의한 방향도 있다. 그래서 \"바꿔야 하는가?\"와 \"어디까지 바꿀 것인가?\"를 구분해서 판단했다.\n\n### 바꿔야 하는가?\n\n이건 명확했다. 유저의 실제 사용 패턴이 기획 의도와 다르면, 기획을 유저에게 맞추는 게 맞다. 우리가 \"이건 커피 내기 서비스입니다\"라고 주장해봤자, 유저가 술자리 벌칙용으로 쓰고 있으면 그게 현실이다.\n\n핵심 기능인 \"미니게임 → 가중치 조정 → 룰렛 추첨\" 흐름 자체는 유저들이 잘 쓰고 있었다. 문제는 이 기능을 감싸고 있는 컨텍스트(\"커피\")가 실제 사용과 안 맞다는 것이었다. 핵심을 버리는 게 아니라 껍데기를 바꾸는 거라면, 비용 대비 효과가 충분하다고 판단했다.\n\n### 어디까지 바꿀 것인가?\n\n바꾸는 범위를 세 가지로 나눴다.\n\n첫째, 서비스 정체성이다. 이름, 주제, 설명 등 서비스가 뭔지 정의하는 부분. \"커피 내기 서비스\"에서 \"게임 기반 추첨 서비스\"로 바꿨다. 이름은 커피빵(CoffeeShout)에서 쫄(ZZOL)로 변경했다. \"쫄릴 준비 됐어?\"라는 태그라인은 추첨이라는 행위의 긴장감을 담고 있어서, 커피든 술자리든 벌칙이든 맥락을 가리지 않는다.\n\n둘째, 사용자 흐름이다. 기존에 있던 \"메뉴 선택\" 단계를 제거했다. 대신 방 참여 방식을 강화했다. 초대 코드뿐 아니라 QR 코드와 초대 링크를 추가해서 원클릭 참여가 가능하도록 했다. 추첨 서비스에서 진입 허들을 낮추는 게 더 중요하다고 봤다.\n\n셋째, 페르소나다. \"커피 중독 직장인\"에서 \"팀 내에서 내기를 자주 하는 사용자\"로 대전제를 넓혔다. 페르소나의 니즈도 \"공짜로 커피를 먹고 싶음\"에서 \"재미있게 당첨자를 정하고 싶음\"으로 바꿨다. 커피가 빠지니까 사용 시나리오가 자연스럽게 넓어진다.\n\n## Before vs After\n\n```\n+-------------------------------------------------------------------+\n|               CoffeeShout vs ZZOL                                 |\n+-------------------------------------------------------------------+\n|                                                                   |\n|  Aspect           CoffeeShout           ZZOL                      |\n|  -----------------------------------------------------------------|\n|                                                                   |\n|  Scope            Coffee bet only       Any kind of bet           |\n|                                                                   |\n|  Core flow        Join -> Menu select   Join -> Mini game         |\n|                   -> Mini game          -> Roulette               |\n|                   -> Roulette                                     |\n|                                                                   |\n|  Entry method     Invite code only      Invite code + QR code     |\n|                                         + Invite link             |\n|                                                                   |\n|  Persona need     \"Free coffee\"         \"Fun and fair drawing\"    |\n|                                                                   |\n|  Pain point       \"Boring same game\"    \"Same person always       |\n|                                          gets picked\"             |\n|                                                                   |\n+-------------------------------------------------------------------+\n```\n\n## 안 바꾼 것\n\n바꾸지 않은 것도 명확히 해둔다.\n\n**미니게임 → 가중치 조정 → 룰렛 추첨** 흐름은 그대로다. 이게 서비스의 핵심이고, 유저들이 실제로 재미있어하는 부분이다. 바꾼 건 이 흐름을 감싸는 맥락이지, 흐름 자체가 아니다.\n\n기술 스택도 바꾸지 않았다. Redis 기반 세션 관리, WebSocket 실시간 통신, Oracle Object Storage QR 코드 저장 등 인프라는 그대로 유지했다. 기획 변경이 기술 부채를 만들지 않도록 범위를 통제한 것이다.\n\n## 돌아보며\n\n기획을 바꾸면서 느낀 건, 유저의 사용 패턴은 기획서보다 정직하다는 것이다. 우리가 \"커피 내기 서비스\"라고 정의해도, 유저는 자기한테 편한 방식으로 쓴다. 그 간극을 인지했을 때 기획에 맞춰달라고 할 수는 없다. 서비스가 유저에게 맞추는 게 맞다.\n\n다만 무작정 바꾸는 건 아니다. 핵심 기능이 유효한지, 바꾸는 범위가 통제 가능한지, 기존 기술 자산을 유지할 수 있는지를 따져보고 결정해야 한다. 이번 경우에는 껍데기만 바꾸고 알맹이는 유지하는 전략이 가능했기 때문에 빠르게 전환할 수 있었다.\n\n"},{"excerpt":"24-26_최민준\n25-26_이재호\n24-26_김준섭\n23-26_김상윤\n25-26_이효근\n24-26_유호인\n25-26_김선희\n24-26_고규필\n23-26_김여진\n25-26_이서연\n24-26_홍가을\n25-26_정보운\n25-26_정세린\n25-26_추서연 22-26_손유진 son_yujin_","fields":{"slug":"/구글_커리어세션/"},"frontmatter":{"date":"2025년 11월 07일 09:11","title":null,"tags":null},"rawMarkdownBody":"24-26_최민준\n25-26_이재호\n24-26_김준섭\n23-26_김상윤\n25-26_이효근\n24-26_유호인\n25-26_김선희\n24-26_고규필\n23-26_김여진\n25-26_이서연\n24-26_홍가을\n25-26_정보운\n25-26_정세린\n25-26_추서연\n\n22-26_손유진\n\nson_yujin_"},{"excerpt":"0. 목차 목표 회사 선택하기 (IT 대기업뿐만 아니라 스타트업도 고려해 본다, 가급적 사람인보다 원티드, 로켓펀치에서 회사를 찾아본 다) (3년 차를 요구한다고 정말 3년 이상만 지원할 수 있는 것이 아니다. 3년 차에 준하는 실력을 가진 사람을 찾는다는 뜻) 목표 우선순위 정하기 (여기서 목표란 회사의 규모, 연봉, 기술, 문화, 집과의 거리, 복지,…","fields":{"slug":"/제이슨_구직특강/"},"frontmatter":{"date":"2025년 10월 31일 09:10","title":null,"tags":null},"rawMarkdownBody":"## 0. 목차\n1. 목표 회사 선택하기 (IT 대기업뿐만 아니라 스타트업도 고려해 본다, 가급적 사람인보다 원티드, 로켓펀치에서 회사를 찾아본 다) (3년 차를 요구한다고 정말 3년 이상만 지원할 수 있는 것이 아니다. 3년 차에 준하는 실력을 가진 사람을 찾는다는 뜻)\n2. 목표 우선순위 정하기 (여기서 목표란 회사의 규모, 연봉, 기술, 문화, 집과의 거리, 복지, 스타 개발자 등 모든 것이 된다. 이 중 에서 우선순위를 정한다. 가급적 구체적인 목표의 선도 설정한다.)\n3. 목표 회사 중 목표 우선순위에 따라 점수를 매긴다.\n4. 채용 기한이 정해져 있는가, 상시 채용인가에 따라 다시 정렬한다.\n5. 정말 가고 싶은 회사의 기본 사항은 만족하여야 하고, 우대 사항도 만족할 수 있도록 공부한다.\n6. 공부를 하며 우선순위가 낮은, 채용 기한이 빠른 회사들을 하나씩 지원한다. (면접도 트렌드가 있다. 이때는 면접을 공부한 는 생각으로 지원하는 것이 좋다. 회사가 나라는 개발자에게 어떤 것을 궁금해 하는지 충분 습한다.)\n7. 만약 면접 연습 중 합격한다면 다급해 할 필요 없이 합격한 회사와 연봉 등에 대해 협상을 한다. (잊지 마라. 지금 합격한 회사는 떨어져도 되는 회사였다.)\n8. 점수가 높은 회사에 최종 합격\n## 1. 목표 회사 선택하기\n- 대기업뿐만 아니라 스타트업도 고려\n- 원티드, 로켓펀치에서 회사 찾아보기\n- 3년차를 요구한다고 정말 3년차 이상만 해당하는 건 아님. 3년차에 준하는 실력을 가진 사람을 원함\n\t- 만 3년이 아니라, 3년차\n\t\t- 가상면접사례로 배우는 대규모시스템설계\n\t\t- Real Mysql\n## 2. 목표 우선순위 정하기\n- 회사 규모, 연봉, 문화, 거리, 복지\n- 여성 복지정책도\n- 각 목표의 하한선\n- https://thevc.kr\n- https://www.innoforest.co.kr\n## 5. 정말 가고 싶은 싶은 회사의 기본사항은 만족해야하고, 우대사항도 만족할 수 있도록 공부해야함\n## 6. 공부하면서 우선순위가 낮은, 채용기한이 빠른 회사들을 지원\n- 면접도 트렌드, 공부한단마인드\n- 회사가 나라는 개발자에게 어떤 것을 궁금해하는지 충분히 학습\n- 나도 회사를 평가하기 위한 질문을 준비\n\t- https://blog.rhostem.com/posts/2019-01-05-developer-guide-for-interview\n\t- 이 사업 아이디어 어떻게 생각했는지\n\t- 오늘 해야 할 일을 어떻게 파악합니까\n\t- 버전관리 어떻게 하냐\n\t- 여기서 일하면 어떤 점이 좋은지\n\t- 유닛 테스트 작성하는지\n\t- 백엔드 개발자 몇 명인지\n\t- 내가 들어가면 사수는 있는지\n\t- 개인 성과 측정 어떻게 하는지\n- 면접 후기는 무조건 작성\n- 자기소개는 잘하자\n\t- 첫 질문은 자기소개 기반\n## 7. 연습 삼아 본 면접이 합격하면 다급해하지 않기, 연봉 협상 진행\n- 대부분 합격은 전화로 들어옴\n- \"밖이라서 그런데, 지금 말씀하신 내용 메일로 보내주실 수 있을까요?\"\n\t- 입사 시간 벌기\n\t\t- 늦추면 늦출수록 좋다\n\t- 최대 한 달까진 가능할수도, 어떤 핑계로?\n\t\t- 이사?\n\t\t- 부모님 모시고 여행?\n\t\t- "},{"excerpt":"infra_design 지난 글에서 이어집니다! Redis pub/sub Redis Pub/Sub의 동작 원리를 이해하면 왜 이 방식이 실시간 게임 동기화에 적합한지 명확해진다. Redis 내부 구조 Redis 서버는 C로 구현되어 있으며, Pub/Sub 기능은 내부적으로 매우 단순한 자료구조로 동작한다. Redis 서버의  구조체는 다음과 같은 Pub/…","fields":{"slug":"/how_redis_pubsub_works/"},"frontmatter":{"date":"2025년 10월 14일 09:10","title":"Redis Pub/Sub을 활용한 다중 서버 간 실시간 메시지 동기화 전략","tags":["우아한테크코스","ZZOL"]},"rawMarkdownBody":"[[infra_design]] 지난 글에서 이어집니다!\n## Redis pub/sub\n\nRedis Pub/Sub의 동작 원리를 이해하면 왜 이 방식이 실시간 게임 동기화에 적합한지 명확해진다.\n\n### Redis 내부 구조\n\nRedis 서버는 C로 구현되어 있으며, Pub/Sub 기능은 내부적으로 매우 단순한 자료구조로 동작한다. Redis 서버의 `redisServer` 구조체는 다음과 같은 Pub/Sub 관련 정보를 메모리에 유지한다:\n\n```c\nstruct redisServer {\n    dict *pubsub_channels;  // 채널명 → 구독자 리스트 해시테이블\n    list *pubsub_patterns;  // 패턴 구독자들 링크드리스트\n    // ...\n}\n```\n\n클라이언트가 `SUBSCRIBE room.events`를 실행하면, Redis는 `pubsub_channels` 해시테이블에서 해당 채널을 찾고, 구독자 리스트에 클라이언트를 추가한다. 이후 `PUBLISH room.events {...}` 메시지가 들어오면, 해시테이블에서 채널을 O(1)로 조회하고 구독자 리스트를 순회하며 메시지를 전송한다.\n\n### 메시지 전달 흐름\n\n커피빵 서비스에서 플레이어가 Ready 상태를 변경하는 과정을 예로 들어보자.\n\n#### 1. 클라이언트가 WebSocket으로 메시지 전송\n\n```javascript\n// 브라우저에서 전송\nstompClient.send('/app/room/ABC123/update-ready', {}, JSON.stringify({\n  joinCode: \"ABC2\",\n  playerName: \"홍길동\",\n  isReady: true\n}));\n```\n\n#### 2. Spring WebSocket Controller가 수신\n\n```java\n@MessageMapping(\"/room/{joinCode}/update-ready\")\npublic void broadcastReady(@DestinationVariable String joinCode, \n                          ReadyChangeMessage message) {\n    final PlayerReadyEvent event = new PlayerReadyEvent(\n        joinCode, \n        message.playerName(),\n        message.isReady()\n    );\n    roomEventPublisher.publishEvent(event);\n}\n```\n\nSpring이 STOMP 프로토콜로 들어온 메시지를 파싱해 컨트롤러로 라우팅한다. 이후 도메인 이벤트인 `PlayerReadyEvent`를 생성하며, 이때 이벤트 ID와 타임스탬프가 자동으로 생성된다.\n\n#### 3. RedisTemplate의 convertAndSend()\n\n```java\npublic <T extends RoomBaseEvent> void publishEvent(T event) {\n    redisTemplate.convertAndSend(roomEventTopic.getTopic(), event);\n}\n```\n\n`RedisTemplate`은 Spring Data Redis가 제공하는 추상화 레이어다. 내부에서는 다음 과정이 순차적으로 실행된다.\n\n```java\n// RedisTemplate 내부 동작\npublic void convertAndSend(String channel, Object message) {\n    // 1. 채널명 직렬화: \"room.events\" → byte[]\n    byte[] rawChannel = \"room.events\".getBytes(StandardCharsets.UTF_8);\n    \n    // 2. 메시지 객체 직렬화: PlayerReadyEvent → JSON → byte[]\n    GenericJackson2JsonRedisSerializer serializer = ...;\n    byte[] rawMessage = serializer.serialize(event);\n    // 결과: {\"eventId\":\"uuid-123\",\"joinCode\":\"ABC2\",\"playerName\":\"홍길동\",\"isReady\":true,...}\n    \n    // 3. Lettuce Connection으로 전달\n    connection.publish(rawChannel, rawMessage);\n}\n```\n\n#### 4. Lettuce의 RESP 프로토콜 변환\n\nLettuce는 Netty 기반의 비동기 Redis 클라이언트다. Redis와 통신하기 위해서는 **RESP(REdis Serialization Protocol)**라는 Redis 전용 프로토콜로 변환해야 한다.\n\nRESP는 Redis의 표준 통신 규약으로, 텍스트 기반의 간단한 프로토콜이다. 각 데이터 타입을 특정 문자로 시작해 구분한다:\n\n- `*` : 배열 (Array)\n- `$` : 문자열 길이 (Bulk String)\n- `:` : 정수 (Integer)\n- `+` : 단순 문자열 (Simple String)\n- `-` : 에러 (Error)\n\n예를 들어 `PUBLISH room.events {\"data\":\"...\"}` 명령은 다음과 같이 변환된다:\n\n```\n*3\\r\\n\n$7\\r\\n\nPUBLISH\\r\\n\n$11\\r\\n\nroom.events\\r\\n\n$152\\r\\n\n{\"eventId\":\"uuid-123\",\"joinCode\":\"ABC2\",\"playerName\":\"홍길동\",\"isReady\":true,...}\\r\\n\n```\n\n해석하면:\n\n- `*3`: 3개 요소를 가진 배열\n- `$7`: 7바이트 문자열 → `PUBLISH`\n- `$11`: 11바이트 문자열 → `room.events`\n- `$152`: 152바이트 문자열 → JSON 메시지\n\nLettuce 내부 코드로 보면 다음과 같다\n\n```java\n// Lettuce 내부\npublic Long publish(byte[] channel, byte[] message) {\n    // RESP 프로토콜로 인코딩\n    CommandArgs<byte[], byte[]> args = new CommandArgs<>(codec)\n        .addKey(channel)   // room.events\n        .addValue(message); // JSON 메시지\n    \n    Command<byte[], byte[], Long> command = commandBuilder.publish(args);\n    \n    // Netty를 통해 비동기 전송\n    return dispatch(command);\n}\n```\n\nLettuce는 Netty의 `ByteBuf`에 RESP 형식의 바이트 데이터를 작성한 뒤, 비동기로 전송한다.\n\n#### 5. Netty의 비동기 네트워크 통신\n\nNetty는 Java NIO를 기반으로 한 비동기 네트워크 프레임워크다. Lettuce가 Netty를 사용하는 이유는 **논블로킹 I/O**와 **커넥션 재사용** 때문이다.\n\n```java\n// Netty 내부 (간략화)\nChannel channel = getChannel(); // Redis 서버와의 TCP 연결\n\n// ByteBuf에 RESP 데이터 작성\nByteBuf buffer = channel.alloc().buffer();\nbuffer.writeBytes(respProtocolBytes);\n\n// 비동기 전송\nChannelFuture future = channel.writeAndFlush(buffer);\n\n// 결과를 기다리지 않고 즉시 리턴 (Non-blocking)\nfuture.addListener(writeCompleteListener);\n```\n\nNetty는 내부적으로 **이벤트 루프(Event Loop)** 스레드를 사용해 여러 커넥션의 I/O를 효율적으로 처리한다. 하나의 스레드가 수천 개의 커넥션을 동시에 관리할 수 있어, 커넥션마다 스레드를 생성하는 전통적인 방식보다 훨씬 효율적이다.\n\n최종적으로 TCP 소켓을 통해 Redis 서버로 데이터가 전송된다.\n\n#### 6. Redis 서버의 메시지 처리\n\nRedis 서버는 **단일 스레드 이벤트 루프** 구조로 동작한다. 멀티스레딩 없이 어떻게 수천 개의 동시 연결을 처리할 수 있을까? 바로 **I/O 멀티플렉싱(I/O Multiplexing)** 기술 덕분이다.\n\n**I/O 멀티플렉싱이란?**\n\n전통적인 블로킹 I/O 방식에서는 `read()`를 호출하면 데이터가 도착할 때까지 스레드가 대기한다. 1000개의 클라이언트를 처리하려면 1000개의 스레드가 필요하고, 이는 컨텍스트 스위칭 비용으로 성능 저하를 일으킨다.\n\nI/O 멀티플렉싱은 **하나의 스레드가 여러 소켓을 동시에 감시**할 수 있게 해준다. Linux의 `epoll`, BSD/macOS의 `kqueue` 같은 시스템 콜이 이 기능을 제공한다.\n\n동작 방식:\n\n1. 수백~수천 개의 소켓을 `epoll`에 등록\n2. `epoll_wait()` 호출 → 이벤트(데이터 도착, 쓰기 가능 등) 발생 시까지 대기\n3. 이벤트 발생 시 어떤 소켓에서 이벤트가 발생했는지 반환\n4. 해당 소켓에서만 `read()` 또는 `write()` 수행\n5. 다시 `epoll_wait()`로 돌아가 다음 이벤트 대기\n\nRedis는 이 방식으로 단일 스레드로도 초당 수만 건의 요청을 처리한다.\n\n```c\n// Redis 이벤트 루프 (간략화)\nvoid aeMain(aeEventLoop *eventLoop) {\n    while (!eventLoop->stop) {\n        // epoll_wait() 호출 - 이벤트 발생 시까지 대기\n        numevents = aeApiPoll(eventLoop, tvp);\n        \n        for (int j = 0; j < numevents; j++) {\n            aeFileEvent *fe = &eventLoop->events[eventLoop->fired[j].fd];\n            \n            // 읽기 이벤트 (클라이언트가 데이터 전송)\n            if (fe->mask & AE_READABLE) {\n                fe->rfileProc(eventLoop, fd, fe->clientData, mask);\n            }\n            \n            // 쓰기 이벤트 (클라이언트에게 전송 가능)\n            if (fe->mask & AE_WRITABLE) {\n                fe->wfileProc(eventLoop, fd, fe->clientData, mask);\n            }\n        }\n    }\n}\n```\n\n클라이언트가 `PUBLISH` 명령을 보내면:\n\n```c\n// 1. 소켓에서 데이터 읽기 (간략화)\nvoid readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) {\n    client *c = (client*) privdata;\n    \n    // TCP 소켓에서 데이터 읽기\n    nread = read(fd, c->querybuf + qblen, readlen);\n    \n    // RESP 프로토콜 파싱\n    processInputBuffer(c);\n}\n\n// 2. PUBLISH 명령 실행 (간략화)\nvoid publishCommand(client *c) {\n    // c->argv[1] = \"room.events\" (채널명)\n    // c->argv[2] = JSON 메시지\n    \n    int receivers = 0;\n    \n    // pubsub_channels 해시테이블에서 채널 조회 (O(1))\n    dictEntry *de = dictFind(server.pubsub_channels, c->argv[1]);\n    \n    if (de) {\n        list *subscribers = dictGetVal(de);\n        \n        // 구독자 리스트 순회 (O(N), N=구독자 수)\n        listNode *ln;\n        listIter li;\n        listRewind(subscribers, &li);\n        \n        while ((ln = listNext(&li)) != NULL) {\n            client *subscriber = ln->value;\n            \n            // 각 구독자의 output buffer에 메시지 추가\n            addReplyPubsubMessage(subscriber, c->argv[1], c->argv[2]);\n            receivers++;\n        }\n    }\n    \n    // 발행자에게 응답: 몇 명에게 전송했는지\n    addReplyLongLong(c, receivers);\n}\n\n// 3. output buffer의 데이터를 실제로 전송 (간략화)\nvoid writeToClient(int fd, client *c, int handler_installed) {\n    while (clientHasPendingReplies(c)) {\n        // write() 시스템콜로 TCP 소켓에 전송\n        nwritten = write(fd, c->buf + c->sentlen, c->bufpos - c->sentlen);\n        \n        if (nwritten <= 0) break;\n        \n        c->sentlen += nwritten;\n    }\n}\n```\n\n이 과정에서 Redis는 메시지를 저장하지 않는다. 받자마자 바로 구독자들의 output buffer에 추가하고 전송한다. 이것이 **Fire-and-Forget** 방식이며, 실시간성을 극대화하는 설계다.\n\n#### 7. 구독자 측 수신 및 처리\n\n각 서버 인스턴스의 Lettuce 클라이언트가 메시지를 수신하면, RESP 프로토콜을 디코딩해 Spring의 `MessageListener`로 전달한다.\n\n```java\n@Override\npublic void onMessage(Message message, byte[] pattern) {\n    // 1. 메시지 body를 String으로 변환\n    String body = new String(message.getBody());\n    \n    // 2. eventType 추출\n    RoomEventType eventType = extractEventType(body); // PLAYER_READY\n    \n    // 3. JSON을 Java 객체로 역직렬화\n    PlayerReadyEvent event = objectMapper.readValue(body, PlayerReadyEvent.class);\n    \n    // 4. 핸들러로 위임\n    RoomEventHandler handler = handlerFactory.getHandler(eventType);\n    handler.handle(event);\n}\n```\n\n#### 8. 비즈니스 로직 실행\n\n```java\n@Override\npublic void handle(PlayerReadyEvent event) {\n    // 로컬 메모리에서 Room 조회 (네트워크 통신 없음)\n    Room room = roomQueryService.getByJoinCode(new JoinCode(event.joinCode()));\n    \n    // Player 찾기\n    Player player = room.findPlayer(new PlayerName(event.playerName()));\n    \n    // 상태 변경 (로컬 메모리)\n    player.updateReadyState(event.isReady());\n    \n    // 로컬 캐시 업데이트\n    roomCommandService.save(room);\n    \n    // WebSocket 브로드캐스팅\n    List<PlayerResponse> responses = room.getPlayers().stream()\n        .map(PlayerResponse::from)\n        .toList();\n    \n    messagingTemplate.convertAndSend(\n        \"/topic/room/\" + event.joinCode(),\n        WebSocketResponse.success(responses)\n    );\n}\n```\n\n여기서 핵심은 **데이터 조회가 로컬 메모리에서 즉시 처리**된다는 점이다. 네트워크 통신도, 직렬화/역직렬화도 필요 없다. Redis는 오직 변경 이벤트를 전파하는 메시지 브로커 역할만 수행한다.\n\n#### 9. 최종 클라이언트 수신\n\nSpring WebSocket이 STOMP 프로토콜로 메시지를 인코딩해 해당 방을 구독 중인 모든 WebSocket 세션에 전송한다. 각 브라우저는 메시지를 수신해 UI를 업데이트한다.\n\n\n```javascript\nstompClient.subscribe('/topic/room/ABC123', (message) => {\n    const response = JSON.parse(message.body);\n    // {success: true, data: [{playerName: \"홍길동\", isReady: true}, ...]}\n    \n    updatePlayerList(response.data);\n});\n```\n\n### 주요 특징과 트레이드오프\n\n#### Fire-and-Forget 방식\n\nRedis Pub/Sub은 메시지를 저장하지 않는다. 구독자가 없거나 네트워크 문제로 수신하지 못하면 메시지는 유실된다. 이는 실시간성을 위한 설계 선택이다. 메시지 저장 없이 즉시 전달만 하기 때문에 레이턴시가 최소화된다.\n\n커피빵의 경우 대부분의 이벤트가 일시적 상태 변경(Ready 상태, 메뉴 선택 등)이기 때문에 이런 특성이 오히려 적합했다. 메시지 유실을 무조건 막아야하거나 Race Condition이 발생할 수 있는 상황을 대비해서 일정부분은 Redis Stream을 적용했다.\n\n#### 네트워크 레이턴시\n\n전체 메시지 전파 과정에서 발생하는 네트워크 구간은 다음과 같다:\n\n1. 발행 서버 → Redis (TCP 왕복)\n2. Redis → 구독 서버들 (TCP 왕복 × N)\n\n동일 리전 내에서는 대략 1~5ms 정도의 지연이 발생한다. 이는 사람이 체감하기 어려운 수준이다.\n#### 언어 경계를 넘는 통신\n\n흥미로운 점은 이 전체 과정에서 **여러 언어와 프로토콜의 경계를 넘는다**는 것이다.\n\n- Java 애플리케이션에서 이벤트 발행\n- Lettuce(Java)가 RESP 프로토콜로 변환\n- 네트워크를 타고 Redis(C)로 전달\n- Redis가 C 레벨의 해시테이블과 링크드리스트로 처리\n- 다시 네트워크를 타고 구독자의 Lettuce(Java)로 수신\n- Java 객체로 복원돼 비즈니스 로직 실행\n\n각 언어는 서로 다른 메모리 관리 방식과 자료구조를 사용하지만, RESP 프로토콜이라는 공통 인터페이스를 통해 안정적으로 통신한다. 이런 추상화 덕분에 개발자는 Redis 내부 구현을 몰라도 Pub/Sub을 사용할 수 있다.\n\n다만 이런 경계를 넘을 때마다 직렬화/역직렬화와 네트워크 비용이 발생한다는 점은 항상 염두에 둬야 한다. 그럼에도 불구하고 이 방식을 선택한 이유는, **읽기 작업은 로컬 메모리에서 즉시 처리되고, 쓰기 작업만 네트워크를 타기 때문**이다. 결과적으로 성능 저하 없이 분산 환경 동기화를 달성할 수 있었다.\n\n## 참고자료\n\n### Redis 공식 자료\n\n- [Redis Pub/Sub](https://redis.io/docs/latest/develop/pubsub/) - Pub/Sub 공식 가이드\n- [RESP Protocol Specification](https://redis.io/docs/latest/develop/reference/protocol-spec/) - RESP 프로토콜 공식 명세\n- [Redis GitHub - pubsub.c](https://github.com/redis/redis/blob/unstable/src/pubsub.c) - Pub/Sub 구현 소스코드\n\n### Redis 내부 구조 분석\n\n- [Redis Pub/Sub under the hood](https://jameshfisher.com/2017/03/01/redis-pubsub-under-the-hood/) - Redis Pub/Sub 소스코드 상세 분석 (Pusher 엔지니어 작성)\n\n\n\n\n"},{"excerpt":"단일 인스턴스 목표 TPS 커피빵은 게임 기반 실시간 서비스이기 때문에 유저 간의 양방향 통신을 위해 웹소켓 통신을 이용하고 있다. 웹소켓 통신의 경우 서버가 각 클라이언트의 구독 상태를 세션별로 메모리에서 관리하고 있는데, REST API와는 다르게 연결이 지속적으로 유지되면서 이벤트 브로드캐스팅과 메시지 라우팅을 처리해야 한다. 이 과정에서 동시 접속…","fields":{"slug":"/infra_design/"},"frontmatter":{"date":"2025년 10월 13일 09:10","title":"단일 서버에서 분산 환경으로: 확장성 있는 아키텍처로의 전환","tags":["우아한테크코스","ZZOL"]},"rawMarkdownBody":"## 단일 인스턴스 목표 TPS\n커피빵은 게임 기반 실시간 서비스이기 때문에 유저 간의 양방향 통신을 위해 웹소켓 통신을 이용하고 있다. 웹소켓 통신의 경우 서버가 각 클라이언트의 구독 상태를 세션별로 메모리에서 관리하고 있는데, REST API와는 다르게 연결이 지속적으로 유지되면서 이벤트 브로드캐스팅과 메시지 라우팅을 처리해야 한다. 이 과정에서 동시 접속자 수가 증가하면 메시지 처리 대기열이 쌓이게 되고, 결과적으로 응답 지연이 발생하는 메시지 처리 병목 현상이 생기게 된다.\n\n단일 인스턴스로 운영하던 서비스 초반, 하나의 EC2(AWS t4g.small)로 버틸 수 있는 처리량을 측정하기 위해 부하 테스트를 진행했다. 웹소켓 요청 처리(Inbound)와 응답 전송(Outbound) 각각의 스레드 풀 크기와 TPS를 점진적으로 증가시키며 테스트했고, 컨텍스트 스위칭 오버헤드로 인한 레이턴시 증가가 발생하기 직전 시점을 기준으로 아래와 같은 최적값을 도출했다.\n#### Inbound 스레드 풀\n- 코어, 최대 스레드 32개\n- 큐 크기 2048\n- TPS 373 기준 P99 레이턴시 113ms\n#### Outbound 스레드 풀\n- 코어, 최대 스레드 16개\n- 큐 크기 4096\n- TPS 2800 기준 P99 레이턴시 92ms\n\n이런 설정값을 유지했을 때 250명 정도가 동시 접속 가능한데, 더 많은 유저들이 몰리게 되면 어떻게 될까?\n\n## 분산환경 구축 옵션\n예산이 제한된 상황에서는 스케일 업(Scale-up)보다 스케일 아웃(Scale-out)을 우선 고려하게 된다. 그런데 여기서 추가적인 문제가 발생한다. 현재 이 서비스는 게임 세션 데이터를 DB가 아닌 **인메모리(in-memory)** 방식으로만 관리하고 있다. 즉, 같은 게임 세션에 참여하는 모든 유저는 **동일한 인스턴스에 웹소켓 연결**을 유지해야 한다.\n\n만약 아무 고려 없이 단순 스케일 아웃을 진행하면, 같은 게임 세션의 유저들이 서로 다른 인스턴스에 분산 연결될 수 있고, 이 경우 각 인스턴스가 서로 다른 게임 상태를 가지게 되어 **게임 동기화가 깨지는 문제**가 발생한다.\n\n이를 해결하기 위해 고려할 수 있는 방안은 다음과 같다.\n\n1. **MySQL을 활용한 실시간 상태 동기화**: 모든 게임 상태 변경을 즉시 MySQL에 저장하고, 각 인스턴스가 DB를 조회하며 게임 진행\n2. **Redis를 원격 캐시로 사용**: Redis를 공유 세션 저장소로 활용하여 모든 인스턴스가 동일한 게임 상태 참조\n3. **로컬 캐시 + Redis Pub/Sub 동기화**: 각 인스턴스가 로컬 메모리에 캐시를 유지하되, Redis Pub/Sub을 통해 상태 변경 이벤트를 브로드캐스팅하여 동기화\n\n각 방안의 장단점을 비교하면 다음과 같다.\n\n#### 1. MySQL을 활용한 실시간 상태 동기화\n\n**장점**\n- 데이터 영속성 보장. 서버 재시작 시에도 게임 상태 복구 가능\n- 별도 학습 곡선 없이 해결 가능\n- 트랜잭션 지원으로 데이터 정합성 확보\n\n**단점**\n- 매 액션마다 **디스크 I/O 발생**으로 레이턴시 급증. 실시간 게임에선 치명적\n- 동시 접속자 증가 시 DB 커넥션 풀 고갈 및 **병목 발생**\n- DB 부하 분산을 위해 결국 Read Replica나 샤딩 필요 → 복잡도 상승\n\n#### 2. Redis를 원격 캐시로 사용\n\n**장점**\n- 디스크 I/O 없이 메모리에서 바로 조회하므로 MySQL 대비 빠름\n- 모든 인스턴스가 단일 Redis를 바라보므로 **상태 일관성 자동 보장**\n- 세션 데이터 TTL 설정으로 자동 만료 처리 가능\n\n**단점**\n- 모든 요청이 네트워크를 타므로 로컬 메모리 대비 **네트워크 레이턴시 존재**\n- **매 요청마다 직렬화/역직렬화 오버헤드 발생**. 특히 복잡한 객체 구조일수록 성능 저하 심각\n- Redis 장애 시 전체 서비스 마비 → **SPOF(Single Point of Failure)** 위험\n- Redis Cluster 구성 시 추가 비용 및 운영 복잡도 증가\n\n#### 3. 로컬 캐시 + Redis Pub/Sub 동기화\n\n**장점**\n- 읽기는 로컬 메모리에서 처리 → **가장 빠른 응답속도**. 네트워크 통신 및 직렬화/역직렬화 불필요\n- Redis는 동기화 메시지 전파 용도로만 사용하므로 부하 최소화\n- Redis 일시 장애 시에도 로컬 캐시로 서비스 지속 가능\n\n**단점**\n- Pub/Sub 메시지 전파 지연으로 **일시적 데이터 불일치(Eventual Consistency)** 발생 가능\n- 구현 복잡도 높음. 캐시 무효화(invalidation) 로직 정교하게 설계 필요\n- 메시지 유실 시 동기화 깨질 위험 존재\n\n### Redis를 원격 캐시로 사용\n\n게임 특성상 유저 간 인터랙션이 빈번하게 발생하는데, 이를 MySQL 같은 RDBMS로 처리하기엔 레이턴시 측면에서 무리가 있었다. 또한 팀 내에서 Redis에 대한 사전 지식이 없어서, 학습 목적도 겸해 Redis 도입을 결정했다.\n\n2번과 3번 옵션 중 무엇을 선택할지 고민하다가, **직접 구현해서 성능을 비교**해보기로 하고 2번 옵션부터 적용했다.\n\n#### 동작 방식\n\n모든 게임 세션 데이터를 **중앙 집중식 Redis**에 저장하고, 각 서버 인스턴스는 로컬 메모리에 데이터를 보관하지 않는 방식이다. 대신 게임 로직 실행 시 매번 Redis에서 데이터를 조회하고 수정한다.\n\n#### 처리 흐름 예시\n\n```\n1. 유저 A가 \"카드 1번\" 선택 액션 전송\n2. 서버 1이 Redis에서 게임 세션 데이터 조회 후 역직렬화 → Java 객체 변환\n3. 비즈니스 로직 처리 (카드 효과 적용, 게임 상태 업데이트 등)\n4. 변경된 객체를 직렬화 → Redis에 저장\n5. 모든 서버 인스턴스가 변경된 Redis 데이터를 조회 및 역직렬화 후 연결된 유저들에게 브로드캐스팅\n```\n\n#### 문제점\n\n이 방식의 가장 큰 문제는 **직렬화/역직렬화가 빈번하게 발생**한다는 점이다. 게임 로직 실행 중 매번 Redis를 거쳐야 하므로, 다음과 같은 오버헤드가 발생한다:\n\n- **읽기 작업**: Redis 조회 → 역직렬화 → 비즈니스 로직 실행\n- **쓰기 작업**: Redis 조회 → 비즈니스 로직 실행 → 직렬화 → Redis 저장\n\n특히 도메인 객체가 복잡할수록(중첩된 객체, 컬렉션 등) 직렬화 비용이 급격히 증가한다. 실제로 게임 세션 객체는 플레이어 리스트, 선택된 메뉴, 미니게임 상태 등 여러 계층의 데이터를 포함하고 있어, 한 번의 직렬화/역직렬화에 수 밀리초가 소요됐다.\n\n모든 구현을 완료하고 로컬 환경에서 약 300개의 테스트를 실행한 결과, **기존 인메모리 방식 대비 2배 이상의 실행 시간**이 소요되는 것을 확인했다. 실시간 게임에서 이 정도 성능 저하는 유저 경험에 직접적인 영향을 미치는 치명적인 문제였다.\n\n또한 이 구조는 **Redis에 과도한 부하를 가한다**는 문제도 있다. 모든 게임 로직이 Redis를 거쳐야 하므로, 동시 접속자가 증가하면 Redis가 애플리케이션 서버보다 먼저 병목이 될 가능성이 높다. \n\n### 로컬 캐시 + Redis Pub/Sub 동기화\n결국 우리는 3번으로 구현 방식을 바꿨다.\n\n#### 동작 방식\n\n각 서버 인스턴스가 게임 세션 데이터를 **로컬 메모리(인메모리 캐시)에 보관**하고, 상태 변경이 발생하면 **Redis Pub/Sub을 통해 다른 인스턴스들에게 변경 이벤트를 브로드캐스팅**하는 방식이다. 각 인스턴스는 메시지를 수신하면 자신의 로컬 캐시를 업데이트한다.\n\n#### 처리 흐름 예시\n\n```\n1. 유저 A가 \"카드 1번\" 선택 액션 전송 (서버 1에 연결)\n2. 서버 1이 로컬 메모리에서 게임 세션 데이터 조회 (역직렬화 불필요)\n3. 비즈니스 로직 처리 (카드 효과 적용, 게임 상태 업데이트)\n4. 서버 1이 변경 이벤트를 Redis Pub/Sub으로 발행 (Publish)\n5. 같은 게임 세션을 구독(Subscribe)하고 있는 서버 2, 3이 메시지 수신\n6. 각 서버가 자신의 로컬 캐시 업데이트 후 연결된 유저들에게 브로드캐스팅\n```\n\n#### 2번 방식과의 차이점\n\n가장 큰 차이는 **읽기 작업이 로컬 메모리에서 처리**된다는 점이다.\n\n- 2번 방식: 매번 네트워크 통신 + 직렬화/역직렬화 필요\n- 3번 방식: 읽기는 로컬 메모리에서 즉시 처리, 쓰기 시에만 Pub/Sub 메시지 발행\n\n2번 방식은 게임 상태를 읽을 때도, 쓸 때도 항상 Redis를 거쳐야 한다. 반면 3번 방식은 **데이터가 이미 로컬에 있기 때문에** 비즈니스 로직 실행 중 발생하는 모든 읽기 작업이 네트워크 없이 바로 처리된다.\n\n#### 성능 개선 결과\n\n동일한 300개 테스트 실행 결과, **기존 인메모리 단일 인스턴스 방식과 거의 동일한 성능**을 확인했다. 이벤트 발행과 읽는 시점에서 직렬화/역직렬화가 필요했지만, 그 크기가 2번의 상황보다 훨씬 적기 때문에 오버헤드가 적었다.\n\n\n## 참고자료\n\n### Redis 공식 자료\n\n- [Redis Pub/Sub](https://redis.io/docs/latest/develop/pubsub/) - Pub/Sub 공식 가이드\n- [RESP Protocol Specification](https://redis.io/docs/latest/develop/reference/protocol-spec/) - RESP 프로토콜 공식 명세\n- [Redis GitHub - pubsub.c](https://github.com/redis/redis/blob/unstable/src/pubsub.c) - Pub/Sub 구현 소스코드\n"},{"excerpt":"스크린샷 2025-09-28 오후 2.45.24.png스크린샷 2025-09-28 오후 2.45.33.png 0. 문제 원인 가설 세우기 P95가 15배 증가했는데, CPU, Memory 사용량이 정상 범위, 그럼 DB 관련 문제이지 않을까? DB 커넥션 풀 고갈 테이블 락 or 행 락 경합 (업데이트와 조회가 동시에) N+1 문제 (커넥션 오래 점유) …","fields":{"slug":"/면접스터디_3주차/"},"frontmatter":{"date":"2025년 09월 28일 09:09","title":"지연의 원인을 찾아라","tags":null},"rawMarkdownBody":"\n\n![[스크린샷 2025-09-28 오후 2.45.24.png]]![[스크린샷 2025-09-28 오후 2.45.33.png]]\n## 0. 문제 원인 가설 세우기\nP95가 15배 증가했는데, CPU, Memory 사용량이 정상 범위, 그럼 DB 관련 문제이지 않을까?\n- DB 커넥션 풀 고갈\n- 테이블 락 or 행 락 경합 (업데이트와 조회가 동시에)\n- N+1 문제 (커넥션 오래 점유)\n- 복잡한 조회 쿼리 (인덱스 없음)\n\n## 1. 현재 상황에서 문제를 어떻게 해결할 수 있을까?\n### 1-1. 커넥션 풀 상태 진단\n```bash\n# 현재 커넥션 풀 상태\ncurl localhost:8080/actuator/metrics/hikaricp.connections.active\ncurl localhost:8080/actuator/metrics/hikaricp.connections.idle  \ncurl localhost:8080/actuator/metrics/hikaricp.connections.pending\n\n# 커넥션 획득 대기 시간\ncurl localhost:8080/actuator/metrics/hikaricp.connections.acquire\n```\n### 1-2. DB 락 상황 확인\nMySQL이 자체적으로 관리하는 메타데이터 저장소 infromation_schema가 있음\n```sql\nSELECT \n    r.trx_id waiting_trx_id,           -- 대기 중인 트랜잭션 ID\n    r.trx_mysql_thread_id waiting_thread,  -- 대기 중인 스레드 ID\n    SUBSTRING(r.trx_query, 1, 100) waiting_query,  -- 대기 중인 쿼리\n    b.trx_id blocking_trx_id,          -- 블로킹하는 트랜잭션 ID  \n    b.trx_mysql_thread_id blocking_thread,  -- 블로킹하는 스레드 ID\n    SUBSTRING(b.trx_query, 1, 100) blocking_query,  -- 블로킹하는 쿼리\n    w.blocking_lock_id,\n    w.requesting_lock_id\nFROM information_schema.innodb_lock_waits w    -- 락 대기 정보\nINNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id\nINNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;\n```\n예시 결과:\n```\nwaiting_trx_id | waiting_query              | blocking_trx_id | blocking_query\n421036         | SELECT * FROM sales WHERE  | 421035          | UPDATE sales SET status=\n421037         | SELECT * FROM sales WHERE  | 421035          | UPDATE sales SET status=\n421038         | SELECT * FROM sales WHERE  | 421035          | UPDATE sales SET status=\n```\n- 트랜잭션 421035가 `UPDATE sales SET status=...` 실행 중\n- 트랜잭션 421036, 421037, 421038이 모두 대기\n- **1명이 3명을 막고 있는 상황**\n### 1-3. 쿼리 성능 분석\n슬로우 쿼리 확인:\n```sql\n-- 최근 1시간 슬로우 쿼리\nSELECT start_time, query_time, lock_time, rows_sent, rows_examined,\n       SUBSTRING(sql_text, 1, 200) as sql_preview\nFROM mysql.slow_log \nWHERE start_time > DATE_SUB(NOW(), INTERVAL 1 HOUR)\nORDER BY query_time DESC\nLIMIT 10;\n```\n실시간 프로세스 확인:\n```sql\nSELECT id, user, host, db, command, time, state,\n       SUBSTRING(info, 1, 100) as query_preview\nFROM information_schema.processlist \nWHERE command != 'Sleep' AND time > 2\nORDER BY time DESC;\n```\n\n## 2. 시스템 상태와 지표를 종합해볼 때, 추정되는 문제 원인은?\n### 도메인 분석: 쇼핑몰 판매자 대시보드\n#### 판매자 대시보드\n- 실시간 판매량, 매출액\n- 상품별 판매 현황\n- 주문 처리 상태\n- 리뷰/평점 통계\n- 정산 관련 데이터\n#### 조회 많은 시간\n- 오전 9~11시: 판매자들 출근해서 전날 매출 확인\n- 저녁 6~8시: 하루 마감 전 최종 확인\n- 특정 이벤트 시: 타임세일 등\n### 유력 원인: 대용량 집계 쿼리의 실시간 계산\n```bash\n판매자 100명이 동시에 대시보드 조회\n↓\n각자 n개씩 복잡한 집계 쿼리 실행  \n↓\n총 n * 100개의 무거운 쿼리가 동시 실행\n↓\nDB 리소스 경합 → 모든 쿼리 느려짐\n↓\nP95 15배 증가\n```\n- 오늘 매출 집계, 상품별 판매량 Top 10, 미처리 주문 수 등 실시간 데이터를 조회하는데, 이 과정에서 복잡한 Join이 생김. \n- 인덱스가 없으면 풀 스캔을 해야함\n- 복잡한 쿼리를 요구하는 대시보드 조회 요청이 많아지면 커넥션 풀까지 고갈\n- 근데 timeout이라면 로그가 남아야하는데 안남음.\n- 커넥션 반환이 늦어지면서 톰캣이 새로운 요청을 못받아서 그 밖에서 500에러가 터짐\n\n## 3. 서비스 안정성을 위해 즉각적으로 취할 수 있는 대응 방법은?\n### 3-1. 커넥션 풀 확장 & CPU 스펙 향상\nmaxinum-pool-size 증가\nconnection-timeout 증가\nvalidation-timesout 증가\n### 3-2. 쿼리 최적화\n핵심 인덱스 생성\n## 4. 문제 해결 및 재발 방지를 위한 근본적인 개선책은?\n### 4-1. Primary-Replica 구조로 DB부하 분산\n### 4-2. 로컬 or Redis 캐시 도입\n인기 상품이 있을 경우, 구매가 자주일어나서 매번 캐시를 초기화하는 건 성능 저하 유발\n성능을 위해 5분, 10분 or 하루단위로 새벽에 캐싱 도입\n## 4-3. 집계 테이블 도입: 미리 계산해두기\n### 근본적인 문제는 실시간 계산\n판매자가 대시보드를 조회할 때마다 아래와 같은 쿼리가 항목별로 발생함\n```sql\n-- 오늘 매출 계산 (실시간)\nSELECT \n    COUNT(*) as order_count,\n    SUM(oi.quantity * oi.price) as total_amount\nFROM orders o\nJOIN order_items oi ON o.id = oi.order_id  \nJOIN products p ON oi.product_id = p.id\nWHERE p.seller_id = 12345 \n  AND o.created_at >= '2024-01-15 00:00:00'\n  AND o.created_at < '2024-01-16 00:00:00'\n  AND o.status IN ('PAID', 'SHIPPED', 'DELIVERED');\n\n-- 데이터량: orders 100만건 × order_items 300만건 × products 50만건\n-- 실행시간: 5-8초\n-- 결과: order_count=157, total_amount=2,340,000\n```\n- **같은 계산을 반복**: 판매자가 새로고침할 때마다 똑같은 집계 연산\n- **데이터량은 계속 증가**: 주문 쌓일수록 계산 시간 늘어남\n- **동시 요청시 부하 급증**: 100명이 동시 조회하면 100번 계산\n\n### 집계 테이블 모습\n```sql\n-- 집계 테이블 (미리 계산된 결과 저장)\nCREATE TABLE seller_daily_stats (\n    seller_id BIGINT,\n    stat_date DATE,\n    order_count INT,           -- 미리 계산된 주문 수\n    total_amount DECIMAL(15,2), -- 미리 계산된 총액\n    avg_amount DECIMAL(10,2),   -- 미리 계산된 평균\n    updated_at TIMESTAMP,\n    PRIMARY KEY (seller_id, stat_date)\n);\n\n-- 데이터 예시\nINSERT INTO seller_daily_stats VALUES \n(12345, '2024-01-15', 157, 2340000.00, 14904.46, NOW());\n```\n- 동시 요청 부하 해결\n- 커넥션 점유 시간 단축\n### 집계 테이블 업데이트 전략\n- 실시간 업데이트\n- 배치 업데이트\n\n---\n"},{"excerpt":"커피빵(CoffeeShout) 서비스의 WebSocket 스레드풀을 부하 테스트 기반으로 튜닝했다. \"스레드 몇 개가 적절한가?\"라는 질문에 감이 아닌 데이터로 답을 내리는 과정을 기록한다. 왜 스레드풀 튜닝이 필요했는가 커피빵은 실시간 멀티플레이어 게임 서비스다. 여러 명이 방에 모여서 미니게임을 하고, 룰렛으로 당첨자를 뽑는다. 모든 게임 진행이 We…","fields":{"slug":"/thread_pool_tuning/"},"frontmatter":{"date":"2025년 09월 27일 11:09","title":"스레드풀, 감으로 잡지 마세요: 부하 테스트로 증명하는 최적의 설정값","tags":["우아한테크코스","ZZOL"]},"rawMarkdownBody":"커피빵(CoffeeShout) 서비스의 WebSocket 스레드풀을 부하 테스트 기반으로 튜닝했다. \"스레드 몇 개가 적절한가?\"라는 질문에 감이 아닌 데이터로 답을 내리는 과정을 기록한다.\n\n## 왜 스레드풀 튜닝이 필요했는가\n\n커피빵은 실시간 멀티플레이어 게임 서비스다. 여러 명이 방에 모여서 미니게임을 하고, 룰렛으로 당첨자를 뽑는다. 모든 게임 진행이 WebSocket으로 이뤄진다.\n\nSpring의 WebSocket(STOMP) 아키텍처에서는 메시지 처리를 위한 스레드풀이 존재한다. 클라이언트에서 서버로 오는 메시지를 처리하는 **inbound 채널**, 서버에서 클라이언트로 보내는 메시지를 처리하는 **outbound 채널**, 그리고 WebSocket 연결 자체를 관리하는 **Tomcat 스레드풀**이 있다.\n\nSpring Boot의 기본값은 inbound/outbound 모두 1개 스레드다. 개발 환경에서는 문제없지만, 실제 서비스에서 250명이 동시 접속하면 얘기가 다르다. 1개 스레드로 수백 TPS의 메시지를 처리하면 큐에 메시지가 쌓이고, 응답 지연이 발생한다. 게임 서비스에서 응답 지연은 곧 \"렉\"이고, 렉은 곧 이탈이다.\n\n그렇다고 스레드를 무조건 많이 잡으면 되는 것도 아니다. t4g.small 인스턴스(vCPU 2개, 메모리 2GB)에서 돌리고 있으니 리소스 제약이 있다. 스레드가 CPU 코어 수를 크게 초과하면 CPU 경합, 캐시 무효화, OS 스케줄러 오버헤드 등이 누적되면서 오히려 성능이 떨어진다. \"어디까지 늘려야 빨라지고, 어디서부터 역효과가 나는가\"를 찾아야 했다.\n\n## 목표 수치 설정\n\n튜닝 전에 목표부터 정했다. 실제 서비스 운영 데이터를 기준으로 잡았다.\n\n|항목|목표값|\n|---|---|\n|동시 접속자|250명|\n|Inbound TPS|325 (250명 × 1.3 req/s)|\n|Outbound TPS|1,600 (250명 × 6.4 res/s)|\n|평균 응답시간|40ms 이내|\n|최대 응답시간|100ms 이내|\n\n사용자 1명 기준으로, 평균 초당 0.4회 요청 / 0.7회 응답이 발생하고, 최대 초당 1.3회 요청 / 6.4회 응답이 발생한다. 레이싱 게임 중에는 플레이어 위치가 프레임마다 업데이트되기 때문에 응답 TPS가 요청 TPS보다 훨씬 높다. 여기에 방 참여자가 최대 9명이니까, 1건의 요청에 최대 9건의 응답(브로드캐스트)이 발생하는 구조다.\n\n## 테스트 환경\n\n- 인스턴스: AWS t4g.small (vCPU 2, RAM 2GB)\n- Redis: AWS ElastiCache t4g.micro\n- 부하 테스트 도구: k6\n\n## Inbound 스레드풀 튜닝\n\nInbound 채널은 클라이언트 → 서버 메시지를 처리한다. 게임 중 플레이어 액션, 방 참여 요청 등이 여기서 처리된다.\n\n스레드 수를 2, 4, 8, 16, 32, 64개로 올려가면서 TPS 171, 373, 513에서 최대 응답시간을 측정했다.\n\n### Inbound 최대 응답시간 (ms)\n\n|TPS|스레드 2|스레드 4|스레드 8|스레드 16|스레드 32|스레드 64|\n|---|---|---|---|---|---|---|\n|171|285|113|22|23|22|28|\n|373|7,780|1,959|235|151|**113**|193|\n|513|15,632|7,250|3,757|2,550|**1,747**|3,883|\n\n목표 TPS 325에 가장 가까운 373 기준으로 보면, 스레드 2개에서는 7,780ms로 사실상 서비스 불가 수준이었다. 8개로 올리면 235ms, 32개에서 113ms까지 떨어진다.\n\n여기서 주목할 점은 **64개부터 오히려 느려진다**는 것이다. TPS 373에서 32개일 때 113ms인데, 64개에서는 193ms로 올라간다. TPS 513에서도 32개(1,747ms) 대비 64개(3,883ms)로 2배 이상 느려진다.\n\nvCPU가 2개인 인스턴스에서 64개 스레드를 돌리면, 스레드 대 코어 비율이 32:1이 된다. 실제 동시에 실행 가능한 건 2개뿐인데 64개 스레드가 CPU를 잡으려고 경쟁한다. 이때 발생하는 오버헤드가 복합적으로 작용한다. CPU 경합으로 각 스레드의 대기 시간이 길어지고, 스레드가 교체될 때마다 CPU 캐시가 무효화되면서 캐시 미스가 늘어나고, OS 스케줄러가 64개 스레드를 관리하는 비용도 커진다. 이 오버헤드의 합이 스레드를 늘려서 얻는 병렬 처리 이점을 넘어서는 지점이 바로 32 → 64 구간이었다.\n\n**결론: inbound 스레드 32개.** 8 → 16 → 32까지는 성능이 개선되지만, 64부터는 역효과다. 목표 TPS(325) 기준 최대 응답시간 113ms로, 100ms 목표에 근접한다.\n\n## Outbound 스레드풀 튜닝\n\nOutbound 채널은 서버 → 클라이언트 메시지를 처리한다. 브로드캐스트가 주 용도라 inbound보다 TPS가 높다.\n\n스레드 수를 4, 8, 16, 32개로 올려가면서 TPS 290, 700, 1400, 2800, 4200에서 측정했다.\n\n### Outbound 최대 응답시간 (ms)\n\n|TPS|스레드 4|스레드 8|스레드 16|스레드 32|\n|---|---|---|---|---|\n|290|56|22|14|13|\n|700|69|71|19|22|\n|1,400|832|109|**96**|60|\n|2,800|1,505|182|**92**|185|\n|4,200|-|226|**109**|369|\n\n목표 TPS 1600에 가장 가까운 1400 기준으로 보면, 16개(96ms)와 32개(60ms) 모두 목표(100ms)를 충족한다. 하지만 TPS 2800에서 패턴이 바뀐다. 16개(92ms)가 32개(185ms)보다 빠르다. TPS 4200에서는 격차가 더 벌어진다. 16개(109ms) vs 32개(369ms).\n\ninbound와 같은 현상이다. 다만 outbound는 inbound보다 역전 지점이 낮다. inbound는 64개에서 역전이 발생했는데, outbound는 32개에서 이미 역전이 시작된다.\n\n이유를 추정하면, outbound 메시지는 주로 브로드캐스트라서 메시지 하나당 처리 시간이 짧다(직렬화 → 전송). 작업 하나의 처리 시간이 짧을수록 스레드 간 전환 빈도가 높아지고, 그만큼 CPU 경합과 캐시 무효화가 더 자주 발생한다. 같은 vCPU 2개 환경이라도, 작업 특성에 따라 최적 스레드 수가 달라지는 것이다.\n\n**결론: outbound 스레드 16개.** 목표 TPS(1600) 기준 100ms 이내를 충족하면서, 고부하(2800~4200 TPS)에서도 안정적이다.\n\n## Tomcat 스레드풀 및 커넥션 설정\n\nWebSocket 연결 수립은 HTTP 핸드셰이크로 시작되기 때문에 Tomcat 스레드풀의 영향을 받는다. Spike 테스트(10초간 집중 연결)로 한계를 확인했다.\n\n### 커넥션 Spike 테스트 (10초간 집중 연결)\n\n|초당 연결|총 연결 (10s)|최대 연결시간 (ms)|Tomcat 스레드|비고|\n|---|---|---|---|---|\n|100|1,000|14|12|안정|\n|150|1,500|22|14|안정|\n|200|2,000|18|21|안정|\n|300|3,000|151|156|지연 발생 시작|\n|400|4,000|638|200 (max)|1.4% 연결 실패|\n|500|5,000|1,015|200 (max)|19.2% 연결 실패|\n\n초당 200개 연결까지는 안정적이다. 300개부터 지연이 시작되고, 400개에서 톰캣 스레드가 최대(200)에 도달하면서 연결 실패가 발생한다.\n\n별도로 WebSocket 연결 + 구독(5개 topic) 테스트도 진행했다. 초당 10명씩 천천히 늘려서 총 동시 연결 수의 한계를 확인했더니, **약 4800개 연결에서 OOM이 발생**했다. t4g.small의 힙 메모리 한계에 도달한 것이다.\n\n이 데이터를 바탕으로 Tomcat 설정을 잡았다.\n\n```yaml\nserver:\n  tomcat:\n    threads:\n      max: 200\n      min-spare: 30\n    max-connections: 700\n    accept-count: 300\n```\n\n**max: 200**은 Spike 테스트에서 확인된 수용 가능한 최대치다. **min-spare: 30**은 cold-start 시 스레드 생성 병목을 방지하기 위해 설정했다. 최초 부하 테스트에서 min-spare가 10일 때, 갑작스러운 부하에 스레드 생성이 병목이 되는 현상이 있었다.\n\n**max-connections: 700**은 목표 동시 접속 250명에 여유분을 더한 값이다. WebSocket 연결 250개 + HTTPS API 요청 여분을 고려했다. 4800개에서 OOM이 터지니까, 그보다 훨씬 낮은 수준에서 제한을 걸어 메모리를 보호한다.\n\n## 게임 스레드풀\n\n레이싱 게임은 라운드마다 일정 간격으로 게임 상태를 업데이트하는 스케줄러가 있다. 이 스케줄러의 스레드풀도 설정이 필요했다.\n\n스레드 3개로 게임 100개, 200개를 동시에 실행해봤다. 결과는 둘 다 32.5초에 모든 라운드가 지연 없이 완료됐다. 게임 스케줄러의 작업은 \"상태 계산 → 메시지 발행\"으로 단순하고, 실제 메시지 전송은 outbound 스레드풀에서 처리하기 때문에 스케줄러 스레드가 많이 필요하지 않았다.\n\n**결론: 게임 스레드 3개 고정.** 200개 게임 동시 실행에도 지연이 없으니 충분하다.\n\n## 삽질: cold-start에서 응답이 느린 현상\n\n부하 테스트를 반복하면서 이상한 현상을 발견했다. 애플리케이션을 재시작한 직후 첫 번째 테스트에서 응답시간이 비정상적으로 느려지는 것이다. 기존 테스트에서 109ms가 나오던 것이 6,812ms로 뛰었다.\n\n처음에는 톰캣 스레드가 한꺼번에 200개까지 생성되면서 발생하는 비용이라고 생각했다. 하지만 min-spare를 10으로 설정한 이전 테스트에서도 스레드 생성이 문제가 되지 않았으니, 이건 원인이 아니었다.\n\n스레드 덤프를 떠서 확인해보니, 대부분의 스레드가 BLOCKED 상태였다. SockJS에서 세션 ID를 생성할 때 `SecureRandom`을 사용하는데, 초기 엔트로피가 부족하면 난수 생성에서 블로킹이 발생하는 것이었다. 이건 Tomcat에서도 잘 알려진 이슈로, JVM 옵션에서 `/dev/urandom`을 사용하도록 설정하거나 워밍업을 해주면 해결된다.\n\n## 최종 설정\n\n|구성 요소|스레드 수|큐 크기|비고|\n|---|---|---|---|\n|Inbound 채널|32|2,048|TPS 373 기준 113ms|\n|Outbound 채널|16|4,096|TPS 2800 기준 92ms|\n|Tomcat (min-spare / max)|30 / 200|300 (accept-count)|max-connections 700|\n|게임 스케줄러|3 (고정)|1,024|200개 게임 동시 실행 OK|\n\n## 핵심 포인트\n\n- **스레드는 많다고 좋은 게 아니다.** vCPU 2개 환경에서 inbound는 64개부터, outbound는 32개부터 오히려 느려졌다. 스레드 수가 코어 수를 크게 초과하면 CPU 경합, 캐시 무효화, 스케줄러 오버헤드가 누적되면서 병렬 처리 이점을 상쇄한다. 역전 지점을 찾아야 한다.\n- **inbound와 outbound의 최적 스레드 수는 다르다.** 같은 하드웨어에서도 작업 특성에 따라 결과가 달라진다. 처리 시간이 긴 작업(inbound)은 스레드를 더 늘려도 효과가 있고, 처리 시간이 짧은 작업(outbound)은 적은 스레드에서 더 효율적이다.\n- **목표 수치를 먼저 정하고 테스트해야 한다.** \"빨라질 때까지 늘린다\"가 아니라, 실제 트래픽 패턴에서 목표 응답시간을 정하고, 그 목표를 충족하는 최소 스레드 수를 찾는 게 맞다.\n- **커넥션 한계도 테스트해야 한다.** 스레드풀만 튜닝하면 안 된다. 메모리 한계(OOM), 연결 수 한계, Spike 상황까지 확인해야 운영에서 안전하다.\n- **cold-start 이슈를 간과하지 말아야 한다.** 반복 테스트에서는 안 보이는 문제가 최초 실행에서 터질 수 있다. 스레드 덤프를 떠서 원인을 정확히 파악해야 한다."},{"excerpt":"지난 회고: 우아한테크코스_7기_BE_레벨2_회고 레벨3도 끝났다. 가속도가 붙은 것처럼 시간이 점점 빨리 지나간다. 지난 8주간 내가 느꼈던 것들을 하나씩 톺아보자! 문제를 정의하고 요구사항을 파악하는 능력은 어떻게 기를까 레벨3 내내 머릿속에서 맴돈 질문이다. 아이디어를 내고, 팀원들을 설득하고, 기획을 세부화하고, 이를 실제로 구현하는 과정 전반에서…","fields":{"slug":"/우아한테크코스_7기_BE_레벨3_회고/"},"frontmatter":{"date":"2025년 08월 30일 09:08","title":"우아한테크코스 7기 BE 레벨3 회고","tags":["우아한테크코스","회고"]},"rawMarkdownBody":"지난 회고: [[우아한테크코스_7기_BE_레벨2_회고]]\n\n레벨3도 끝났다. 가속도가 붙은 것처럼 시간이 점점 빨리 지나간다. 지난 8주간 내가 느꼈던 것들을 하나씩 톺아보자!\n## 문제를 정의하고 요구사항을 파악하는 능력은 어떻게 기를까\n레벨3 내내 머릿속에서 맴돈 질문이다.  \n\n아이디어를 내고, 팀원들을 설득하고, 기획을 세부화하고, 이를 실제로 구현하는 과정 전반에서 문제 정의와 요구사항 파악은 늘 중심에 있었다. 사람들이 정말 필요로 하는 기능인지, 우리가 이걸 만든다고 해서 진짜 쓸 만한 제품이 되는지, 문제를 효과적으로 해결하고 있는지 계속 고민해야 했다. 이건 단순히 분석 능력만으로 되는 게 아니라 통찰과 메타인지, 그리고 타인에 대한 세심한 관심과 관찰력이 필요했던 것 같다.  \n\n능력있는 팀원들과 함께 하면서 숲을 보는 연습을 많이 했었다. 프로젝트가 처음에 기획을 했던대로, 중심에서 벗어나지 않게 자주 질문을 던지고 방향성을 점검하는 역할을 맡았던 것 같다. 그런 과정을 거치면서 아이디어가 채택되고, 기획이 점점 구체화되고, 마지막 데모데이때 피드백을 받으면서 지금까지 내가 문제를 바라본 방식이 크게 틀리지 않았다는 걸 확인할 수 있었다. \n\n그리고 이 일련의 과정이 단순히 개발만 하는 것보다 훨씬 재미있었고, \"이게 어쩌면 개발자의 본질이 아닐까?\"라는 생각도 들었다. 앞으로 어떤 개발자로 성장해야 할지, 내 강점은 어디에 있는지에 대해 더 깊게 고민할 수 있는 계기가 된 것 같다.\n## 설득하는 말하기 & 이해시키기\n어렵다.\n\n쿠션어를 많이 쓰거나 의견을 너무 완곡하게 표현하면 상대가 제대로 이해하지 못하거나 납득하지 못한다. 반대로 직설적으로 말하면 공격적으로 받아들이는 사람이 생긴다. 전자를 택하면 프로젝트가 이상한 방향으로 흘러가는 게 보이고, 후자를 택하면 \"말이 세다\"라는 피드백이 들어온다.  \n\n사람마다 성향이 너무도 다르다는 걸 느끼고 있다. 난 돌려 말해주는 것보다, '싫으면 싫다, 별로인 것 같다, 이 방향이 맞는 것 같다' 처럼 다른 사람이 느끼기에 무언가 잘못되고 있으면 이를 빠르고 정확하게 공유해주는 게 너무 직관적이고 편한 방식이라고 느낀다. 하지만 팀 프로젝트에서는 모두가 나 같을 수 없다는 걸 이번에 뼈저리게 느꼈다.  \n\n더 난감했던 건, 직설적으로 말해줘야 이해하는 사람과, 부드럽게 말해야 상처받지 않는 사람이 동시에 있을 때였다. 강하게 말하면 누군가는 불편해하고, 약하게 말하면 누군가는 제대로 못 알아듣는다. 그 사이 균형을 잡는 게 진짜 어렵다.  \n\n결국 중요한 건 \"공격적으로 받아들여지지 않으면서도 무게감 있게 말하는 법\"인 것 같다. 단순히 기술적 설득이 아니라 말하는 방식 자체가 하나의 역량이라는 걸 몸소 체감 중이다.\n\n## 우테코에서만 할 수 있는 게 뭘까\n학교나 동아리에서 할 법한, 어디서나 흔히 볼 수 있는 프로젝트 경험은 하고 싶지 않았다.  \n\n기획을 하는 것도, 새로운 기술을 도입하는 것도, 너무 착하고 무난하게만 하고 싶지 않았다. 회사에서 프로젝트를 할당받아서 진행하는 것도 아니고, 당장 창업을 할 것도 아니고, 그저 시간많고 학습 욕구 가득인 사람들이 모인 곳에서는 좀 더 재미있고 무모해 보이는 선택도 해보고 싶었다. 내가 지금까지 해온 공부들은 모두 호기심에 시작됐고, 물음표가 물음표를 낳으면서 재미를 추구해오며 공부를 했었는데, 우테코에서도 그러고 싶었다. 그리고 이게 우테코에서 원하는 몰입 경험이지 않았나 싶었다. \n\n하지만 또 모든 팀원이 그러진 않았다. 좀 더 안정적인 선택을 하고 싶어하는 팀원도 있었고 그 간극 때문에 매번 타협하기 어려웠는데 레벨4는 어떨지 모르겠다.  \n\n## 앞으로는?\n모범생처럼만 살고 싶진 않다. 이미 너무 모범생처럼 살아온 것 같다.  \n\n앞으로는 재미있는 상상들, 이상해 보이는 시도들을 더 많이 해보고 싶다. 그 과정에서 내가 스스로 옳고 그름을 판단할 수 있는 기준을 세우고 싶다. 어쩌면 이게 지금까지 내가 공부해온 방식인데, 괜히 다른 사람들의 시선을 너무 의식했던 것 같다. 결국 가장 중요한 건 내가 재미를 느끼는 것인데, 거기서부터 성장이 시작된다고 믿는다.  \n"},{"excerpt":"문제 상황 mvp를 빠르게 만들고 테스트를 하던 중, 다른 앱을 사용하다가 다시 돌아오면 웹소켓 통신이 안된다는 것을 발견했다. 찾아보니 모바일이든 pc의 각각의 기기에서 앱을 전환할 때 환경에 맞게 백그라운드에서 웹소켓을 유지하는 시간이 달랐고, 테스트를 결과 아이폰이나 맥북 기준 대부분 4~5초이내로 연결이 중단되는 것 같다. 또 클라이언트 코드에서도…","fields":{"slug":"/websocket_reconnection_app_switching/"},"frontmatter":{"date":"2025년 08월 13일 09:08","title":"모바일 백그라운드 전환 시에도 끊김 없는 WebSocket 연결 경험 만들기","tags":["우아한테크코스","ZZOL"]},"rawMarkdownBody":"## 문제 상황\nmvp를 빠르게 만들고 테스트를 하던 중, **다른 앱을 사용하다가 다시 돌아오면 웹소켓 통신이 안된다**는 것을 발견했다.\n\n찾아보니 모바일이든 pc의 각각의 기기에서 앱을 전환할 때 환경에 맞게 백그라운드에서 웹소켓을 유지하는 시간이 달랐고, 테스트를 결과 아이폰이나 맥북 기준 대부분 4~5초이내로 연결이 중단되는 것 같다.\n\n또 클라이언트 코드에서도 백그라운드 감지 로직이 없어서, OS에 의해 웹소켓이 연결 해제되면 감지조차 못했다.\n\n서버에서도 이렇게 연결이 끊어지고 구독이 해제되면, `SimpleBrokerMessageHandler`의 `SubscriptionRegistry`에 저장되어있던 구독정보가 자동으로 제거되기 때문에 서버가 클라이언트에게 메시지를 보낼 수 없게 된다.\n\n또 문제는 그렇게 재연결을 하려고 할 때 사용되는 세션 id가 기존에 사용하던 id가 아니어서 서버에서는 다른 세션 id이지만, 기존에 있던 사용자인지 알 수 있어야했다.\n\n## 요구사항\n앱 전환 시에도 사용자는 안정적으로 서비스를 이용할 수 있어야한다.\n### 세부 요구사항\n- 클라이언트는 서비스의 백 -> 포그라운드 전환을 감지해서 연결을 재요청해줘야한다.\n- 서버는 다른 세션id를 들고 오는 클라이언트를 보고, 기존의 플레이어와 연동해줘야한다.\n\n## 전처리\n### 사용자와 player를 어떻게 관리할까?\n현재 우리 서비스에서는 player를 구분할 수 있는 id인 고유식별자가 존재하지 않는다. DB를 사용하고 있지도 않고, player끼리의 구분이 필요한 상황이 없어서 id를 도입하지 않았다.\n\n대신 `joinCode:playerName`의 형식으로 room의 joinCode와 player의 playerName을 합성키처럼 활용했다. 그리고 웹소켓 연결시에 필요한 `sessionId`도 관리를 해주고 있어야 연결 재요청시에 해당 사용자가 기존 플레이어인지 구분을 할 수 있었다.\n\n```java\n// 플레이어 세션 매핑 관리  \nprivate final ConcurrentHashMap<String, String> playerSessionMap; // \"joinCode:playerName\" -> sessionId  \nprivate final ConcurrentHashMap<String, String> sessionPlayerMap; // sessionId -> \"joinCode:playerName\"\n```\n\n### Disconnect가 감지되면?\n우선 서버에서 가장 먼저 서버에서 해줘야했던 건 Disconnect가 감지되면 room에서 해당 player를 제거해줘야했다. 그 사용자가 Disconnect 되어도 해당 room에 있던 다른 사용자들은 서비스를 계속 이용할 수 있어야했기에, Disconnect된 player 감지 및 제거가 필수였다.\n\n웹소켓 연결이 끊어지면 클라이언트로부터 Disconnect 메시지가 온다. 이를 서버가 받을 수 있는데, 이와 같은 메시지를 받는 과정은 [[how_spring_handles_websocket]]를 참고하면 좋다!\n\n**'서버에서 Disconnect를 감지하면, 어느 단계에서 player를 room에서 지워줘야할까?'를 많이 고민했다.** 그 과정에서 웹소켓을 구현한 Spring의 내부 구조를 많이 고민하고 실험을 했었는데, 지금까지 연결해제와 관련해서 정리된 내용은 아래와 같다!\n```\n클라이언트가 DISCONNECT 프레임 전송\n\t↓ \nPreSend 인터셉터 실행 (DISCONNECT 메시지 처리 전)\n\t↓ \n메시지 브로커가 DISCONNECT 프레임 처리 (라우팅은 없고 연결 종료 준비)\n\t↓ \nPostSend 인터셉터 실행 (DISCONNECT 메시지 처리 후)\n\t↓ \nTCP WebSocket 연결 종료\n\t↓ \nSubProtocolWebSocketHandler.afterConnectionClosed() ← WebSocket 레벨\n\t↓ \nclearSession() 호출\n\t↓ \nStompSubProtocolHandler.afterSessionEnded() ← STOMP 프로토콜 레벨\n\t↓ \nSessionDisconnectEvent 발행 \n```\n이중에서 처음에는 postSend에서 player 제거를 구현했었다. 하지만 Interceptor의 주목적에 맞게 사용하는 것도 아니었고, Spring에서 tcp 소켓 연결 해제를 판단하는 시점보다 빨라서 정합성이 깨질 수도 있을 거라 생각했다. 또한 얼마전에 브라우저가 강제종료 됐을 때 클라이언트가 Disconnect 프레임을 전송하지도 못하고 바로 tcp 연결이 끊기면서 room에서 player가 제거되지 않는 문제도 발견했다. \n\n그래서 좀 더 살펴보니, Spring 내부에서 완전히 tcp 소켓이 끊어지면, STOMP 연결해제를 감지하고 자동으로 SessionDisconnectEvent을 발행해주고 있었고,  이를 잡아서 room에서 player를 지워주는 게 더 적절한 시점에 처리하는 것이라고 판단했다.\n\n## 첫 번째 시도, 클라이언트 코드에서만 재연결을 추가해주면?\n서버에서는 위에서 말한 것처럼 Disconnect가 감지되면 바로 room에서 player를 지워줬다.\n\n클라이언트 코드에서는 Page Visibility API를 사용해서 사용 중이던 서비스가 백그라운드에서 포그라운도 전환됐을 때를 감지해서 그 시점에 클라이언트가 서버로 웹소켓 연결을 재요청하도록 추가했다.\n\n서버에서는 연결 요청시에 오는 메시지의 헤더에 담긴 joinCode와 playerName을 보고 적절한 room을 찾아서 다시 player 객체를 만들어서 추가시켜줬다.\n\n### 뭔가 어색하다.\n잘 작동하긴 했다. 하지만 좀 어색하게 느껴졌던 건, 사용자가 앱 전환을 하자마자 room에서 player가 사라지는 모습이었다. \n\n다른 여타 비슷한 류의 게임을 살펴보면, 배틀그라운드든, 오버워치든, 텐텐이든 사용자가 앱 전환을 했을 때 바로 튕기게끔 하는 게 아니라 조금의 유예 시간을 주고, 그래도 사용자가 돌아오지 않았을 때 나가게 처리하는 모습을 볼 수 있었다.\n\n우리 서비스도 참고해보려고 했다.\n## 두 번째 시도, 15초의 유예 시간을 주자\n사용자의 Disconnect가 감지되면 조금의 유예 시간을 주도록 했다. joinCode를 다른 서비스에 공유하러 나가거나, 급한 알림을 확인하는 등의 상황을 고려했다. 그렇게 15초의 여유 시간을 줬고, 그 시간 안에도 서비스로 안돌아오면 room에서 player를 제거해주었다.\n\n이를 구현하기 위해 ScheduledFuture를 이용했다.\n```java\npublic void schedulePlayerRemoval(String playerKey, String sessionId, String reason) {  \n    log.info(\"플레이어 지연 삭제 스케줄링: playerKey={}, sessionId={}, delay={}초\",  \n            playerKey, sessionId, REMOVAL_DELAY.getSeconds());  \n  \n    // disconnect 된 플레이어는 ready 상태 false로 변경  \n    playerDisconnectionService.cancelReady(playerKey);  \n  \n    // 새로운 스케줄 등록  \n    final ScheduledFuture<?> future = taskScheduler.schedule(  \n            () -> {  \n                executePlayerRemoval(playerKey, sessionId, reason);  \n                stompSessionManager.removeSession(sessionId);  \n            },  \n            Instant.now().plus(REMOVAL_DELAY)  \n    );  \n  \n    scheduledTasks.put(playerKey, future);  \n}\n```\n\n그래서 잠시 앱을 전환하더라도 room에는 player가 남아있고, 대신 그렇게 잠시 나가있을 땐 host가 게임을 시작하지 못하도록 해줬다.\n\n## TODO\n웹소켓은 네트워크 연결 방식이 바뀔 때도 연결이 끊기고, 새로운 세션id가 발급된다. 이런 상황은 앱 전환과 다르게 사용자가 컨트롤하지 못하는 상황도 있을거라 생각이 들어서 이 이슈도 우선적으로 해결해야할 것 같다.\n\n이 문제를 해결하면서, 게임 중에 연결이 끊기는 경우 게임시간을 어떻게 다시 전파해야할지, 끊긴 과정에서 못받은 메시지들은 어떻게 다시 전달해줘야할지 고민할 수 있을 것 같다."},{"excerpt":"how_spring_injects_httpsession 이 포스트를 읽고 오면 이해가 더 잘 됩니다! Spring에서 어떻게 WebSocket 연결을 수립할까? 그 과정을 찾아가보자. Spring에서 연결방식을 WebSocket으로 업그레이드 하는 방법 handshake 성공 후에는? 물리적 TCP 연결은 동일함 메시지들은 DispatcherServlet…","fields":{"slug":"/how_spring_handles_websocket/"},"frontmatter":{"date":"2025년 08월 12일 09:08","title":"Spring WebSocket 내부 동작 원리 파헤치기","tags":["spring","ZZOL"]},"rawMarkdownBody":"[[how_spring_injects_httpsession]] 이 포스트를 읽고 오면 이해가 더 잘 됩니다!\n\nSpring에서 어떻게 WebSocket 연결을 수립할까? 그 과정을 찾아가보자.\n\n## Spring에서 연결방식을 WebSocket으로 업그레이드 하는 방법\n```\nHTTP Request (GET /ws) \n\t↓ \nDispatcherServlet.doService() \n\t↓ \nDispatcherServlet.doDispatch() \n\t↓ \nHandlerMapping.getHandler() (여기서 WebSocketHandlerMapping 사용) \n\t↓ \nHandlerAdapter.handle() (여기서 HttpRequestHandlerAdapter 사용) \n\t↓ \nWebSocketHttpRequestHandler.handleRequest() \n\t↓ \nDefaultHandshakeHandler.doHandshake()\n\t↓ \nRequestUpgradeStrategy.upgrade() (HTTP 연결이 WebSocket 연결로 업그레이드)\n\t↓\nDispatcherServlet 완전히 빠짐\n\t↓ \n이후 모든 메시지는 WebSocket 핸들러가 직접처리\n```\n\n### handshake 성공 후에는?\n- 물리적 TCP 연결은 동일함\n- 메시지들은 DispatcherServlet을 안거쳐감\n- Tomcat/Jetty가 직접 WebSocket 핸들러로 라우팅\n- Spring WebSocket 인프라가 직접 처리\n### 흐름 비교\n#### HTTP 요청\n```\nTCP → Tomcat → DispatcherServlet → Controller → 응답 \n```\n#### WebSocket 메시지 (handshake 성공 후)\n```\nTCP → Tomcat WebSocket Container → SubProtocolWebSocketHandler → \bChannelInterceptor → @MessageMapping\n```\n\n## 클라이언트에서 서버로\n```\nWebSocket Frame (STOMP CONNECT)\n    ↓\nSubProtocolWebSocketHandler.handleMessage() (서블릿 컨테이너가 호출함)\n    ↓  \nStompSubProtocolHandler.handleMessageFromClient()\n    ↓\nclientInboundChannel로 Spring Message 전송\n    ↓\nChannelInterceptor (커스텀한 인터셉터가 여기서 동작!)\n    ↓\nSimpleBroker 또는 외부 브로커\n    ↓\n@MessageMapping 컨트롤러 (전후로 presend, postsend)\n```\n\n### SubProtocolWebSocketHandler.handleMessage() 호출\n```java\n\n@Override  \npublic void handleMessage(WebSocketSession session, WebSocketMessage<?> message) throws Exception {  \n\n\t// 세션 갖고오기\n    WebSocketSessionHolder holder = this.sessions.get(session.getId());  \n    if (holder != null) {  \n       session = holder.getSession();  \n    }  \n    \n    // 프로토콜 핸들러 찾기 (STOMP, etc, ...)\n    SubProtocolHandler protocolHandler = findProtocolHandler(session);  \n\n\t// 위임하기\n    protocolHandler.handleMessageFromClient(session, message, this.clientInboundChannel);  \n    if (holder != null) {  \n       holder.setHasHandledMessages();  \n    }  \n}\n```\n### StompSubProtocolHandler.handleMessageFromClient() 호출\n\n```java\n@Override  \npublic void handleMessageFromClient(WebSocketSession session,  \n       WebSocketMessage<?> webSocketMessage, MessageChannel targetChannel) {  \n  \n    /* 위에서 생략된 내용들\n    1. WebSocket 메시지 -> ByteBuffer로 변환\n    2. STOMP 프레임 디코딩\n    3. 순서 보장처리 (하나의 메시지가 프레임단위로 쪼개져서 올 수도 있음)\n    */\n\n\t// 4. 각 STOMP 메시지별 처리\n    for (Message<byte[]> message : messages) {  \n       StompHeaderAccessor headerAccessor =  \n             MessageHeaderAccessor.getAccessor(message, StompHeaderAccessor.class);  \n\n       StompCommand command = headerAccessor.getCommand();  \n       boolean isConnect = StompCommand.CONNECT.equals(command) || StompCommand.STOMP.equals(command);  \n  \n       boolean sent = false;  \n       try {  \n\t\t  // 5. 세션 정보를 Spring Message 헤더에 설정\n          headerAccessor.setSessionId(session.getId());  \n          headerAccessor.setSessionAttributes(session.getAttributes());  \n          headerAccessor.setUser(getUser(session));  \n          if (isConnect) {  \n             headerAccessor.setUserChangeCallback(user -> {  \n                if (user != null && user != session.getPrincipal()) {  \n                   this.stompAuthentications.put(session.getId(), user);  \n                }  \n             });  \n          }  \n          headerAccessor.setHeader(SimpMessageHeaderAccessor.HEART_BEAT_HEADER, headerAccessor.getHeartbeat());  \n          \n          try {  \n            // 여기서 \bclientInboudChannel로 전송! \n            // → channelToUse.send()\n            // → AbstractMessageChannel.send() \n            // → ChannelInterceptorChain.applyPreSend() \n            // → ChannelInterceptor.preSend() 호출됨! (Custom)\n            // → 실제메시지 처리 (@MessageMapping)\n            // → SimpleBrokerMessageHandler의 SubscriptionRegistry에 구독정보 저장\n            // → ChannelInterceptorChain.applyPostSend()\n            // → ChannelIntercaptor.postSend() 호출됨 (Custom)\n\t         SimpAttributesContextHolder.setAttributesFromMessage(message); \n             sent = channelToUse.send(message);  \n  \n             if (sent) {  \n                if (this.eventPublisher != null) {  \n                   Principal user = getUser(session);  \n                   if (isConnect) {  \n                      publishEvent(this.eventPublisher, new SessionConnectEvent(this, message, user));  \n                   }  \n                   else if (StompCommand.SUBSCRIBE.equals(command)) {  \n                      publishEvent(this.eventPublisher, new SessionSubscribeEvent(this, message, user));  \n                   }  \n                   else if (StompCommand.UNSUBSCRIBE.equals(command)) {  \n                      publishEvent(this.eventPublisher, new SessionUnsubscribeEvent(this, message, user));  \n                   }  \n                }  \n             }  \n          }  \n          finally {  \n             SimpAttributesContextHolder.resetAttributes();  \n          }  \n       }  \n}\n```\n\n## 서버에서 클라이언트로!\n```\n@Controller에서 SimpMessagingTemplate.send()\n    ↓\nclientOutboundChannel로 메시지 전송\n\t↓\nSimpleBroker 또는 외부 브로커\n    ↓\nSubProtocolWebSocketHandler.handleMessage()\n    ↓\nStompSubProtocolHandler.handleMessageToClient()\n    ↓\nWebSocket Frame으로 변환해서 클라이언트 전송 (Tomcat/Jetty에서)\n```\n### @Controller에서 SimpMessagingTemplate.send()\n```java\n@MessageMapping(\"/room/{joinCode}/update-players\")  \npublic void broadcastPlayers(@DestinationVariable String joinCode) {  \n    final List<PlayerResponse> responses = roomService.getAllPlayers(joinCode)  \n            .stream()  \n            .map(PlayerResponse::from)  \n            .toList();  \n  \n    messagingTemplate.convertAndSend(\"/topic/room/\" + joinCode,  \n            WebSocketResponse.success(responses));  \n}\n```\n### SimpMessagingTemplate 내부동작\n```java\n@Override  \npublic void convertAndSend(D destination, Object payload, @Nullable Map<String, Object> headers,  \n       @Nullable MessagePostProcessor postProcessor) throws MessagingException {  \n  \n    Message<?> message = doConvert(payload, headers, postProcessor);  \n    send(destination, message);  \n}\n\n// send -> ... -> AbstractMessageChannel.send()\n@Override  \npublic final boolean send(Message<?> message, long timeout) {  \n    Assert.notNull(message, \"Message must not be null\");  \n    Message<?> messageToUse = message;  \n    ChannelInterceptorChain chain = new ChannelInterceptorChain();  \n    boolean sent = false;  \n    try {  \n\n\t\t// 커스텀한 interceptor의 presend 호출\n       messageToUse = chain.applyPreSend(messageToUse, this);  \n       if (messageToUse == null) {  \n          return false;  \n       }  \n       \n\t\t// 등록된 모든 MessageHandler들에게 메시지 전달\n\t\t// SubProtocolWebSocketHandler.handleMessage 호출됨\n       sent = sendInternal(messageToUse, timeout);\n\n\t\t// 커스텀한 interceptor의 postsend 호출\n       chain.applyPostSend(messageToUse, this, sent);  \n       chain.triggerAfterSendCompletion(messageToUse, this, sent, null);  \n       return sent;  \n    }  \n    catch (Exception ex) {  \n       chain.triggerAfterSendCompletion(messageToUse, this, sent, ex);  \n       if (ex instanceof MessagingException messagingException) {  \n          throw messagingException;  \n       }  \n       throw new MessageDeliveryException(messageToUse,\"Failed to send message to \" + this, ex);  \n    }  \n    catch (Throwable err) {  \n       MessageDeliveryException ex2 =  \n             new MessageDeliveryException(messageToUse, \"Failed to send message to \" + this, err);  \n       chain.triggerAfterSendCompletion(messageToUse, this, sent, ex2);  \n       throw ex2;  \n    }  \n}\n```\n### SubProtocolWebSocketHandler.handleMessage() 호출\n```java\n@Override  \npublic void handleMessage(Message<?> message) throws MessagingException {  \n\n\t// 1. 메시지에서 세션 id 추출\n    String sessionId = resolveSessionId(message);  \n    if (sessionId == null) {  \n       if (logger.isErrorEnabled()) {  \n          logger.error(\"Could not find session id in \" + message);  \n       }  \n       return;  \n    }  \n\n\t// 2. 해당 세션 찾기\n    WebSocketSessionHolder holder = this.sessions.get(sessionId);  \n    if (holder == null) {  \n       if (logger.isDebugEnabled()) {  \n          // The broker may not have removed the session yet  \n          logger.debug(\"No session for \" + message);  \n       }  \n       return;  \n    }  \n  \n    WebSocketSession session = holder.getSession();  \n    try {  \n      // 3. 프로토콜 핸들러로 클라이언트에게 전송\n     findProtocolHandler(session).handleMessageToClient(session, message);  \n    }  \n    catch (SessionLimitExceededException ex) {  \n       try {  \n          if (logger.isDebugEnabled()) {  \n             logger.debug(\"Terminating '\" + session + \"'\", ex);  \n          }  \n          else if (logger.isWarnEnabled()) {  \n             logger.warn(\"Terminating '\" + session + \"': \" + ex.getMessage());  \n          }  \n          this.stats.incrementLimitExceededCount();  \n          clearSession(session, ex.getStatus()); // clear first, session may be unresponsive  \n          session.close(ex.getStatus());  \n       }  \n       catch (Exception secondException) {  \n          logger.debug(\"Failure while closing session \" + sessionId + \".\", secondException);  \n       }  \n    }  \n    catch (Exception ex) {  \n       // Could be part of normal workflow (for example, browser tab closed)  \n       if (logger.isDebugEnabled()) {  \n          logger.debug(\"Failed to send message to client in \" + session + \": \" + message, ex);  \n       }  \n    }  \n}\n```\n### StompSubProtocolHandler.handleMessageToClient() (실제 전송)\n```java\n@Override  \n@SuppressWarnings(\"unchecked\")  \npublic void handleMessageToClient(WebSocketSession session, Message<?> message) {  \n    // ... 생략\n    \n    // 순서 보장\n    Runnable task = OrderedMessageChannelDecorator.getNextMessageTask(message);  \n    if (task != null) {  \n       Assert.isInstanceOf(ConcurrentWebSocketSessionDecorator.class, session);  \n       ((ConcurrentWebSocketSessionDecorator) session).setMessageCallback(m -> task.run());  \n    }  \n\n\t// 실제 클라이언트에게 전송\n    sendToClient(session, accessor, payload);  \n}\n\n```\n\n```java\nprivate void sendToClient(WebSocketSession session, StompHeaderAccessor stompAccessor, byte[] payload) {  \n    StompCommand command = stompAccessor.getCommand();  \n    try {  \n       byte[] bytes = this.stompEncoder.encode(stompAccessor.getMessageHeaders(), payload);  \n       boolean useBinary = (payload.length > 0 && !(session instanceof SockJsSession) &&  \n             MimeTypeUtils.APPLICATION_OCTET_STREAM.isCompatibleWith(stompAccessor.getContentType()));  \n\t    // Tomcat/Jetty 컨테이너로 전달\n       if (useBinary) {  \n          session.sendMessage(new BinaryMessage(bytes));  \n       }  \n       else {  \n          session.sendMessage(new TextMessage(bytes));  \n       }  \n    }  \n    catch (SessionLimitExceededException ex) {  \n       // Bad session, just get out  \n       throw ex;  \n    }  \n    catch (Throwable ex) {  \n       // Could be part of normal workflow (for example, browser tab closed)  \n       if (logger.isDebugEnabled()) {  \n          logger.debug(\"Failed to send WebSocket message to client in session \" + session.getId(), ex);  \n       }  \n       command = StompCommand.ERROR;  \n    }  \n    finally {  \n       if (StompCommand.ERROR.equals(command)) {  \n          try {  \n             session.close(CloseStatus.PROTOCOL_ERROR);  \n          }  \n          catch (IOException ex) {  \n             // Ignore  \n          }  \n       }  \n    }  \n}\n```\n\n## 핵심 포인트\n### SubProtocolWebSocketHandler\n- **SubProtocolWebSocketHandler**는 **WebSocket ↔ Spring Messaging 브릿지 역할**을 하는 핵심 컴포넌트임\n- WebSocketHandler 구현\n\t- WebSocket 컨테이너(Tomcat/Jetty)에서 호출\n\t- **클라이언트 → 서버** 메시지 처리\n\t- **WebSocketMessage → Spring Message** 변환\n- MessageHandler 구현\n\t- **clientOutboundChannel**에 구독자로 등록됨\n\t- **서버 → 클라이언트** 메시지 처리\n\t- **Spring Message → WebSocket 프레임** 변환하도록 Tomcat/Jetty 호출\n\n### ChannelInterceptor의 Presend/PostSend\n- Input 메시지 (clientInboundChannel):\n\t- preSend → @MessageMapping 실행 → postSend\n- Output 메시지 (clientOutboundChannel, 컨트롤러에서 전송):\n\t- preSend → 클라이언트 전송 → postSend\n- 그래서 채팅 하나 보내면 inbound 채널에서 preSend/postSend 한 번, outbound 채널에서 preSend/postSend 또 한 번 실행됨"},{"excerpt":"커피빵(CoffeeShout): 똥손도 즐기는 커피빵 전쟁 목표 커피 내기, 재미있게 해보자! 매일 똑같은 가위바위보 그만! 핵심 기능 미니게임을 통한 가중치 기반 룰렛 시스템 기능 세부사항 방을 만든다. 초대 코드로 참가 가능. 사용자들이 해당 방에 입장한다. 메뉴 선택. 미니게임을 통해 확률을 조절한다. 룰렛을 돌려서 당첨자를 뽑는다. 당첨자가 메뉴 …","fields":{"slug":"/persona/"},"frontmatter":{"date":"2025년 07월 08일 09:07","title":"누가 우리 서비스를 쓸까? : 페르소나 정의를 통한 타겟 유저 구체화","tags":["우아한테크코스","ZZOL"]},"rawMarkdownBody":"# 커피빵(CoffeeShout): 똥손도 즐기는 커피빵 전쟁\n## 목표\n- 커피 내기, 재미있게 해보자!\n- 매일 똑같은 가위바위보 그만!\n## 핵심 기능\n- 미니게임을 통한 가중치 기반 룰렛 시스템\n## 기능 세부사항\n1. 방을 만든다.\n    1. 초대 코드로 참가 가능.\n2. 사용자들이 해당 방에 입장한다.\n    1. 메뉴 선택.\n3. 미니게임을 통해 확률을 조절한다.\n4. 룰렛을 돌려서 당첨자를 뽑는다.\n5. 당첨자가 메뉴 리스트를 확인해서 주문하러 간다.\n## 사용자 페르소나\n대전제: 커피 내기 자주함\n\n| **유형**        | **정의**                | **니즈**                              | **Pain Points** |\n| ------------- | --------------------- | ----------------------------------- | --------------- |\n| **커피 중독 직장인** | 매일같이 아메리카노를 달고 사는 직장인 | 공짜로 커피를 먹고 싶음 <br/> 재미있게 당첨자 고르고 싶음 | 재미있게 몰빵 정하고 싶음  |\n| **똥손(루키)**    | 운이 없어서 매번 커피사는 사람     | 낮은 당첨 확률                            | 운 나쁘면 계속 걸림     |\n\n### 사용자 페르소나 상세\n\n| **사용자 유형**    | **페르소나 상세**                                                                             |\n| ------------- | --------------------------------------------------------------------------------------- |\n| **커피 중독 직장인** | **이름:** 엠제이 (27, 마케터) <br/> **목표:** 점심 먹고 카페인 수혈 <br/> **니즈:** 도파민 부족, 커피라도 재밌게 마시고 싶다. |\n| **똥손**        | **이름:** 루키 (25, 백엔드 개발자) <br/> **목표:** 오늘은 걸리지 말자! <br/> **니즈:** 낮은 당첨 확률               |\n\n### 사용자 시나리오 & 요구사항\n\n| **페르소나** | **시나리오 (사용 흐름)**                                   | **요구사항**                                         |\n| -------- | -------------------------------------------------- | ------------------------------------------------ |\n| **루키**   | 점심 식사 → 팀원들과 커피 내기 → 서비스 참가 → 메뉴 선정 → 미니게임 → 결과 확인 | 1. 미니게임 <br/> 2. 승리 시 당첨 확률 감소 <br/> 3. 주문리스트 확인 |\n\n### 사용자 스토리\n**나는야 카페인 필수 인간 – 루키**\n- **요구사항:** 재미있게 당첨자 추첨 & 주문리스트 쉽게 알아보기\n- **스토리:** \"오늘은 난 절대 안걸린다!\"\n- **인수조건:**\n    - **Given:** 루키, 월요일 13:00, 식사 후 팀원들과 커피 내기\n    - **When:** 커피빵의 방 입장 후 ‘참가’ 버튼 클릭\n    - **Then:** 미니게임 후 룰렛 추첨, 본인 당첨 시 쉽게 주문리스트 확인"},{"excerpt":"프로젝트명 - 한글 커피빵 프로젝트명 - 영어 \bCoffeeShout 프로젝트 주제 똥손도 즐기는 커피빵 전쟁 프로젝트 목적 및 설명 커피 내기를 재미있고 간편하게 할 수 있도록 만든 플랫폼 점심시간마다 반복되는 커피 내기를 좀 더 유쾌하고 흥미롭게 즐길 수 있도록","fields":{"slug":"/ideation/"},"frontmatter":{"date":"2025년 07월 07일 09:07","title":"사이드 프로젝트에서 실제 서비스까지: 커피빵 기획과 그 시작","tags":["우아한테크코스","ZZOL"]},"rawMarkdownBody":"## 프로젝트명 - 한글\n커피빵\n## 프로젝트명 - 영어\n\bCoffeeShout\n## 프로젝트 주제\n똥손도 즐기는 커피빵 전쟁\n## 프로젝트 목적 및 설명\n- 커피 내기를 재미있고 간편하게 할 수 있도록 만든 플랫폼\n- 점심시간마다 반복되는 커피 내기를 좀 더 유쾌하고 흥미롭게 즐길 수 있도록\n\n"},{"excerpt":"지난 회고: 우아한테크코스_7기_BE_레벨1_회고 레벨2도 지나갔다. 지난 8주간 무엇을 배우고 느꼈는지 곰곰이 고민을 했는데, 개인적으로 아쉬운 점들이 많았다. 이번 회고도 그 연장선에서, 지난 8주를 되돌아보며 레벨3를 더 의미 있게 보내기 위한 준비 과정으로 삼고 싶다. 나만의 학습법, 왜 찾아야하죠? 레벨2의 가장 큰 키워드는 단연 “나만의 학습법…","fields":{"slug":"/우아한테크코스_7기_BE_레벨2_회고/"},"frontmatter":{"date":"2025년 06월 11일 09:06","title":"우아한테크코스 7기 BE 레벨2 회고","tags":["우아한테크코스","회고"]},"rawMarkdownBody":"지난 회고: [[우아한테크코스_7기_BE_레벨1_회고]]\n\n레벨2도 지나갔다. 지난 8주간 무엇을 배우고 느꼈는지 곰곰이 고민을 했는데, 개인적으로 아쉬운 점들이 많았다. 이번 회고도 그 연장선에서, 지난 8주를 되돌아보며 레벨3를 더 의미 있게 보내기 위한 준비 과정으로 삼고 싶다.\n\n## 나만의 학습법, 왜 찾아야하죠?\n레벨2의 가장 큰 키워드는 단연 “나만의 학습법 찾기”였다.\n시작부터 끝까지 많은 코치분들이 이 메시지를 강조하셨고, 크루들 사이에서도 이 주제가 자주 언급됐다. 나 역시 스프링을 처음 공부하는 입장에서 여러 시도를 했었다. 코드를 직접 뜯어보기도 했고, 공식 문서도 많이 읽어보고, 크루들과 의견을 주고받아보고, AI에게 질문도 던져봤다. 각각의 방식은 나름의 장단점을 가지고 있었고, 상황에 따라 맞는 접근법은 달랐다.\n\n그런데 어느 순간 이런 생각이 들었다. ‘나만의 학습법’을 하나로 딱 정리해서 말하는 게 과연 자연스러운 일일까? 누군가 나에게 “너는 어떤 방식으로 공부해?“라고 물으면, 뭔가 선명하게 답해야 할 것 같은 압박감이 생겼다. 하지만 실제로는 계속해서 방식이 바뀌고, 유동적으로 대응하는 게 더 현실적인 학습 태도 아닐까 싶었다.\n\n나는 지금 뭘 알고, 뭘 모르는지 명확히 구분할 수 있다면 그걸로 충분하다고 생각한다. 공부할 때마다 ‘이 방식이 맞는 걸까?’ 고민하는 것보단, 데드라인과 컨디션을 고려해서 가장 효율적인 방향으로 선택하고, 필요하면 또 바꾸는 유연함이 더 중요하다고 느꼈던 것 같다. 공식 문서에 손이 잘 안 가는 날도 있었고, 혼자 실습을 하면서 익힐 때 더 집중이 잘 되는 날도 있었다. 그때그때 내가 가장 잘 배울 수 있는 방식으로 접근하는 게 결국 ‘나만의 학습법’이 아닐까.\n\n그래서 레벨2에서 지속적으로 “학습법을 찾아야 한다”는 메시지를 강조하는 흐름은 아쉽게 느껴졌다. 레벨1에서는 “정답이 없는 문제를 어떻게 풀어야 하는가?”라는 고민을 중심으로, 문제 해결 능력 자체에 집중할 수 있었는데, 레벨2는 다소 추상적인 주제에 갇힌 느낌도 있었다. 레벨1의 방향성을 조금 더 잘 잇는 목표 설정이었으면 어땠을까 하는 아쉬움이 남는다.\n\n## 내 학습목표는?\n공식 커리큘럼에서 제시한 학습 목표에 온전히 집중하지 않았기 때문에, 오히려 마음의 여유가 생겼다. 그 여유 덕분에 이전부터 고민하던 ‘소프트 스킬’ 쪽에 더 많은 시간을 쏟을 수 있었다.\n\n레벨2가 진행되는 동안 현업에 계신 선배들, 코치분들, 학교 친구들과 커피챗을 자주 했고, 그때마다 반복적으로 한 가지 질문을 던졌다.\n> “팀장으로서, 혹은 팀원으로서, 사람들에게 어떻게 동기부여를 할 수 있을까요?”\n\n내가 속한 어떤 조직에서든 항상 느꼈던 고민이었다. 동아리에서 회장단으로 활동할 때도, 팀 프로젝트에서 팀원으로 참여할 때도, ‘사람이 움직이게 만드는 힘’이 결국 팀의 방향을 좌우한다는 걸 여러 번 체감했었다\n\n우테코도 마찬가지였다. 모두가 자발적으로 모인 공간이었고, 학습 동기가 충분한 사람들이라고 생각했지만, 의외로 ‘동기 결여’ 상태에 놓인 크루들을 몇 번 마주했다. 그때 다시 한 번, 이 질문의 무게를 느꼈고, 그래서 더 많은 사람들에게 질문을 던지며 그 답을 탐색하고자 했다.\n\n정답은 없었다. 각자 서로 다른 이야기를 해줬고, 각자의 맥락에 맞는 조언들이었다. 그럼에도 불구하고 하나하나 마음에 남았다. 그리고 그런 대화들이 레벨2에서 내가 가장 의미 있게 느꼈던 순간이기도 했다.\n\n## 우테코의 사실과 오해\n우테코에 들어오기 전에는 이 부트캠프가 마냥 대단한 활동인 줄 알았다. 이 활동만 하면 벡엔드 분야에 대해 잘 알 수 있고, 부족한 하드 스킬을 배울 수 있을 것만 같았다. 그러다보니 우테코가 취업 발사대인 것 마냥 활동을 하는 사람들이 종종 있었다. 단순 지적 호기심 때문에 학습을 하는 게 아닌, 취업을 위해 필요한 정보들이 무엇인지 찾고, 딱 거기까지만 공부하고자 하는 사람들을 심심치 않게 발견할 수 있다. 물론 잘못된 거라고는 생각하지 않는다. 졸업을 했고, 당장 취업을 해야하는 상황이면 나도 그들과 별반 다르지 않을 것 같았다. \n\n하지만 그럴수록 더욱 본인의 색깔을 찾으려고 해야하지 않을까. \n\n우테코 내부에서도 취업의 관점에서 너무 사회의 시선과 요구에 본인을 맞추려고 하는 사람들이 많다. Best Practice를 따라가는 게 안정적인 선택일 수도 있지만 그 과정에서 자기다움을 잃어버리는 건 아닌지, 한 번쯤 되돌아볼 필요가 있다고 느꼈다.\n\n## 앞으로는?\n우테코는 분명 열정 있는 사람들이 모인 좋은 환경이다. 근데 매일 이 안에서만 생활하다 보니, 어느 순간부터 내 성장 기준이 자연스레 이 내부로만 한정된 느낌이 들었다.\n\n공부를 하면 할수록 우테코가 모든 걸 해결해주진 않는다는 사실을 체감하고 있다. 방향은 제시해줄 수 있어도, 성장은 결국 내 몫이고, 우테코가 제시해주는 그 방향조차 그리 대단한 게 아님을 느끼고 있다.\n\n이제는 좀 더 바깥으로 시야를 넓히고 싶다. 우테코 밖의 사람들과도 부딪히면서, 좀 더 객관적으로 메타인지를 해야하지 않을까.\n\n\n"},{"excerpt":"지난 포스트에서 DispatcherServlet에 대해 공부를 했고, 요즘은 로그인 과정에 대해 배우고 있다. 그 중에서 session 로그인 과정을 공부하던 중에 의문이 생기는 코드가 있어서 이번 포스트에서는 이 코드를 실행할 때 Spring 내부에서 일어나는 일련의 과정을 알아보고자 한다. 문제 상황 테스트 코드를 보면 단순히 이메일과 비밀번호를 파라…","fields":{"slug":"/how_spring_injects_httpsession/"},"frontmatter":{"date":"2025년 05월 10일 09:05","title":"How Spring Injects HttpSession","tags":["spring"]},"rawMarkdownBody":"지난 포스트에서 DispatcherServlet에 대해 공부를 했고, 요즘은 로그인 과정에 대해 배우고 있다. 그 중에서 session 로그인 과정을 공부하던 중에 의문이 생기는 코드가 있어서 이번 포스트에서는 이 코드를 실행할 때 Spring 내부에서 일어나는 일련의 과정을 알아보고자 한다.\n\n## 문제 상황\n```java\n// cholog, spring-auth-1 코드 중 세션 관련 일부\n\n@PostMapping(\"/login/session\")  \npublic ResponseEntity<Void> sessionLogin(HttpServletRequest request, HttpSession session) {  \n    final Map<String, String[]> paramMap = request.getParameterMap();  \n    String email = paramMap.get(USERNAME_FIELD)[0];  \n    String password = paramMap.get(PASSWORD_FIELD)[0];  \n  \n    if (authService.checkInvalidLogin(email, password)) {  \n        throw new AuthorizationException();  \n    }  \n  \n    session.setAttribute(SESSION_KEY, email);  \n  \n    return ResponseEntity.ok().build();  \n}  \n  \n@GetMapping(\"/members/me/session\")  \npublic ResponseEntity<MemberResponse> findMyInfo(HttpSession session) {  \n    String email = (String) session.getAttribute(SESSION_KEY);  \n    MemberResponse member = authService.findMember(email);  \n    return ResponseEntity.ok().body(member);  \n}\n```\n```java\n@Test  \nvoid sessionLogin() {  \n    String cookie = RestAssured  \n            .given().log().all()  \n            .param(USERNAME_FIELD, EMAIL)  \n            .param(PASSWORD_FIELD, PASSWORD)  \n            .when().post(\"/login/session\")  \n            .then().log().all()  \n            .extract()  \n            .header(\"Set-Cookie\").split(\";\")[0];  \n  \n    MemberResponse member = RestAssured  \n            .given().log().all()  \n            .header(\"Cookie\", cookie)  \n            .accept(MediaType.APPLICATION_JSON_VALUE)  \n            .when().get(\"/members/me/session\")  \n            .then().log().all()  \n            .statusCode(HttpStatus.OK.value()).extract().as(MemberResponse.class);  \n  \n    assertThat(member.getEmail()).isEqualTo(EMAIL);  \n}\n```\n테스트 코드를 보면 단순히 이메일과 비밀번호를 파라미터 값으로 넘겨주고 있는데 컨트롤러의 PostMapping 해주는 코드에서는 request외에도 session을 받아주고, 메서드 내부에서도 `session.setAttribute(SESSION_KEY, email)` 을 해주고 있다. \n\n누가 메서드의 파라미터로 session까지 넣어주는걸까?\n\n## Spring MVC의 핵심 흐름\n[[spring_mvc_dispatcherservlet]]에서 다루었듯이 파라미터를 처리하는 역할을 담당하는 건 ArgumentResolver의 한 종류이다. Spring MVC는 컨트롤러의 메서드를 실행할 때 실제로 HandlerMethodArgumentResolver 목록을 순회하며 파라미터를 처리한다.\n\n세부 흐름은 다음과 같다.\n```scss\nDispatcherServlet\n └── HandlerAdapter\n      └── InvocableHandlerMethod\n           └── HandlerMethodArgumentResolverComposite\n                └── 각 ArgumentResolver의 supportsParameter() 호출\n\n```\n\n코드 상에서는 다음과 같은 모습으로 호출이된다.\n```java\n// InvocableHandlerMethod.class 내부\n\nprotected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception {  \n    MethodParameter[] parameters = this.getMethodParameters();  \n    if (ObjectUtils.isEmpty(parameters)) {  \n        return EMPTY_ARGS;  \n    } else {  \n        Object[] args = new Object[parameters.length];  \n  \n        for(int i = 0; i < parameters.length; ++i) {  \n            MethodParameter parameter = parameters[i];  \n            parameter.initParameterNameDiscovery(this.parameterNameDiscoverer);  \n            args[i] = findProvidedArgument(parameter, providedArgs);  \n            if (args[i] == null) {  \n                if (!this.resolvers.supportsParameter(parameter)) {  \n                    throw new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\"));  \n                }  \n  \n                try {  \n                    args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);  \n                } catch (Exception var10) {  \n                    if (logger.isDebugEnabled()) {  \n                        String exMsg = var10.getMessage();  \n                        if (exMsg != null && !exMsg.contains(parameter.getExecutable().toGenericString())) {  \n                            logger.debug(formatArgumentError(parameter, exMsg));  \n                        }  \n                    }  \n  \n                    throw var10;  \n                }  \n            }  \n        }  \n  \n        return args;  \n    }  \n}\n```\n이때 HttpSession 타입을 지원해주는 게 바로 ServletRequestMethodArgumentResolver이다.\n\n## ArgumentResolver가 뭘 해주나?\n```java\npublic interface HandlerMethodArgumentResolver {  \n    boolean supportsParameter(MethodParameter parameter);  \n  \n    @Nullable  \n    Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception;  \n}\n```\n\nArgumentResolver는 각 파라미터를 지원해주는지 판단하고, 변환해준다.\n\n### 그 중에서 ServletRequestMethodArgumentResolver은?\n```java\n// ServletRequestMethodArgumentResolver.class\n\npublic boolean supportsParameter(MethodParameter parameter) {  \n    Class<?> paramType = parameter.getParameterType();  \n    return WebRequest.class.isAssignableFrom(paramType) ||\n    ServletRequest.class.isAssignableFrom(paramType) ||   \n    MultipartRequest.class.isAssignableFrom(paramType) ||\n    HttpSession.class.isAssignableFrom(paramType) ||\n    PushBuilder.class.isAssignableFrom(paramType) ||\n    Principal.class.isAssignableFrom(paramType) &&\n    !parameter.hasParameterAnnotations() ||\n    InputStream.class.isAssignableFrom(paramType) ||\n    Reader.class.isAssignableFrom(paramType) || \n    HttpMethod.class == paramType || \n    Locale.class == paramType || \n    TimeZone.class == paramType || \n    ZoneId.class == paramType;  \n}\n\n@Nullable  \nprivate Object resolveArgument(Class<?> paramType, HttpServletRequest request) throws IOException {  \n    if (HttpSession.class.isAssignableFrom(paramType)) {  \n        HttpSession session = request.getSession();  \n        if (session != null && !paramType.isInstance(session)) {  \n            String var13 = paramType.getName();  \n            throw new IllegalStateException(\"Current session is not of type [\" + var13 + \"]: \" + session);  \n        } else {  \n            return session;  \n        }\n\t}\n\t// ...\n}\n```\n\n그럼 다시 원래 코드로 돌아와서,\n```java\n@PostMapping(\"/login/session\")  \npublic ResponseEntity<Void> sessionLogin(HttpServletRequest request, HttpSession session) {  \n    final Map<String, String[]> paramMap = request.getParameterMap();  \n    String email = paramMap.get(USERNAME_FIELD)[0];  \n    String password = paramMap.get(PASSWORD_FIELD)[0];  \n  \n    if (authService.checkInvalidLogin(email, password)) {  \n        throw new AuthorizationException();  \n    }  \n  \n    session.setAttribute(SESSION_KEY, email);  \n  \n    return ResponseEntity.ok().build();  \n}  \n```\n파라미터로 HttpSession을 받고 있기 때문에 ServletRequestMethodArgumentResolver.resolveArgument에서 session을 반환해줄 수 있는 것이다.\n\n## 번외\n### 성능 이슈는 없을까?\nQ. Spring MVC는 컨트롤러의 메서드를 실행할 때 실제로 HandlerMethodArgumentResolver 목록을 순회하며 파라미터를 처리한다고 했는데, HandlerMethodArgumentResolver가 많으면 매번 찾을 때마다 성능 문제가 생기지 않을까?\n\nA. Spring에서 이미 고려해주고 있다.\nHandlerMethodArgumentResolverComposite의 필드로 캐시된 값들을 관리해주고 있다.\n\n```java\npublic class HandlerMethodArgumentResolverComposite implements HandlerMethodArgumentResolver {\n\tprivate final Map<MethodParameter, HandlerMethodArgumentResolver> argumentResolverCache;\n\t// ...\n}\n```\n"},{"excerpt":"Preview overview.jpg DispatcherServlet 공식문서에 따르면, Spring MVC는 다른 많은 웹 프레임워크들과 마찬가지로 Front Controller Pattern에 기반을 두고 있다. 우선 여기서 말하는 Front Controller Pattern은 뭘까? 이는 어플리케이션에서 들어오는 모든 요청을 하나의 진입점으로 모아서…","fields":{"slug":"/spring_mvc_dispatcherservlet/"},"frontmatter":{"date":"2025년 04월 15일 09:04","title":"Understanding DispatcherServlet in Spring MVC","tags":["spring"]},"rawMarkdownBody":"\n\n## Preview\n![[overview.jpg]]\n## DispatcherServlet\n\n[공식문서](https://docs.spring.io/spring-framework/reference/web/webmvc/mvc-servlet.html)에 따르면, Spring MVC는 다른 많은 웹 프레임워크들과 마찬가지로 Front Controller Pattern에 기반을 두고 있다.\n\n우선 여기서 말하는 **Front Controller Pattern은 뭘까?** 이는 어플리케이션에서 들어오는 모든 요청을 하나의 진입점으로 모아서 처리하는 설계 방식이다. 좀 더 자세히 설명하면, 로그인은 LoginServlet에서, 회원가입은 SignupServlet에서 처리하는 게 아니라 공통된 모듈에서 처리해주는 설계방식이다. \n\n그럼 다시 **Servlet은 뭘까?** Servlet은 웹 요청을 받아 동적인 웹 페이지나 데이터를 만들어주는 역할을 하는 객체인데, 자바로 만든 서버측 컴포넌트 정도로 이해하고 넘어가려한다.\n\n**DispatcherServlet도 이 Servlet을 상속해서 만들어진 것으로, 여기서 모든 요청을 받아주고 있다.** 이후 실제 처리는 여러 delegate component들이 나누어 담당하고 있다. \n\ndelegate components\n- Handler Mapping\n- Handler Adapter\n- View Resolver\n- Exception Handler\n- etc...\n\n## Spring MVC's Internal Request Handling Flow\n1. DispatcherServlet이 클라이언트로부터 Request를 받는다.\n2. HandlerMapping을 통해 Request 정보에 대한 알맞은 Controller를 찾는다.\n3. Request를 Controller로 건내줄 수 있는 HandlerAdapter를 찾아서 건내준다.\n4. HandlerAdapter를 통해 Controller 메서드를 호출한다.\n5. 반환값(Response)을 HandlerAdapter에게 건내준다.\n6. 반환값에 따라 ResponseEntity로 감싸는 경우가 있고, 이 형식에 따라 다른 Converter가 동작한다.\n\t- 반환값이 view 이름인 경우, ViewResolver를 통해 렌더링\n\t- 반환값이 데이터(json)인 경우, ResponseEntity로 감싸고 HttpMessageConverter가 작동\n\t\t- 단순 문자열이면, StringHttpMessageConverter\n\t\t- 객체면, MappingJackson2HttpMessageConverter\n## Deep Dive to Workflow\n![[diagram.png]]\nDispatcherServlet은 위와 같은 계층 구조로 이루어져있다. 그래서 각 단계마다 실행되는 메서드의 위치가 다른데, 좀 더 자세히 살펴보자\n\n### 1. DispatcherServlet이 클라이언트로부터 Request를 받는다.\n외부에서 들어온 요청은 HttpServlet에서 구현된 service 메서드에서 처리된다. \n```java\npublic abstract class HttpServlet extends GenericServlet {\n\n\tpublic void service(ServletRequest req, ServletResponse res) throws ServletException, IOException {  \n\t    HttpServletRequest request;  \n\t    HttpServletResponse response;  \n\t    try {  \n\t        request = (HttpServletRequest)req;  \n\t        response = (HttpServletResponse)res;  \n\t    } catch (ClassCastException var6) {  \n\t        throw new ServletException(lStrings.getString(\"http.non_http\"));  \n\t    }  \n\t  \n\t    this.service(request, response);  \n\t}\n}\n```\n이 메서드에서는 외부에서 받은 ServletRequest, ServletResponse 객체를 각각 HttpServletRequest, HttpServletResponse 객체로 캐스팅해주고 다시 서비스를 호출해주는데, 이때 호출되는 service 메서드는 다음과 같다.\n```java\npublic abstract class HttpServlet extends GenericServlet {\n\n\tprotected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {  \n\t    String method = req.getMethod();  \n\t    if (method.equals(\"GET\")) {  \n\t        long lastModified = this.getLastModified(req);  \n\t        if (lastModified == -1L) {  \n\t            this.doGet(req, resp);  \n\t        } else {  \n\t            long ifModifiedSince;  \n\t            try {  \n\t                ifModifiedSince = req.getDateHeader(\"If-Modified-Since\");  \n\t            } catch (IllegalArgumentException var9) {  \n\t                ifModifiedSince = -1L;  \n\t            }  \n\t  \n\t            if (ifModifiedSince < lastModified / 1000L * 1000L) {  \n\t                this.maybeSetLastModified(resp, lastModified);  \n\t                this.doGet(req, resp);  \n\t            } else {  \n\t                resp.setStatus(304);  \n\t            }  \n\t        }  \n\t    } else if (method.equals(\"HEAD\")) {  \n\t        long lastModified = this.getLastModified(req);  \n\t        this.maybeSetLastModified(resp, lastModified);  \n\t        this.doHead(req, resp);  \n\t    } else if (method.equals(\"POST\")) {  \n\t        this.doPost(req, resp);  \n\t    } else if (method.equals(\"PUT\")) {  \n\t        this.doPut(req, resp);  \n\t    } else if (method.equals(\"DELETE\")) {  \n\t        this.doDelete(req, resp);  \n\t    } else if (method.equals(\"OPTIONS\")) {  \n\t        this.doOptions(req, resp);  \n\t    } else if (method.equals(\"TRACE\")) {  \n\t        this.doTrace(req, resp);  \n\t    } else {  \n\t        String errMsg = lStrings.getString(\"http.method_not_implemented\");  \n\t        Object[] errArgs = new Object[1];  \n\t        errArgs[0] = method;  \n\t        errMsg = MessageFormat.format(errMsg, errArgs);  \n\t        resp.sendError(501, errMsg);  \n\t    }  \n\t}\n}\n```\n들어오는 Request의 종류에 따라 알맞은 doX 메서드를 각각 호출해주고 있다. 이때 doX 메서드들은 자식 클래스인 FrameworkServlet에서 구현되어있는 것들이 호출된다.\n\n```java\npublic abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware {\n\n\t@Override  \n\tprotected final void doGet(HttpServletRequest request, HttpServletResponse response)  \n\t       throws ServletException, IOException {  \n\t  \n\t    processRequest(request, response);  \n\t}  \n\t  \n\t@Override  \n\tprotected final void doPost(HttpServletRequest request, HttpServletResponse response)  \n\t       throws ServletException, IOException {  \n\t  \n\t    processRequest(request, response);  \n\t}  \n\t  \n\t@Override  \n\tprotected final void doPut(HttpServletRequest request, HttpServletResponse response)  \n\t       throws ServletException, IOException {  \n\t  \n\t    processRequest(request, response);  \n\t}\n\t// ... 다른 doX 메서드들\n}\n```\n생각보다 각 doX 메서드에서 해주는 게 없었고 processRequest가 Request에 맞게 처리를 해주고 있다.\n```java\npublic abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware {\n\n\tprotected final void processRequest(HttpServletRequest request, HttpServletResponse response)  \n       throws ServletException, IOException {  \n  \n    // ...  \n  \n\t    try {  \n\t       doService(request, response);  \n\t    }  \n\t    catch (ServletException | IOException ex) {  \n\t       failureCause = ex;  \n\t       throw ex;  \n\t    }  \n\t    catch (Throwable ex) {  \n\t       failureCause = ex;  \n\t       throw new ServletException(\"Request processing failed: \" + ex, ex);  \n\t    }  \n\t  \n\t    // ...\n\t}\n}\n```\nprocessRequest는 내부에서 doService를 호출하고 있고, 이 메서드는 FrameworkServlet의 자식 클래스인 DispatcherServlet에서 구현되어있다.\n```java\npublic class DispatcherServlet extends FrameworkServlet {\n    \n    @Override\n    protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception {\n        logRequest(request);\n\n        // ...\n\n        try {\n            doDispatch(request, response);\n        } finally {\n            // ...\n        }\n    }\n\n    // ...\n\n}\n```\n또 다시 여기서 doDispatch를 호출해주고 있는데 좀 더 자세히 들여다보자.\n```java\npublic class DispatcherServlet extends FrameworkServlet {\n    \n    protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {  \n    HttpServletRequest processedRequest = request;  \n    HandlerExecutionChain mappedHandler = null;  \n    boolean multipartRequestParsed = false;  \n  \n    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);  \n  \n    try {  \n       ModelAndView mv = null;  \n       Exception dispatchException = null;  \n  \n       try {  \n          processedRequest = checkMultipart(request);  \n          multipartRequestParsed = (processedRequest != request);  \n  \n          // Determine handler for the current request.  \n          mappedHandler = getHandler(processedRequest);  \n          if (mappedHandler == null) {  \n             noHandlerFound(processedRequest, response);  \n             return;  \n          }  \n  \n          // Determine handler adapter for the current request.  \n          HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());  \n  \n          // Process last-modified header, if supported by the handler.  \n          String method = request.getMethod();  \n          boolean isGet = HttpMethod.GET.matches(method);  \n          if (isGet || HttpMethod.HEAD.matches(method)) {  \n             long lastModified = ha.getLastModified(request, mappedHandler.getHandler());  \n             if (new ServletWebRequest(request, response).checkNotModified(lastModified) && isGet) {  \n                return;  \n             }  \n          }  \n  \n          if (!mappedHandler.applyPreHandle(processedRequest, response)) {  \n             return;  \n          }  \n  \n          // Actually invoke the handler.  \n          mv = ha.handle(processedRequest, response, mappedHandler.getHandler());  \n  \n          if (asyncManager.isConcurrentHandlingStarted()) {  \n             return;  \n          }  \n  \n          applyDefaultViewName(processedRequest, mv);  \n          mappedHandler.applyPostHandle(processedRequest, response, mv);  \n       }  \n       catch (Exception ex) {  \n          dispatchException = ex;  \n       }  \n       catch (Throwable err) {  \n          // As of 4.3, we're processing Errors thrown from handler methods as well,  \n          // making them available for @ExceptionHandler methods and other scenarios.          dispatchException = new ServletException(\"Handler dispatch failed: \" + err, err);  \n       }  \n       processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);  \n    }  \n    catch (Exception ex) {  \n       triggerAfterCompletion(processedRequest, response, mappedHandler, ex);  \n    }  \n    catch (Throwable err) {  \n       triggerAfterCompletion(processedRequest, response, mappedHandler,  \n             new ServletException(\"Handler processing failed: \" + err, err));  \n    }  \n    finally {  \n       if (asyncManager.isConcurrentHandlingStarted()) {  \n          // Instead of postHandle and afterCompletion  \n          if (mappedHandler != null) {  \n             mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);  \n          }  \n          asyncManager.setMultipartRequestParsed(multipartRequestParsed);  \n       }  \n       else {  \n          // Clean up any resources used by a multipart request.  \n          if (multipartRequestParsed || asyncManager.isMultipartRequestParsed()) {  \n             cleanupMultipart(processedRequest);  \n          }  \n       }  \n    }  \n}\n}\n```\ndoDispatch 메서드를 살펴보면 많은 것들을 해주고 있다.\n\n우선 HandlerMapping을 해주고, 이를 처리할 HandlerAdapter를 조회해주고 있다. 이후에 컨트롤러를 찾아 메서드들을 수행한다.\n### 2. HandlerMapping을 통해 Request 정보에 대한 알맞은 Controller를 찾는다.\n잠깐 되돌아보면, 지금까지 DispatcherServlet은 Request를 받아서 여러 메서드를 거쳐, doDispatch까지 왔다. 이제 DispatchServlet은 개발자가 만들어놓은 컨트롤러 중에서 요청을 처리할  수 컨트롤러를 찾고 해당 객체의 메서드를 호출해야하는데, 이때 컨트롤러를 찾아줄 수 있는 게 HandlerMapping이다.\n\n아래는 위 코드의 일부분을 그대로 가져왔다.\n```java\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {  \n\t// ...\n\t\n\t// Determine handler for the current request.  \n\tmappedHandler = getHandler(processedRequest);  \n\tif (mappedHandler == null) {  \n\t\t noHandlerFound(processedRequest, response);  \n\t\t return;  \n\t} \n\n\t// ...\n}\n\n@Nullable  \nprotected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {  \n    if (this.handlerMappings != null) {  \n       for (HandlerMapping mapping : this.handlerMappings) {  \n          HandlerExecutionChain handler = mapping.getHandler(request);  \n          if (handler != null) {  \n             return handler;  \n          }  \n       }  \n    }  \n    return null;  \n}\n```\n이 코드에서는 요청에 맞는 HandlerExecutionChain(mappedHandler)을 찾아주고 있다. \n\n찾아주는 방법은 다음과 같다. \n\nRequestMappingHandlerMapping은 @Controller로 어노테이트된 모든 컨트롤러를 찾아서 필드로 관리를 해주고 있다. 이 클래스는 필드로 Map<String, Predicate<>> pathPrefixes를 갖고 있어서, key 값에는 요청 정보, value 값에는 처리할 대상을 관리하고 있다.  \n\n처리할 대상은 컨트롤러와 메서드를 담고 있는 HandlerMethod 객체이며, 요청정보로 Map에서 값을 찾고 반환할 때 HandlerExecutionChain으로 감싸서 넘겨준다.\n\nHandlerExecutionChain은 실제 HTTP 요청을 처리하는 handler(컨트롤러 메서드)와 handler 전후에 인증, 로깅 등을 처리할 수 있는 인터셉터로 이루어진다. \n### 3. Request를 Controller로 건내줄 수 있는 HandlerAdapter를 찾아서 건내준다.\n```java\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {  \n\n\t// ...\n\t\n\t// Determine handler adapter for the current request.  \n\tHandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());  \n\n\t// ...\n}\n\nprotected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException {  \n    if (this.handlerAdapters != null) {  \n       for (HandlerAdapter adapter : this.handlerAdapters) {  \n          if (adapter.supports(handler)) {  \n             return adapter;  \n          }  \n       }  \n    }  \n    throw new ServletException(\"No adapter for handler [\" + handler +  \n          \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\");  \n}\n```\nHandlerExecutionChain에는 요청에 맞는 handler가 저장되어있고, 이를 통해 다음과 같이 HandlerAdapter를 조회하고 있다.\n### 4. HandlerAdapter를 통해 Controller 메서드를 호출한다.\nHandlerAdapter는 HandlerExecutionChain을 처리하는 과정에서, 내부적으로 인터셉터를 관리하여 공통적인 전/후 처리 작업을 수행한다. 예를 들어, 컨트롤러 메서드 호출 전에는 적합한 파라미터를 생성하여 전달하는 작업이 필요하고, 호출 후에는 메시지 컨버터를 사용하여 ResponseEntity의 본문을 찾아 JSON 직렬화와 같은 작업을 처리하는 과정이 필요하다.\n\nHandlerAdapter가 요청하는 코드를 살펴보자.\n```java\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {  \n\n\t// ...\n\t\n\t// Actually invoke the handler.  \n\tmv = ha.handle(processedRequest, response, mappedHandler.getHandler()); \n\n\t// ...\n}\n```\n이때 요청의 종류에 따라 HandlerAdapter의 종류가 달라지고, 예시로 @Controller로 어노테이트된 컨트롤러를 처리하는 RequestMappingHandlerAdapter의 코드는 다음과 같다.\n```java\npublic abstract class AbstractHandlerMethodAdapter extends WebContentGenerator implements HandlerAdapter, Ordered {\n\n\t@Override  \n\t@Nullable  \n\tpublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {  \n\t    return handleInternal(request, response, (HandlerMethod) handler);  \n\t}\n}\n\npublic class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter {\n\n\t@Override  \n\t@Nullable  \n\tprotected ModelAndView handleInternal(HttpServletRequest request,  \n\t       HttpServletResponse response, HandlerMethod handlerMethod) throws Exception {  \n\t  \n\t    ModelAndView mav;  \n\t    checkRequest(request);  \n\t  \n\t    // Execute invokeHandlerMethod in synchronized block if required.  \n\t    if (this.synchronizeOnSession) {  \n\t       HttpSession session = request.getSession(false);  \n\t       if (session != null) {  \n\t          Object mutex = WebUtils.getSessionMutex(session);  \n\t          synchronized (mutex) {  \n\t             mav = invokeHandlerMethod(request, response, handlerMethod);  \n\t          }  \n\t       }  \n\t       else {  \n\t          // No HttpSession available -> no mutex necessary  \n\t          mav = invokeHandlerMethod(request, response, handlerMethod);  \n\t       }  \n\t    }  \n\t    // ...\n\t    return mav;  \n\t}\n}\n```\n여기서도 중요한건 invokeHandlerMethod를 호출해주고 있다는 것인데, 이를 통해 컨트롤러로 요청을 위임하고있다.\n```java\npublic class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter {\n\n\t@Nullable  \n\tprotected ModelAndView invokeHandlerMethod(HttpServletRequest request,  \n\t       HttpServletResponse response, HandlerMethod handlerMethod) throws Exception {  \n\t  \n\t    // ...\n\t  \n\t    ServletWebRequest webRequest = (asyncWebRequest instanceof ServletWebRequest ?  \n\t          (ServletWebRequest) asyncWebRequest : new ServletWebRequest(request, response));  \n\t  \n\t    WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod);  \n\t    ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory);  \n\t  \n\t    ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);  \n\t    if (this.argumentResolvers != null) {  \n\t       invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);  \n\t    }  \n\t    if (this.returnValueHandlers != null) {  \n\t       invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers);  \n\t    }  \n\t    \n\t    // ...\t  \n\t    \n\t    invocableMethod.invokeAndHandle(webRequest, mavContainer);  \n\n\t\t// ...\n\t  \n\t    return getModelAndView(mavContainer, modelFactory, webRequest);  \n\t}\n}\n```\nHandlerExecutionChain에는 인터셉터를 통해 전후처리가 진행된다고 했었는데, 이 코드에서는 컨트롤러의 파라미터를 위해 ArgumentResolver가, 반환값 처리를 위해 ReturnValueHandler가 등장한다.\n\n다시 말하면 ArgumentResolver를 통해 컨트롤러의 메서드 인자값을 받고, ReturnValueHandler를 통해 컨트롤러 메서드의 반환값을 얻는 것이다.\n\n세팅이 끝나면 invokeAndHandle이 호출되고, 또 그 내부에서 invokeForRequest가 실행된다.\n```java\npublic class ServletInvocableHandlerMethod extends InvocableHandlerMethod {\n\t\n\tpublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,  \n\t       Object... providedArgs) throws Exception {  \n\t  \n\t    Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);  \n\t    \n\t    // ...\n\t    \n\t    try {  \n\t       this.returnValueHandlers.handleReturnValue(  \n\t             returnValue, getReturnValueType(returnValue), mavContainer, webRequest);  \n\t    }  \n\t    catch (Exception ex) {  \n\t       // ...\n\t       throw ex;  \n\t    }  \n\t}\n}\n\npublic class InvocableHandlerMethod extends HandlerMethod {\n\t\n\t@Nullable  \n\tpublic Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception {  \n\t    Object[] args = this.getMethodArgumentValues(request, mavContainer, providedArgs);  \n\t    // ...\n\t\tObject returnValue = this.doInvoke(args);\n\t    return returnValue;  \n\t}\n}\n```\n여기서는 인자로 받은 값을 받아오는게 중요하다. 우리가 사용하는 어노테이션들을 getMethodArgumentValues에서 처리가 되고 doInvoke에서 만들어진 값으로 컨트롤러의 메서드를 호출한다.\n```java\npublic class InvocableHandlerMethod extends HandlerMethod {\n\t\n\t@Nullable  \n\tprotected Object doInvoke(Object... args) throws Exception {  \n\t    Method method = this.getBridgedMethod();  \n\t  \n\t    try {  \n\t        if (KotlinDetector.isKotlinReflectPresent()) {  \n\t            // ...\n\t        }  \n\t  \n\t        return method.invoke(this.getBean(), args);  \n\t    } catch (IllegalArgumentException var8) {  \n\t        // ...\n\t    } \n\t    return method.invoke(this.getBean(), args);\n    }\n}\n```\n자바의 리플렉션으로 컨트롤러의 메소드 객체를 가져온다. 그리고 method.invoke(this.getBean(), args)로 실제 컨트롤러에게 위임을 해주고 있다.\n\n### 5. 반환값(Response)을 HandlerAdapter에게 건내준다.\n그리고 다시 ServletInvocableHandlerMethod의 invokeAndHandle 메서드로 다시 돌아온다.\n\n```java\npublic class ServletInvocableHandlerMethod extends InvocableHandlerMethod {\n\t\n\t\tpublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,  \n\t       Object... providedArgs) throws Exception {  \n\t  \n\t    Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);  \n\t    \n\t    // ...\n\t    \n\t    try {  \n\t       this.returnValueHandlers.handleReturnValue(  \n\t             returnValue, getReturnValueType(returnValue), mavContainer, webRequest);  \n\t    }  \n\t    catch (Exception ex) {  \n\t       // ...\n\t       throw ex;  \n\t    }  \n\t}\n}\n```\n컨트톨러의 로직이 끝나고 이때 반환값은 returnValue에 담긴다. 이후에는 ReturnValueHandler에서 후 처리를 거친다.\n### 6. 반환값에 따라 ResponseEntity로 감싸는 경우가 있고, 이 형식에 따라 다른 Converter가 동작한다.\n```java\npublic class HandlerMethodReturnValueHandlerComposite implements HandlerMethodReturnValueHandler {\n\tpublic void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception {  \n\t    HandlerMethodReturnValueHandler handler = this.selectHandler(returnValue, returnType);  \n\t    if (handler == null) {  \n\t        throw new IllegalArgumentException(\"Unknown return value type: \" + returnType.getParameterType().getName());  \n\t    } else {  \n\t        handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);  \n\t    }  \n\t}\n}\n```\n어떤 값을 반환하느냐에 따라 HandlerMethodReturnValueHandler 구현체가 정해지고, 예를 들어 ResponseEntity 객체가 반환되는 경우 HttpEntityMethodProcessor가 사용된다.\n```java\npublic class HttpEntityMethodProcessor extends AbstractMessageConverterMethodProcessor {\n\t@Override  \n\tpublic void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,  \n\t       ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception {  \n\t  \n\t    mavContainer.setRequestHandled(true);  \n\t    if (returnValue == null) {  \n\t       return;  \n\t    }  \n\t  \n\t    ServletServerHttpRequest inputMessage = createInputMessage(webRequest);  \n\t    ServletServerHttpResponse outputMessage = createOutputMessage(webRequest);  \n\t  \n\t    HttpEntity<?> httpEntity;  \n\t    if (returnValue instanceof ErrorResponse response) {  \n\t       httpEntity = new ResponseEntity<>(response.getBody(), response.getHeaders(), response.getStatusCode());  \n\t    }  \n\t    else if (returnValue instanceof ProblemDetail detail) {  \n\t       httpEntity = ResponseEntity.of(detail).build();  \n\t    }  \n\t    else {  \n\t       Assert.isInstanceOf(HttpEntity.class, returnValue);  \n\t       httpEntity = (HttpEntity<?>) returnValue;  \n\t    }  \n\t  \n\t    // ... \n\t  \n\t    // Try even with null body. ResponseBodyAdvice could get involved.  \n\t    writeWithMessageConverters(httpEntity.getBody(), returnType, inputMessage, outputMessage);  \n\t  \n\t    // Ensure headers are flushed even if no body was written.  \n\t    outputMessage.flush();  \n\t}\n}\n```\n이 메서드는 응답가능한 타입인지 확인해주고 적절한 Converter와 응답을 처리할 수 있게 해준다.\n```java\npublic abstract class AbstractMessageConverterMethodProcessor extends AbstractMessageConverterMethodArgumentResolver  \n       implements HandlerMethodReturnValueHandler {\n\n\tprotected <T> void writeWithMessageConverters(@Nullable T value, MethodParameter returnType,  \n       ServletServerHttpRequest inputMessage, ServletServerHttpResponse outputMessage)  \n       throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException {  \n  \n\t    // ...\n\t  \n\t    if (isResourceType(value, returnType)) {  \n\t       outputMessage.getHeaders().set(HttpHeaders.ACCEPT_RANGES, \"bytes\");  \n\t       if (value != null && inputMessage.getHeaders().getFirst(HttpHeaders.RANGE) != null &&  \n\t             outputMessage.getServletResponse().getStatus() == 200) {  \n\t          Resource resource = (Resource) value;  \n\t          try {  \n\t             List<HttpRange> httpRanges = inputMessage.getHeaders().getRange();  \n\t             outputMessage.getServletResponse().setStatus(HttpStatus.PARTIAL_CONTENT.value());  \n\t             body = HttpRange.toResourceRegions(httpRanges, resource);  \n\t             valueType = body.getClass();  \n\t             targetType = RESOURCE_REGION_LIST_TYPE;  \n\t          }  \n\t          catch (IllegalArgumentException ex) {  \n\t             outputMessage.getHeaders().set(HttpHeaders.CONTENT_RANGE, \"bytes */\" + resource.contentLength());  \n\t             outputMessage.getServletResponse().setStatus(HttpStatus.REQUESTED_RANGE_NOT_SATISFIABLE.value());  \n\t          }  \n\t       }  \n\t    }\n\t}\n\t\n\t// ...\n\n\tif (selectedMediaType != null) {  \n\t\tselectedMediaType = selectedMediaType.removeQualityValue();  \n\t  \n\t    ResolvableType targetResolvableType = null;  \n\t    for (HttpMessageConverter converter : this.messageConverters) {  \n\t       ConverterType converterTypeToUse = null;  \n\t       if (converter instanceof GenericHttpMessageConverter genericConverter) {  \n\t          if (genericConverter.canWrite(targetType, valueType, selectedMediaType)) {  \n\t             converterTypeToUse = ConverterType.GENERIC;  \n\t          }  \n\t       }  \n\t       else if (converter instanceof SmartHttpMessageConverter smartConverter) {  \n\t          targetResolvableType = getNestedTypeIfNeeded(ResolvableType.forMethodParameter(returnType));  \n\t          if (smartConverter.canWrite(targetResolvableType, valueType, selectedMediaType)) {  \n\t             converterTypeToUse = ConverterType.SMART;  \n\t          }  \n\t       }  \n\t       else if (converter.canWrite(valueType, selectedMediaType)){  \n\t          converterTypeToUse = ConverterType.BASE;  \n\t       }  \n\t       if (converterTypeToUse != null) {  \n\t          body = getAdvice().beforeBodyWrite(body, returnType, selectedMediaType,  \n\t                (Class<? extends HttpMessageConverter<?>>) converter.getClass(), inputMessage, outputMessage);  \n\t          if (body != null) {  \n\t             Object theBody = body;  \n\t             LogFormatUtils.traceDebug(logger, traceOn ->  \n\t                   \"Writing [\" + LogFormatUtils.formatValue(theBody, !traceOn) + \"]\");  \n\t             addContentDispositionHeader(inputMessage, outputMessage);  \n\t             switch (converterTypeToUse) {  \n\t                case BASE -> converter.write(body, selectedMediaType, outputMessage);  \n\t                case GENERIC -> ((GenericHttpMessageConverter) converter).write(body, targetType, selectedMediaType, outputMessage);  \n\t                case SMART -> ((SmartHttpMessageConverter) converter).write(body, targetResolvableType, selectedMediaType, outputMessage, null);  \n\t             }  \n\t          }  \n\t          else {  \n\t             if (logger.isDebugEnabled()) {  \n\t                logger.debug(\"Nothing to write: null body\");  \n\t             }  \n\t          }  \n\t          return;  \n\t       }  \n\t    }  \n\t}\n\t\n\t// ...\n\t\n}\n```\n\n## Summary (by ChatGPT)\nSpring MVC의 `DispatcherServlet` 처리 흐름을 목록으로 정리한 내용은 다음과 같다:\n1. **DispatcherServlet**:\n\t- 클라이언트 요청을 중앙에서 처리하는 역할\n\t- `HandlerMapping`, `HandlerAdapter`, `ReturnValueHandler` 등 delegate components를 사용하여 요청을 처리\n2. **HandlerExecutionChain**:\n    - 실제 핸들러(컨트롤러 메서드)와 이를 전후로 처리할 인터셉터들을 관리\n    - 요청에 맞는 핸들러와 인터셉터를 찾아 전후 처리 작업 수행\n3. **HandlerMapping**:\n    - 요청에 맞는 컨트롤러를 찾아 반환\n4. **HandlerAdapter**:\n    - 컨트롤러 메서드를 호출하기 위한 어댑터 역할\n    - 적합한 `ArgumentResolver`로 파라미터를 처리하고, `ReturnValueHandler`로 반환값을 처리\n5. **ArgumentResolver**:\n    - 컨트롤러 메서드의 파라미터 값을 생성하여 전달\n6. **ReturnValueHandler**:\n    - 컨트롤러 메서드의 반환값을 처리\n    - 반환값에 따라 적합한 메시지 컨버터를 사용하여 직렬화 처리\n7. **MessageConverter**:\n    - 반환값을 직렬화하여 클라이언트에게 전달\n    - 예: `StringHttpMessageConverter`, `MappingJackson2HttpMessageConverter` 등\n8. **최종 처리**:\n    - 반환값이 `ResponseEntity`라면, 적합한 `HttpMessageConverter`로 직렬화하여 응답 처리"},{"excerpt":"레벨 1이 끝났다. 8주라는 시간이 눈 깜짝할 사이에 사라졌다. 너무도 짧게 느껴졌지만, 돌아보면 정말 많은 것을 배우고 느낀 기간이었고, 기억이 희미해지기 전에 회고하고자 한다. 열정적인 사람들 언제나 열정적인 사람들과 함께하는 건 재미있다. 내가 꽤나 사람을 좋아하는 사람이구나...를 느낄 수 있었다. 무엇을 하느냐도 중요하지만 누구랑 함께 하느냐가 …","fields":{"slug":"/우아한테크코스_7기_BE_레벨1_회고/"},"frontmatter":{"date":"2025년 04월 13일 09:04","title":"우아한테크코스 7기 BE 레벨1 회고","tags":["우아한테크코스","회고"]},"rawMarkdownBody":"\n레벨 1이 끝났다. 8주라는 시간이 눈 깜짝할 사이에 사라졌다. 너무도 짧게 느껴졌지만, 돌아보면 정말 많은 것을 배우고 느낀 기간이었고, 기억이 희미해지기 전에 회고하고자 한다.\n\n## 열정적인 사람들\n언제나 열정적인 사람들과 함께하는 건 재미있다. \n\n내가 꽤나 사람을 좋아하는 사람이구나...를 느낄 수 있었다. 무엇을 하느냐도 중요하지만 누구랑 함께 하느냐가 더 중요하다는 걸 다시 한 번 체감하고 있다. \n\n레벨1 데일리 조원으로  [강산](https://github.com/m-a-king), [띠용](https://github.com/jye326), [링크](https://github.com/sonjh919), [벡터](https://github.com/Byesol), [에드](https://github.com/jinu0328), [율무](https://github.com/yeezy-com), [제프](https://github.com/horizonpioneer), [칼리](https://github.com/2Jin1031), [폰트](https://github.com/yeong0jae)를, 코치로는 [저스틴](https://github.com/liquidjoo)을 만났다. 각자 색깔은 달라도 항상 다른 사람의 크고 작은 고민들에 대해 같이 고민해주고 의문을 품어줄 수 있는 사람들이어서 그만큼 편하게 질문하고, 같이 떠들고, 그 과정에서 많은 걸 배울 수 있었다.\n\n그 중에서도 하나를 꼽자면, \"이야기하기 위한 사고력\"을 기를 수 있었던 것 같다. 저렇게 표현하는 게 맞나 싶기도 하지만, 그동안은 개발관련, 혹은 지식 공유를 위한 이야기를 하면서 내 생각조차 정립되지 않는 경우가 많았었다. 그러다보니 내 의견이 아닌 어디선가 들은 이야기, 책이 말하고 있는 이야기를 그대로 듣고 그대로 말하는 경우가 많았던 것 같은데, 이 사람들이 지속적으로 내 생각을 톡톡 건드려준 덕에 내가 사고한 것들, 내가 정의하는 내 의견을 찾아갈 수 있었던 것 같다. \n\n그리고 다시 한 번, 지식의 습득은 책이나 문서가 아니라 누군가에게 물어봤을 때 가장 빠르게 일어난다는 것을 느꼈다. 이 때문에 내가 사람들이랑 떠드는 걸 좋아한다. 열심히 듣다가 궁금한 게 생겨서 물어보면 누구나 친절하게 그것도 아주 자세히 설명을 해준다. 이럴 때마다 나도 누군가에게 지식을 전파할 수 있는 사람이 되어야겠다고, 이런 선순환을 만들 수 있는 사람이 되어야겠다고 다시금 다짐한다.\n\n## 라떼는 말야...\n우테코는 모든 게 피드백이다. 코딩을 하든, 인터뷰를 하든, 뭐만 하면 피드백이다. 지금까지 지나온 환경에서 이렇게까지 피드백이 많았던 환경이 없어서 그런지 처음에는 나에게 쏟아지는 피드백에 왠지 모를 거부감이 들었다. 피드백은 피드백으로써 남겨야하는데 더나아가서 나에 대한 공격으로 받아드려서 더욱 방어적 태도를 취했던 것 같다. 또 고집스러운 내 성격도 한 몫하지 않았나 싶다 ㅎㅎ.\n\n하지만 어느 시점에서 '변화하고자, 배우고자 이 곳에 왔는데 여전히 같은 모습이다' 라는 생각이 문득 들었다. \n다른 사람의 이야기에 무조건 흔들리지 않는 것도 중요하지만, 동시에 그들의 피드백에서 받아들일 건 받아들이는 태도 역시 필요하다는 걸 깨달았다.\n\n지금은 어느 정도 중간 지점을 찾은 것 같다. 적어도 처음보다는 내 모습을 더 잘 이해하고, 스스로를 돌아보는 힘도 생겼다.\n\n## 소프트스킬\n레벨1에서 가장 기억에 남는 부분이다. 페어 프로그래밍을 하면서 더더욱 소프트 스킬의 중요성을 깨달았다. 어느 분야든, 나와 다른 사람과 같이 살아가려면 꼭 필요한 능력 중 하나, 길러야될 덕목이라고 생각한다. \n\n분명 레벨1을 마무리할 때는 꽤나 만족스럽게 나를 되돌아보고 보완했다고 생각했는데, 지금 회고를 하며 다시 생각해보니 레벨1 초반과 그렇게 크게 바뀐 것 같지 않다는 생각도 스쳐가고 있다. 레벨2에는 지금보다 소프트스킬 향상에 더 많은 시간을 투자하고, 좀 더 나를 객관적인 시선에서 바라볼 수 있으면 좋겠다.\n\n## 앞으로는?\n아직 레벨1만 끝났고 8개월이 더 남았다. 우테코라는 교육과정이 정말 재미있고, 좋은 개발자로 성장하는 데 많은 도움을 주는 것 같긴 하지만 조금 더 욕심을 내보고 싶다.\n\n레벨1을 하면서 이 과정에 몰입했다고 생각하고, 개발 지식 내외적으로 많은 것들을 배운 것 같지만 좀 더 넓은 시각으로 봐야겠다는 생각이 들었다. 레벨1 과정에서도 아무리 다 다른 생각을 갖고 설계를 해내가지만, 오답을 피하다보면 어느 순간 다 비슷한 코드를 짜고 있는 것 같았다. 이런 모습이 나쁘다고는 말할 수 없다. 누구나 이해할 수 있는 설계와 코드를 작성하는 건 나 역시 중요하다고 생각한다. 하지만 이런 공장에서 찍어낸듯한 생산품같이, 다같은 개발자가 되는 건 질색이다. 좀 더 나 다운, 좀 더 재미있는 생각과 설계를 할 수 있는 사람이 되고 싶었다.\n\n그럼 어떻게 해야할까?\n\n아직 열심히 고민 중이다. 어려운 것 같다. 이에 대한 해답을 레벨2에서 찾고 싶다. 레벨2에서도 지금처럼 많이 고민하고, 시도해보고, 실패하고 깨달았으면 좋겠다. 아자아자화이팅.\n\n\n\n\n"},{"excerpt":"TODO 검색 없이 git, github를 할 수 있을 정도로 공부하기 고민거리와 자료들 해결 전 getter 없이 extracting으로 필드 검사가 안좋을 수도 있나? 질문 잘하는 법이란? 런타임 컴파일타임 의존성이란? 제네릭 공변, 블공변이란? 해결 중 해결 완료 getter 대신 객체에게 메시지를 보내자 toList() vs collect(Coll…","fields":{"slug":"/우아한테크코스 레벨1 고민거리와 자료들/"},"frontmatter":{"date":"2025년 02월 14일 09:02","title":"우아한테크코스 레벨1 고민거리와 자료들","tags":["우아한테크코스","레벨1"]},"rawMarkdownBody":"## TODO\n- 검색 없이 git, github를 할 수 있을 정도로 공부하기\n\n## 고민거리와 자료들\n\n### 해결 전\n- [getter 없이 extracting으로 필드 검사](https://www.baeldung.com/java-extract-values-assertj)가 안좋을 수도 있나?\n- 질문 잘하는 법이란?\n- 런타임 컴파일타임 의존성이란?\n- 제네릭 공변, 블공변이란?\n\n### 해결 중\n- \n\n\n### 해결 완료\n- [getter 대신 객체에게 메시지를 보내자](https://tecoble.techcourse.co.kr/post/2020-04-28-ask-instead-of-getter/)\n- toList() vs collect(Collectors.toList())\n\t- toList() : UnModifiableList 또는 UnmodifiableRandomAccessList 반환\n\t- collect(Collectors.toList()) : ArrayList 반환\n- 순서에 맞게 정렬해서 출력을 해야하면, \"정렬\"은 view에서 하는 게 맞는가? 아니면 미리 해서 view에게 넘겨줘야하는가?\n\t- 설계에 따라 다르다\n\t- 요구사항에 따라 다르지만 우선 view 역할이라고 생각함\n- `모든 원시값을 포장한다`를 어느 수준까지 지켜야할까?\n\t- 저 말의 의미는, 역할이 있는 원시값이면 포장해야한다라고 생각함. 역할이 없고, 이 인스턴스 변수를 갖는 클래스의 하나의 역할로써 존재한다면 굳이 포장할 필요는 없다고 생각함.\n- TDD는 바텀업?\n\t- 바텀업으로 구현을 하되, 뭐부터 해야할지 막히는 시점에서는 탑다운을 해도 좋다!\n- 미리 작성한 메소드들 어떻게 다 기억하나?\n\t- 며칠 전에 만들어둔 메소드가 있는데, 난 다른 이름의 동일 기능을 하고 있는 메소드를 짜고 있음\n\t- 코드 베이스를 그때그때 확인해라..\n-  mvc패턴에서 validation의 책임은 누구에게? [참고 자료](https://velog.io/@pengoose_dev/MVC-Pattern%EC%97%90%EC%84%9C-%EC%9C%A0%ED%9A%A8%EC%84%B1-%EA%B2%80%EC%82%AC%EB%8A%94-%EB%88%84%EA%B5%AC%EC%9D%98-%EC%B1%85%EC%9E%84%EC%9D%B8%EA%B0%80#230724---%EC%B2%AB-%EA%B2%B0%EB%A1%A0%EC%9D%80-controller)\n\t- 우선, model에서는 model에 관련된 validation만!\n\t\t- ex) Lotto에서는 로또번호의 개수 및 중복체크만, LottoNumber는 범위체크\n\t- 나머지 validation, 예를 들어 문자열, 정수와 같은 형식이나 null 및 공백과 같은 체크는 Controller!\n\t- 서비스의 흐름을 제어하는 주체는 Controller라고 생각함.\n\t- 대신 Controller의 로직이 너무 복잡해지고 길어지면 View에 validation 책임을 넘겨줘도 된다고 생각함\n- 테스트코드 커버리지를 100%을 달성하면서 도메인을 다 구현했는데 컨트롤러를 구현하면서 더 필요한 메소드들이 생기고, 결국 커버리지가 다시 낮아짐. \n\t- 모든 메소드들을 고려면서 tdd를 하는 건 불가능. 커버리지가 낮아지는 게 맞다고 생각함. \n\t- 이후에 다시 커버리지를 올리는 것을 목표로\n-  필요할 것 같아서 만들어둔 메소드들이 컨트롤러에서 기능들을 합치면서 안필요해짐. 그럼 테스트 코드를 위한 코드가 되는게 아닌가?\n\t- 사용안되는 코드가 되어버리면 삭제해야함.\n\t- 프로덕션 코드에 테스트만을 위한 코드가 있으면 안된다고 생각함.\n- \"객체지향의 사실과 오해\" 읽기\n\t- 책임이 자율적일수록 적절하게 '추상화'되며, '응집도'가 높아지고, '결합도'가 낮아지며, '캡슐화'가 증진되고, '인터페이스와 구현이 명확히 분리'되며, 설계의 '유연성'과 '재사용성'이 향상된다.\n\n\n"},{"excerpt":"","fields":{"slug":"/DH_채용설명회/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":null,"tags":null},"rawMarkdownBody":"\n\n"},{"excerpt":"git remote add pair https:sdfsdfsdf\ngit fetch pair\ngit rebase pair/step1 // 무조건 step1에서 나가야됨\ngit checkout main\ngit remote add upstream https://github.com/woowacourse/spring-roomescape-payment\ngit fet…","fields":{"slug":"/우테코 git/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":"우아한테크코스 GitHub","tags":["우아한테크코스"]},"rawMarkdownBody":"\ngit remote add pair https:sdfsdfsdf\ngit fetch pair\ngit rebase pair/step1\n\n// 무조건 step1에서 나가야됨\ngit checkout main\ngit remote add upstream https://github.com/woowacourse/spring-roomescape-payment\ngit fetch upstream theminjunchoi\ngit rebase upstream/theminjunchoi\ngit checkout -b step2\n\ndocker exec -it my-mysql-container mysql -u ec2_user -p\n\nprod용 db\nssh -i key-coffee_shout.pem ubuntu@43.203.229.152"},{"excerpt":"인프라 및 서비스 구성 설명서 개요 제가 설계하고 구축한 Spring Boot 애플리케이션 배포 인프라는 개발과 운영 환경을 분리하여 안정성과 확장성을 보장하는 아키텍처입니다. 이 구성을 통해 개발 단계에서의 빠른 반복과 운영 환경에서의 높은 가용성을 동시에 달성할 수 있도록 설계했습니다. 전체 아키텍처 구성 1. 환경 분리 전략 개발 환경 (Dev) 컴…","fields":{"slug":"/우테코_레벨3_정리/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":null,"tags":null},"rawMarkdownBody":"# 인프라 및 서비스 구성 설명서\n\n## 개요\n\n제가 설계하고 구축한 Spring Boot 애플리케이션 배포 인프라는 개발과 운영 환경을 분리하여 안정성과 확장성을 보장하는 아키텍처입니다. 이 구성을 통해 개발 단계에서의 빠른 반복과 운영 환경에서의 높은 가용성을 동시에 달성할 수 있도록 설계했습니다.\n\n## 전체 아키텍처 구성\n\n### 1. 환경 분리 전략\n\n**개발 환경 (Dev)**\n\n- **컴퓨팅**: AWS EC2 인스턴스 (Amazon Linux 2023, ARM64)\n- **데이터베이스**: Docker MySQL 8.0 컨테이너\n- **배포 트리거**: dev 브랜치 push 시 자동 배포\n- **특징**: 빠른 개발 사이클을 위한 컨테이너 기반 구성\n\n**운영 환경 (Prod)**\n\n- **컴퓨팅**: 동일한 EC2 인스턴스 (리소스 공유)\n- **데이터베이스**: AWS RDS MySQL 8.0 (별도 인스턴스)\n- **배포 트리거**: prod 브랜치 push 시 자동 배포\n- **특징**: 데이터 영속성과 가용성을 위한 관리형 서비스 활용\n\n### 2. CI/CD 파이프라인 설계\n\n**GitHub Actions 기반 자동화**\n\n- **Self-hosted Runner**: EC2 인스턴스에 직접 설치하여 배포 지연시간 최소화\n- **단일 워크플로우**: 브랜치별 조건부 실행으로 관리 복잡성 감소\n- **환경별 분기 처리**: 런타임에 브랜치 정보를 기반으로 환경 설정 자동 선택\n\n### 3. 데이터베이스 전략\n\n**개발 환경의 Docker MySQL**\n\n- **장점**: 빠른 프로토타이핑과 스키마 변경 테스트 가능\n- **데이터 보존**: Docker Volume 설정으로 컨테이너 재시작 시에도 데이터 유지\n- **설정**: `ddl-auto: update`로 스키마 자동 업데이트\n\n**운영 환경의 RDS**\n\n- **장점**: 자동 백업, Multi-AZ 배포, 모니터링 기능 내장\n- **보안**: 프라이빗 서브넷 배치, EC2 보안그룹을 통한 접근 제한\n- **설정**: `ddl-auto: validate`로 스키마 무결성 검증\n\n**네트워크 보안**\n\n- RDS는 프라이빗 서브넷에 배치\n- 보안그룹을 통해 EC2에서만 3306 포트 접근 허용\n- 애플리케이션은 8080 포트로 외부 접근 제한적 허용\n\n**민감정보 관리**\n\n- GitHub Secrets를 통한 운영 환경 설정 관리\n- 개발 환경은 하드코딩된 개발용 계정 사용\n- JWT Secret 등 보안 키는 환경별 분리"},{"excerpt":"How are you doing Ha yuh doin What's up this weekend I'm gonna kick back going to relax and stop doing things I slept in get up late (on purpose) What do you do for a living I'm into sports My knee w…","fields":{"slug":"/daily_easy_english_expression_summary/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":"Daily Easy English Expression","tags":null},"rawMarkdownBody":"1. How are you doing\n\t- Ha yuh doin\n2. What's up this weekend\n3. I'm gonna kick back\n\t- going to relax and stop doing things\n4. I slept in\n\t- get up late (on purpose)\n5. What do you do for a living\n6. I'm into sports\n7. My knee went out\n8. I overslept\n9. to stock up on something\n\t- to buy a large quantity of something\n10. to count on\n11. Did you get out ~ing?\n12. pure nonsense\n13. to do away with\n14. I had a long week\n15. TGIF\n\t- Thank God It's Friday\n16. to do something up\n17. to do up something\n18. because of ~\n19. thanks to ~\n20. in a jiffy\n\t- very soon\n21. Do it over\n\t- try again\n22. pick up your poison\n23. poor children\n24. pathetic\n25. What purpose does it serve?\n26. I couldn't help it\n27. to look away\n28. to push it\n29. Are you done yet?\n30. "},{"excerpt":"Pasted image 20251103152807.png\nPasted image 20251103155748.png\nPasted image 20251103155757.png\nPasted image 20251103160332.png 신입 개발자 기대 역량 개발 스킬 언어를 다룰 수 있어야함 문제 인지, 어케 풀지 고민 설명할 줄 알아야함 그 과정에서 주도해나…","fields":{"slug":"/우형_채용설명회/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":null,"tags":null},"rawMarkdownBody":"![[Pasted image 20251103152807.png]]\n![[Pasted image 20251103155748.png]]\n![[Pasted image 20251103155757.png]]\n![[Pasted image 20251103160332.png]]\n\n신입 개발자 기대 역량\n- 개발 스킬\n\t- 언어를 다룰 수 있어야함\n- 문제 인지, 어케 풀지 고민\n\t- 설명할 줄 알아야함\n\t- 그 과정에서 주도해나가고, 피드백 잘 받고\n\t- 소통 잘되고\n\n신입이라도 같이 일하고 싶은 개발자 특징\n- 즐겁게 사람들과 이야기를 주고 받을 수 있는\n- 편하게 이야기할 수 있는\n\n우테코 출신에게 특히 기대하고 중요하게 보는 부분\n- 얼추 아는 시기\n- 사람들과 융화될 수 있어야함 (너무 많이 앎)\n- 여러 신입들 중에서 잘함, 대신 거기서 멈추지 않아야함\n- 아무리 일을 잘해도 주변 사람과 공유할 수 있어야\n\t- 설명, 소통 잘해야함\n\ncs 기본기, 알고리즘 얼만큼 알아야함?\n- 본질 여전히 중요\n\n코테 난이도\n- \n\n"},{"excerpt":"P.1 안녕하세요.\n분산환경에서 게임 구현을 위한 Redis 사용기를 주제로 발표를 진행할 엠제이라고 합니다.\n이제 다들 테코톡이 끝나서 그런지 편안한 얼굴로 앉아계시네요.\n미미만 안좋은 것 같아요. 그럼 시작하겠습니다. P.2 들어가기 앞서, 오늘 발표할 내용은 저희 커피빵이라는 서비스 개발 과정 중 일부입니다.\n그래서 다른 도메인에서는 오늘 내용이 유…","fields":{"slug":"/테코톡/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":null,"tags":null},"rawMarkdownBody":"### P.1\n안녕하세요.\n분산환경에서 게임 구현을 위한 Redis 사용기를 주제로 발표를 진행할 엠제이라고 합니다.\n이제 다들 테코톡이 끝나서 그런지 편안한 얼굴로 앉아계시네요.\n미미만 안좋은 것 같아요. 그럼 시작하겠습니다.\n### P.2\n들어가기 앞서, 오늘 발표할 내용은 저희 커피빵이라는 서비스 개발 과정 중 일부입니다.\n그래서 다른 도메인에서는 오늘 내용이 유효하지 않을 수도 있다는 점을 미리 밝힙니다.\n### P.3\n우선 몇가지, 여러분들이 알고 넘어가야할 내용이 있는데요. \n첫 번째는, 저희 서비스 완전 초창기 모습입니다. 너무 단순하고 이쁘죠?\n저희 서비스는 한 번씩 써보셨으면 알텐데, 게임을 번복하거나, 전날 게임 기록을 불러온다는지 하는 기능이 없기 때문에 데이터 베이스가 필요가 없었어요. 그래서 단순히 메모리에서만 구현을 했었습니다.\n\n두 번째는, 스프링에서 웹소켓 통신을 구현한 방법이에요. \n루키의 테코톡을 보고 오시면 더 자세히 이해를 할 수 있는데요, \n오늘 이 발표에서 필요한 내용만 요약하면 다음과 같아요.\n처음에 클라이언트와 서버가 handshake를 하면 tcp 연결이 수립이 돼요.\n### P.4\n그럼 스프링은 내부적으로 클라이언트의 sessionId를 관리를 하게 되는데, 이 덕분에 추후 서버가 클라이언트들에게 다같이 broadcast를 해줘야할 때 관리를 하고 있는 클라이언트들의 sessionId를 보고 메시지를 전송을 할 수 있습니다.\n\n본격적인 내용을 이해하기 위한 모든 준비가 된 것 같아요. \n### P.5\n자 이제 더 많은 사용자들이 이 서비스에 몰리면 어떻게 될까요?\n실제로 부하 테스트를 해보면 생각보다 이 인스턴스는 웹소캣 메시지를 수신하고, 송신하는데 병목 현상이 생긴다는 걸 확인할 수 있었는데요. 1차적으로 이를 해결할 수 있는 방법은 역시\n### P.6\n스케일아웃하는 것이었습니다. 웹소켓 메시지를 송수신할 수 있는 인스턴스를 늘리면 병목을 해결할 수 있는데요. \n그럼 다음과 같은 문제가 생깁니다. \n이제부터 잘 따라오셔야해요.\n### P.7\n저희 서비스에 카드게임이 있는데 다들 아시죠?\n예를 들어 유저1이 카드를 하나 선택했다고 해봅시다. 그리고 이때 유저1이 인스턴스A에게 연결되어 있었다면, 카드가 선택됐다는 메시지도 역시 인스턴스A에게로 갈텐데요.\n### P.8\n기존 방식이라면 로컬 메모리에서 관리되던 게임 데이터가 업데이트가 되고, 인스턴스A가 관리하던 유저들에게 브로드캐스트를 해줄거에요. 하지만 이러면 문제가 생기죠.\n\n같은 방에 플레이하던 유저가 인스턴스B에게 연결이 되어있었다면,\n인스턴스B는 오래된 게임데이터를 갖고 있게 되고, 인스턴스B에 연결되어있던 유저들도 업데이트를 못 받게 돼요.\n### P.9\n이처럼 게임 상태와 유저 정보를 어디에 저장하고 어떻게 동기화할거냐! 가 이 상황의 핵심 문제입니다.\n### P.10\n우선 여러 인스턴스가 함께 정보를 공유하는 방법에 대해 생각해봤는데요.\n게임 상태를 어디에 저장할 수 있을까 고민을 해봤는데 처음에 이렇게 3개가 떠올랐어요. \n늘 사용하던 DB, 글로벌 캐시, 혹은 로컬캐시도 가능하지 않을까 생각이 들었습니다.\n\n그럼 이렇게 저장을 하면, 값을 업데이트 한 인스턴스말고도 다른 인스턴스도 이 변화했다는 점을 알아야하잖아요? 이를 위해 Redis를 사용할 수 있겠다는 생각이 들었습니다. 다들 여기저기서 Redis에 대해 한 번쯤은 들어보셨을텐데, 이를 간략하게 설명하면,\n### P.11\nRemote Dictionary Server라고 해서, 인메모리 데이터 저장소를 뜻합니다.\n우리가 자주 사용하는 Mysql처럼 디스크에서 데이터들을 관리하는 게 아니라 메모리에서 관리를 하기 때문에 디스크 IO가 없어서 비교적 빠르다는 특징이 있어요.\n### P.12\n이제 이런 애를 어디에 쓸 수 있냐!하면 다음과 같은 곳들에서 사용할 수 있는데요.\n여러 인스턴스에서 사용하는 데이터를 중앙에서 관리, 혹은 캐싱을 한다거나 메시지를 전달해주는 브로커 역할을 한다거나, 뿌려지는 이벤트를 기반으로 집계 및 분석을 할 수가 있어요.\n오늘 이 곳에서는 중앙 세션 저장소와 메시지 브로커로서 Redis를 사용해보겠습니다.\n### P.13\n우선 방금 보여드렸던 3가지 옵션 중에 첫 번째, 우리가 늘 사용하던 DB에 게임 상태를 저장해볼게요.\n### P.14\n똑같이 유저1이 카드를 선택하면 메시지가 기존 연결되어있던 인스턴스A에게 흘러갈텐데, 이때 A는 DB에서 게임을 조회하고, 객체로서 비즈니스 로직을 처리하고 다시 저장을 하게 될거에요.\n그리고 Redis가 없다면, 그대로 인스턴스A는 본인이 관리하고 있는 유저들에게만 브로드캐스트를 할텐데, 그럼 여전히 인스턴스B에서는 DB가 바뀌었는지 알 수가 없어서 기존과 같은 문제가 생기고 있습니다.\n### P.15\n이제 이 상황에서 Redis가 어떻게 사용되는지 보여드릴게요.\n### P.16\n여전히 게임 상태는 DB에서 관리를 하고 있고요. 이제는 Redis가 생겼습니다.\n### P.17\n똑같이 카드 선택 메시지를 인스턴스A가 받아서, DB로부터 값을 조회하고, 변경해서 저장까지 하게 되는데, \n### P.18\n이때 바로 본인이 관리를 하던 유저들에게 브로드캐스트를 하는게 아니라 Redis에 메시지를 보내요.\n이 메시지는 DB가 변경됐다는 정보를 담고 있는데요.\n### P.19\n이때 Redis는 그 메시지를 그대로, 본인과 연결되어있는 모든 인스턴스들에게 전달을 해요. 브로킹을 하고 있는거죠. 그러면 모든 인스턴스는 이 메시지, 즉 이벤트를 수신을 해서\n### P.20\n바뀐 DB를 다시 조회하러갑니다.\n### P.21\n그리고 변경된 값을 찾아서 각 인스턴스가 관리를 하는 유저들에게 브로드캐스트를 해줄 수 있어요.\n앞서 설명한 과정대로 전파를 하면 같은 방에 참여를 하고 있는 모든 유저들은 거의 동시에 메시지를 수신할 수 있습니다.\n### P.22\n이제 다시 장단을 따져볼까요?\n우선 늘 사용하던 죽마고우 같은 DB, 대부분 편리하게 JPA를 사용하게 될텐데 이렇게 하면 러닝커브 없이 이 문제를 풀 수 있는게 장점이에요. 하지만 어쩔 수 없이 생기는 네트워크 비용마다 DB에서는 디스크를 조회해서 값을 찾아오기 때문에 느릴 수가 있어요. 그럼 2번째 방법을 봐볼까요\n### P.23\n이 방법은 기존에 늘 사용하던 Mysql같은 RDBMS없이 Redis로만 구현한 방법인데요. \n보시는 것처럼 각 인스턴스는 본인의 로컬 메모리에서 게임상태를 관리하지 않고 전부 Redis라는 글로벌 캐시에서 관리를 하고 있어요. 똑같이 흐름을 따라가볼게요.\n### P.24\n유저1이 카드 선택을 해서 메시지가 인스턴스A에게 꽂히게 됩니다. 이때 인스턴스A는 Redis에 저장된 값을 불러와서 비즈니스 로직을 처리하고 다시 Redis에 저장을 하게돼요.\n### P.25\n그리고 Redis에게 메시지를 쏩니다. \n### P.26\n그럼 기존1에서와 마찬가지로, Redis는 받은 메시지를 그대로 브로킹해서 본인과 연결되어있는 인스턴스들에게 송신을 하고 \n### P.27 \n그 메시지를 받은 인스턴스들은 Redis에서 변경된 값을 찾아와서 \n### P.28\n거의 동시에 본인들이 관리하던 유저들에게 브로드 캐스트를 해줘요.\n### P.29\n이것도 장단점을 따져볼까요?\n2번 방법에서는 Redis를 중앙 세션 저장소로 쓰고, 메시지 브로커로도 사용해봤는데, 1번의 방식보다 빠른 읽기/쓰기가 가능합니다. 하지만 구현과정에서는 저장할 때 객체를 풀어헤쳐서 Redis에 저장하고, 조회할 땐 String이나 json 형태로 저장된 값을 그대로 읽어서 하나하나 객체로 변환해줘야하는 객체 직렬화/역직렬화가 필요했고, 비즈니스 로직 전개과정에서도 직렬과/역직렬화가 너무 자주 일어나서 확실히 오래걸리는 걸 체감할 수 있었어요. 이 문제는 도메인 객체가 복잡하고 커질수록 심해졌습니다. \n또 Redis는 내부적으로 단일 쓰레드로만 작업을 하고 있는데, 외부에서 Redis에게 요청을 많이 보내면 보낼 수록 이 Redis의 CPU 사용률이 올라갈 수 있어요.\n그리고 또 역시 당연하게도 로컬 메모리에서 작업하는 것보단 느리죠.\n### P.30\n이제 마지막으로 로컬캐시에서 게임 상태를 관리하는 방법에 대해 알아볼게요.\n이 그림처럼 현재 게임 상테는 각 인스턴스에서 관리를 해주고 있는데 어떻게 서로 다른 인스턴스에서 게임 상태를 동등하게 유지하는지 확인해보면 좋을 것 같아요.\n### P.31\n똑같이 카드 선택 메시지가 날라오고요.\n### P.32\n이때 인스턴스A는 본인 로컬 캐시에서 값을 확인만 하고, 변경없이 바로 Redis에 이벤트를 발송합니다.\n하지만 이때 기존과 좀 차이가 있는데요,\n예를 들어, 유저1이 5번위치에 있는 카드를 선택했으면, 이때 인스턴스A는 이벤트에 쏠 때 페이로드로 누가? 에 유저1, 뭐를? 에 5번위치 카드를 넣어서 이벤트를 쏘는거에요.\n### P.33\n그럼 모든 인스턴스가 이 이벤트를 수신해서,\n### P.34\n거의 동시에 본인 로컬에서 관리하는 게임 상태를 변경을 하고\n### P.35\n유저들에게 브로드캐스트를 해줄 수 있습니다.\n### P.36 \n하지만 여전히 장단은 있어요. 이 방법은 1,2번 방법보단 읽기 성능이 압도적으로 빠르고, Redis에 값을 저장하거나 조회하는 로직이 없어요. 그러다보니 요청을 덜 하게 되고 Redis가 건강해집니다.\n대신 모든 인스턴스가 중복된 게임상태를 가지게 되는 단점이 있어요.\n### P.37\n이제 다시 처음으로 돌아와서,\n게임 상태와 유저 정보를 어떻게 저장하고, 어떻게 동기화 할 것인가에 대해 3가지 옵션이 있었는데요,\n첫 번째 방법은 지웠어요. 아무래도 실시간 게임이라 레이턴시가 중요했고, Redis를 안써봐서 좀 더 적극적으로 활용해보고 싶었습니다.\n그럼 2가지 방법이 남았는데요, 이 둘을 다시 비교를 해볼게요.\n### P.38\n앞서 설명한 장단점은 다음과 같아요.\n저는 무엇보다 중앙 집중형 병목이 생길 수 있다는 게 눈에 들어왔었는데요, 현재는 돈이 없어 클러스터링 없이 하나만 사용하고 있는 Redis가 단일장애지점이 되면 안되겠다라는 생각을 했었고, 어떤 방법이 조금이라도 안전할지 확인하고자 부하테스트를 해봤습니다.\n### P.39\n부하테스트 내용은 다음과 같아요.\n1000명이 10초동안 50ms 간격으로 웹소켓 메시지를 보내봤습니다.\n그러면 초당 20000번의 요청이 Redis로 가게 되는데, 스펙 상 t4g micro로 띄운 Redis가 최소 2만건에서 4만건의 메시지를 버틸 수가 있다고 해서 이와 같이 테스트를 진행했습니다\n### P.40\n각각 5번씩 동일한 부하를 주면서 테스트를 진행했는데 결과는 다음과 같아요.\n평균 cpu 사용률이 16%에서 7.5%로 기존대비 절반정도 감소한 모습을 볼 수 있어요.\n또 이 자료화면에는 없지만, 기존 2번 방법에서는 매 요청마다 직렬과/역직렬화 과정을 거쳐야해서 유저가 메시지를 받는데까지 시간이 길었는데, 3번 방식으로 바꾸면서 이 지연이 줄어들었다는 것을 확인할 수 있었습니다.\n### P.41\n그래서 저희는 현재 3번구조를 적용하고 있는데요, 여전히 한계점은 존재하고 있어요.\n### P.42\n각 인스턴스가 Redis에게 메시지를 쏠 때는 Fire And Forget 방식을 사용합니다.\n그래서 운이 안좋으면 메시지가 유실이 되는 경우도 있습니다.\n\n또한 카드게임을 보면 알 수 있다시피 동시성 문제가 생길 수가 있는데요,\n만약 서로 다른 유저가 동일한 카드를 거의 동시에 선택을 했을 때 각각의 요청이 서로 다른 인스턴스에게 흘러가서 각 인스턴스는 아무도 선택안할 줄 알고 비즈니스 로직을 처리할 수 있어요.\n\n이 부분도 고민할 수 있는게 많은데, 더 궁금하신분은 개인적으로 찾아보거나 끝나고 저와 더 이야기를 나누면 좋을 것 같습니다."},{"excerpt":"Solution Chanllenge 올해도 있다 최소 하나 이상의 구글 기술을 이용해서 지역 문제 해결을 목표 작년은 유엔에서 선정한 문제들 중 5개 선정해서 진행했음 팀원은 최소 4명 작년은 필리핀 마닐라에서 데모데이가 진행됨 26년 상반기에 열림 정확한 일정은 모름 올해는 3~5월 사이에 진행됨, 비슷하지 않을까 Requirements 리드는 최소 1…","fields":{"slug":"/lead_onboarding/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":null,"tags":null},"rawMarkdownBody":"\n## Solution Chanllenge\n- 올해도 있다\n- 최소 하나 이상의 구글 기술을 이용해서 지역 문제 해결을 목표\n- 작년은 유엔에서 선정한 문제들 중 5개 선정해서 진행했음\n- 팀원은 최소 4명\n- 작년은 필리핀 마닐라에서 데모데이가 진행됨\n- 26년 상반기에 열림\n- 정확한 일정은 모름\n- 올해는 3~5월 사이에 진행됨, 비슷하지 않을까\n## Requirements\n- 리드는 최소 1년이상 (권장)\n- 대학생 신분이어야함\n- 이벤트는 최소 3개월에 하나 이상 제대로된 이벤트를 열어야함\n## 구글 엔지니어 커리어 세션\n- 졸업생 및 현 멤버 대상\n- 11월 17일 (금)\n- AI 시대의 커리어를 어떻게 쌓아야할까\n## 이벤트 플랫폼\n- 잘 사용해라\n- 모든 이벤트를 여기에 등록해라\n## CLP\n- 어떤 이벤트를 열 수 있는지 확인할 수 있음\n- [https://developers.google.com/community/community-hub](https://developers.google.com/community/community-hub) 이곳으로 이동 중\n- https://communityleads.dev/home/ls/content/8420169136588567/program-resources/google-developer-program 이곳으로 이동 중\n\nhttps://sites.google.com/view/gdeveloperskorea/gdg-on-campus?authuser=0&pli=1\n\n"},{"excerpt":"스크린샷 2025-09-14 오후 3.38.40.png 스크린샷 2025-09-14 오후 3.38.51.png 문제 원인 분석 매 시간 10분 단위로 발생, 특정 Key만 문제 발생 캐시의 TTL 이 1시간이고, 특정 인기 데이터들이 같은 시점에 캐시 설정됨 9시 10분에 캐싱됨, 10시 10분에 캐시 만료되고 다시 캐싱, 11시 10분에 캐시 만료되고 …","fields":{"slug":"/면접스터디_1주차/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":"DB 부하의 원인을해결해보자!","tags":null},"rawMarkdownBody":"![[스크린샷 2025-09-14 오후 3.38.40.png]]\n\n![[스크린샷 2025-09-14 오후 3.38.51.png]]\n\n## 문제 원인 분석\n- 매 시간 10분 단위로 발생, 특정 Key만 문제 발생\n\t- 캐시의 TTL 이 1시간이고, 특정 인기 데이터들이 같은 시점에 캐시 설정됨\n\t- 9시 10분에 캐싱됨, 10시 10분에 캐시 만료되고 다시 캐싱, 11시 10분에 캐시 만료되고 다시 캐싱, ...\n- 30초 후 자동 복구\n\t- 새롭게 캐싱이 되면서 정상화\n이런 문제를 Cache Stampede 라고 부름\n\n## 해결 전략\n### TTL Jitter: 랜덤하게 만료하도록 설정\n- 모든 핫 데이터가 매 시간 10분에 동일하게 만료되는 걸 랜덤하게 조정해서 만료 시점을 분산시킴\n- 이때 실시간성이 중요한 데이터일수록 Jitter를 작게\n- 하지만 각 시점별 트래픽이 여전히 기준치보다 크면 문제는 여전히 발생\n\n### Single Flight Pattern: N개 동시 요청 중 1개만 DB 호출, 나머지는 대기\n- 첫 번째 요청 실패 시 연쇄적으로 나머지 전부 실패\n- 응답 시간 증가\n\t- 요청 1: DB 호출 (5초 소요)\n\t- 요청 2~1000 : 5초 대기\n- DB 요청이 자주 생긴다?\n\t- Circuit Breaker 도입\n\t- 요청 실패가 5번 누적이 되면, 그 이후 요청들은 빠르게 실패처리 후 응답보냄\n\t- 그동안 DB 복구하고 1분뒤 자동으로 재시도하게끔\n하지만 여전히 캐시 만료는 발생하고, Single Flight Pattern을 도입하더라도 첫 번째 요청을 제외한 나머지 요청은 대기해야함. Circuit Breaker 작동하더라도 서비스 품질 이상함.\n### Proactive Refresh: TTL 20% 남았을 때 백그라운드 캐싱\n- 캐시 만료 자체를 없앰, 사용자 요청 시에는 항상 캐시 있음\n- 간헐적 지연 상황 안생김, 일정한 성능 보장\n\n## 그럼 Proactive Refresh 만 하면 되지, 나머지 전략은 왜 필요해?\n### 1. 갑작스런 새 인기 데이터 등장\n```\n# 평소에는 조용했던 데이터가 갑자기 핫해짐\n16:00 - 어떤 상품이 SNS에서 갑자기 바이럴\n16:01 - 해당 상품 메타데이터에 요청 폭주 (10000 TPS)\n16:02 - 캐시에 없음 → Proactive Refresh 대상도 아님\n16:03 - 썬더링 허드 발생! 💥\n```\n### 2. Proactive Refresh 자체 실패\n```\n# 백그라운드 갱신 중 실패 상황\n15:50 - 백그라운드에서 캐시 갱신 시도\n15:51 - DB 일시적 장애로 갱신 실패\n15:52 - 재시도해도 계속 실패\n16:00 - 결국 캐시 만료됨\n16:01 - 사용자 요청 들어옴 → 캐시 없음 → 썬더링 허드 💥\n```\n### 3. 콜드 스타트\n```\n# 서버 재시작 시\n09:00 - 서버 재부팅 (배포 등)\n09:01 - 캐시 모두 비워짐\n09:02 - 출근 시간 트래픽 몰림\n09:03 - 모든 데이터가 캐시 미스 → 대규모 썬더링 허드 💥\n```\n### 4. 트래픽 패턴 예측 실패\n```\n# 예상치 못한 이벤트\n평소: \"이 데이터는 하루에 100번 정도 조회되네\"\n갑자기: 마케팅팀이 광고 때림 → 1분에 10000번 조회\n결과: Proactive Refresh 주기 (5분마다)로는 따라갈 수 없음\n```\n## 실제 장애 시나리오\n\n### Case 1: 마케팅 이벤트\n```\n14:00 - 마케팅팀이 갑자기 이벤트 오픈\n14:01 - 특정 상품에 요청 폭주 (평소의 1000배)\n14:02 - Proactive Refresh로는 감당 안 됨\n14:03 - Single Flight 없었다면? → DB 뻗음 💥\n14:03 - Single Flight 있어서 → 1개 요청만 DB, 나머지 대기 ✅\n```\n### Case 2: DB 장애\n```\n15:00 - Primary DB 장애 발생\n15:10 - Proactive Refresh 계속 실패\n15:20 - 캐시들 하나둘 만료 시작\n15:30 - Circuit Breaker 없다면? → 모든 요청 타임아웃 💥\n15:30 - Circuit Breaker 있어서 → 즉시 실패, Stale Cache 반환 ✅\n```\n### Case 3: 코드 배포\n```\n16:00 - 새 버전 배포로 서버 재시작\n16:01 - 모든 캐시 날라감 (Redis 외부 캐시 제외)\n16:02 - 저녁 시간 트래픽 시작\n16:03 - 모든 조합 필요함:\n        - Jitter: 캐시 재생성 시점 분산\n        - Single Flight: 중복 호출 방지  \n        - Circuit Breaker: DB 보호\n        - Proactive: 이후 안정화\n```\n## 보험의 개념\n```\n# 자동차 보험 비유\nproactive_refresh = \"안전 운전\"     # 99% 사고 방지\ncircuit_breaker = \"에어백\"         # 사고 시 피해 최소화  \nsingle_flight = \"브레이크\"         # 위험 상황 대응\nttl_jitter = \"안전거리\"           # 연쇄 추돌 방지\n```\n### 99% vs 99.99%의 차이\n- **Proactive Refresh만**: 99% 안정성\n- **4개 조합**: 99.99% 안정성\n**0.99%의 차이**가 별거 아닌 것 같지만:\n- 하루 100만 요청 → 1000번 장애\n- 한 달 → 30,000번 장애\n- **매월 8시간씩 서비스 불안정**\n대규모 서비스에서는 **이 차이가 엄청남**.\n## + 캐시무효화\n\n**데이터 일관성** 문제 때문에 필요함\n```\n# 문제 상황\n10:00 - 상품 가격: 10,000원 (DB + 캐시 둘 다)\n10:30 - 관리자가 가격 변경: 15,000원 (DB만 업데이트)\n10:31 - 사용자가 조회 → 캐시에서 10,000원 반환 😡\n\n# 사용자: \"어? 결제할 때는 15,000원이네? 사기당한 기분\"\n```\n**캐시와 DB 데이터가 달라지는 문제**를 해결하는 게 캐시 무효화임.\n### 주요 캐시 무효화 전략들\n\n#### 1. TTL (Time To Live) 기반\n**가장 단순한 방법**: 시간 지나면 자동 삭제\n- **자주 변하지 않는 데이터** (사용자 프로필, 상품 기본 정보)\n- **약간의 지연 허용 가능**한 경우\n#### 2. Manual Invalidation (수동 무효화)\n**데이터 변경 시 직접 캐시 삭제**\n- 데이터 일관성 보장 \n- 연관 캐시 다 찾아서 지워야 함 → 실수하기 쉬움\n#### 3. Write-Through 패턴\n**DB 쓸 때 캐시도 같이 업데이트**\n- 캐시 항상 최신 \n- 쓰기 성능 느려짐 (DB + 캐시 둘 다 써야함)\n#### 4. Write-Behind (Write-Back) 패턴\n**캐시만 먼저 업데이트, DB는 나중에**\n- 쓰기 성능 좋음 \n- 캐시 장애 시 데이터 손실** 위험\n#### 5. Event-Driven Invalidation\n**DB 변경 이벤트 감지해서 캐시 무효화**\n- 자동화, 놓치는 캐시 없음 \n- 구현 복잡, 이벤트 시스템 필요\n#### 6. Tag-Based Invalidation\n**캐시에 태그 붙여서 관련된 것들 한 번에 삭제**\n- 관련 캐시 찾기 쉬움 \n- 태그 관리 복잡, Redis에서 기본 지원 안 함\n#### 7. Refresh-Ahead (사전 갱신)\n**만료되기 전에 미리 새 데이터로 교체**\n- 사용자는 항상 빠른 응답 \n- 백그라운드 작업 필요\n\n## 참고자료\nhttps://toss.tech/article/cache-traffic-tip\nhttps://channel.io/ko/team/blog/articles/tech-cache-rdb-4cc0bbf4"},{"excerpt":"스크린샷 2025-09-17 오후 10.45.10.png\n스크린샷 2025-09-17 오후 10.45.19.png 문제1: Traffic Mirroring 방식과 주의사항 주의사항 데이터 무결성: 실제 DB에 영향 주면 안 됨 성능 영향: 미러링 때문에 레이턴시 늘어나면 안 됨 보안: 테스트 환경에 실제 데이터 들어감 특히 결제관련 조심 네트워크 부하: …","fields":{"slug":"/면접스터디_2주차/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":"엔제니어링 위크, 안전하게 마무리하기","tags":null},"rawMarkdownBody":"\n\n![[스크린샷 2025-09-17 오후 10.45.10.png]]\n![[스크린샷 2025-09-17 오후 10.45.19.png]]\n## 문제1: Traffic Mirroring 방식과 주의사항\n\n### 주의사항\n- **데이터 무결성**: 실제 DB에 영향 주면 안 됨\n- **성능 영향**: 미러링 때문에 레이턴시 늘어나면 안 됨\n- **보안**: 테스트 환경에 실제 데이터 들어감\n\t- 특히 결제관련 조심\n- **네트워크 부하**: 트래픽 2배로 늘어남\n## 문제2: Canary 배포에서 문제 상황과 대응\n"},{"excerpt":"스크린샷 2025-10-01 오후 8.40.41.png\n스크린샷 2025-10-01 오후 8.40.51.png 0. 뭐가 중요할까 멱등성 보장 안 되면 중복 이체 발생 분산 환경에서 동시 실행 방지 안 하면 같은 이체 2번 탐 부분 실패 시 데이터 정합성 깨짐 배치 처리 중 서버 죽으면 어디까지 했는지 모름 은행 API 장애 시 전체 멈춤 돈은 장애 대응…","fields":{"slug":"/면접스터디_4주차/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":"신규 자동이체 시스템을 설계해보자","tags":null},"rawMarkdownBody":"\n![[스크린샷 2025-10-01 오후 8.40.41.png]]\n![[스크린샷 2025-10-01 오후 8.40.51.png]]\n## 0. 뭐가 중요할까\n- **멱등성 보장 안 되면 중복 이체 발생** \n- **분산 환경에서 동시 실행 방지 안 하면 같은 이체 2번 탐**\n- **부분 실패 시 데이터 정합성 깨짐**\n- **배치 처리 중 서버 죽으면 어디까지 했는지 모름**\n- **은행 API 장애 시 전체 멈춤**\n\n돈은 장애 대응이 핵심이다.\n## 1. DB 테이블 구조\n기본적인 테이블은 구축되어있다는 가정 하에, 장애 대응용 컬럼들 추가\n### 1-1. 자동이체 설정 테이블 추가 사항\n- version(낙관적락용): 동시 수정 방지\n- last_executed_at(마지막 실행 시간): 중복 실행 체크용\n- *retry_count*(재시도 횟수): 계속 실패하는 애들 파악용\n- execution_lock_until(실행 락 만료 시간): 분산 락 대신 DB 락으로 쓸 수 있음\n\t- Redis 같은 외부 분산 락 시스템 쓰면 좋겠지만 Redis도 장애지점이 될 수 있거나 \n\t- 인프라 제약이 있거나\n\t- 외부 의존성 없이 DB 만으로 해결하고 싶을 때\n\n### 1-2. 이체 이력 테이블 추가사항\n- *[idempotency_key](https://docs.tosspayments.com/reference/using-api/authorization) (*멱등성 키): 중복 실행 방지의 핵심\n    - `{transfer_id}:{실행예정일}:{nonce}` 형태로 생성\n    - 이게 없으면 같은 이체 2번 타는 거 못 막음\n- external_transaction_id (외부 거래 ID): 은행 API 응답 ID\n    - 은행에서 실제로 처리했는지 조회할 때 필요\n- processing_started_at, processing_ended_at: 처리 시간 추적용\n\n### 1-3. 배치 실행 상태 테이블\n- 배치 돌릴 때마다 레코드 하나 박음\n- 배치 ID, 시작 시각, 종료 시각, 처리 건수, 실패 건수, 상태(RUNNING/COMPLETED/FAILED)\n- 서버 죽었을 때 재시작 지점 찾는 용도\n- 배치가 RUNNING 상태로 2시간 넘게 있으면? → 장애 알람\n\n## 2. 자동이체 실행 흐름\n분산 환경 동시 실행 방지가 핵심\n서버 2대 이상이거나 재부팅하면 여러번 배치를 돌 수 있음, 그럼 같은 이체 여러번 실행됨\n\n### 해결책 1\n- 분산락: Redis, DB (SELECT ... FOR UPDATE SKIP LOCKED)\n\n### 해결책 2\n멱등성 키 생성: 같은 이체를 여러번 실행해도 한 번만 처리될 수 있게 해야함\n- 이체 실행 전에 idempotency_key 생성\n- 이력 테이블에 이미 같은 키 있는지 체크\n- 있으면? → 이미 처리했다는 거니까 스킵\n- 없으면? → 처리 진행\n\n왜 중요하냐\n- 서버 죽었다가 재시작할 때\n- 네트워크 타임아웃으로 재시도할 때\n- 이거 없으면 같은 금액 2번 빠져나감 → 고객 빡침 → 소송\n\n### 상황 1: 부분 실패\n- 한 청크(1000건) 처리 중 500번째에서 DB 락 타임아웃\n- 그럼 앞에 499건은? → 커밋됐으면 처리됨, 안 됐으면 롤백\n- 재시도할 때 499건 스킵하고 500번부터 해야 하는데 어떻게?\n\n해결:\n- 각 이체마다 별도 트랜잭션 (기본)\n- 근데 **실패한 건 이력에 FAILED 찍고 다음 거 계속 처리**\n- 전체 배치는 멈추지 않음\n- retry_count 증가시키고 다음 실행일은 그대로 (재시도용)\n\n### 상황 2: 타임 아웃과 서킷 브레이커\n- 은행 API 응답 느려짐 (10초씩 걸림)\n- 20만 건 처리하면? → 2시간 넘게 걸림 → 실패\n\n해결:\n- 각 은행 API 호출에 타임아웃 3초 설정\n- 3초 안에 응답 없으면 FAILED 처리하고 다음 거 진행\n- 연속으로 실패 많이 나면 서킷 브레이커 열어서 일시 중단\n- 특정 은행 API만 장애면 해당 은행 이체만 스킵하고 나머지 처리\n\n## 3. 이력 저장 방식\n### 이력은 절대 삭제/수정 불가능 (Immutable)\n- 이력 테이블은 INSERT ONLY\n- UPDATE/DELETE 권한 아예 안 줌\n- 법적 분쟁 생기면 이력이 증거\n- 수정 가능하면 \"회사가 조작했다\" 이런 얘기 나옴\n\n### 감사 로그는 별도 저장소에\n- 설정 변경 이력은 메인 DB 말고 별도 로그 저장소(ELK, S3)에도 백업\n- 누가, 언제, 어떤 IP에서, 뭘 바꿨는지 다 남김\n- DB 날아가도 로그는 남아있어야 함\n\n### 조회 성능 고려\n- 이력 테이블은 무조건 커짐 (20만 건 × 365일 = 7천만 건/년)\n- 파티셔닝 필수: 월별로 테이블 분리\n- 1년 지난 데이터는 콜드 스토리지로 이관\n\n## 4. 성능 제약 대응 전략\n- 하루 = 86,400초\n- 초당 20건 × 86,400초 = 1,728,000건 (이론적 최대치)\n- 보수적으로 20만건, 중요한 건 성능 제약이 있다~\n\n### 4-1. 우선순위 큐 도입\n20만 건을 동등하게 처리하면 안 됨.\n우선순위:\n- P0 (최우선): 월급, 공과금 같은 중요 이체\n- P1 (일반): 일반 자동이체\n- P2 (저우선): 소액 이체\n\n실패 시 재시도 횟수도 우선순위별로 다르게.\n\n### 4-2. 점진적 롤아웃 \n처음부터 20만 건 전부 돌리면 장애 시 임팩트 큼.\n방법:\n- 처음 10분: 1만 건만 처리 → 모니터링\n- 이상 없으면: 5만 건 처리\n- 최종: 전체 처리\n\n실패율 5% 넘으면 자동 중단하고 알람.\n### 4-3. 백프레셔(Backpressure) 처리\nDB나 은행 API가 버티기 힘들면:\n- 처리 속도 자동으로 줄임\n- DB CPU 80% 넘으면 스레드 수 줄임\n- 은행 API 에러율 올라가면 요청 간격 늘림\n\n### 4-4. 데드레터 큐 (DLQ)\n계속 실패하는 이체:\n- 5번 재시도해도 실패하면 DLQ로 보냄\n- 별도로 수동 처리하거나 고객센터 통보\n- 메인 배치 흐름은 막지 않음\n\n### 4-5. 장애 복구 시나리오\n서버 죽었을 때:\n1. 배치 상태 테이블에서 RUNNING 상태 찾음\n2. 마지막 처리 시각 확인\n3. 그 이후부터 재처리 (멱등성 키로 중복 방지)"},{"excerpt":"스크린샷 2025-10-12 오후 2.54.20.png스크린샷 2025-10-12 오후 2.54.30.png 전체 아키텍처 한 줄 요약 1. 데이터 수집 CDC(Debezium)로 RDB Binlog 읽어서 Kafka로 전송 왜? RDB 직접 폴링(SELECT)하면 TPS 5000에 DB 터짐 2. 실시간 처리 Kafka 파티션 50개 (거래점 ID 기준…","fields":{"slug":"/면접스터디_5주차/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":"실시간 리스크 분석 시스템을 설계해보자","tags":null},"rawMarkdownBody":"\n![[스크린샷 2025-10-12 오후 2.54.20.png]]![[스크린샷 2025-10-12 오후 2.54.30.png]]\n### 전체 아키텍처 한 줄 요약\n\n```\nRDB → CDC → Kafka → Flink(1분 윈도우 집계) → Redis(캐시) → 리스크 판단 → 알림\n```\n\n---\n\n### 1. 데이터 수집\n\n- **CDC(Debezium)로 RDB Binlog 읽어서 Kafka로 전송**\n- 왜? RDB 직접 폴링(SELECT)하면 TPS 5000에 DB 터짐\n\n### 2. 실시간 처리\n\n- **Kafka 파티션 50개** (거래점 ID 기준 파티셔닝)\n- **Flink로 1분 윈도우 집계**\n    - 거래점별 취소율, 거래액 계산\n    - State Backend(RocksDB)로 중간 상태 관리\n\n### 3. 데이터 저장\n\n**Redis (Hot Cache):**\n\n- 최근 1시간: 1분 단위 집계\n- 최근 7일: 일 단위 평균 취소율 (배치로 미리 계산)\n- 전일 10억 이상 거래점 목록\n\n**TimescaleDB (분석용):**\n\n- 히스토리 데이터 적재\n\n### 4. 리스크 판단\n\n**조건1: 취소율 2배 증가**\n\n- 최근 1시간 취소율 vs 7일 평균 비교\n- 7일 평균은 배치로 미리 계산해서 Redis 캐싱\n\n**조건2: 거래액 50% 급감**\n\n- 전일 10억 이상 거래점만 체크\n- 당일 누적 vs 전일 비교 (같은 시간대 기준)\n\n### 5. 스케일링\n\n- **롱테일 대응**: 상위 1% 거래점은 Salting으로 Key 분산\n- **병렬 처리**: Flink Parallelism 50, Task Manager 10대,,.... 몰라\n- **Redis Cluster**: 샤딩으로 부하 분산\n\n---\n\n## Q&A\n\n**Q: 왜 CDC 써야 함?** \nA: RDB 폴링하면 SELECT 쿼리로 DB 부하 터짐. CDC는 Binlog만 읽어서 부하 없음.\n\n**Q: 왜 Kafka?** \nA:\n1. 버퍼 역할 (Flink 죽어도 데이터 유실 X)\n2. 파티셔닝으로 병렬 처리 (TPS 5000 감당)\n3. 순서 보장 (같은 거래점 순차 처리)\n\n**Q: 1분마다 10만 거래점 체크하면 Redis 부하는?** \nA: 7일 평균은 배치로 미리 계산. 실시간엔 단순 조회만. Redis sub-ms라 10만 건도 OK.\n\n**Q: Hot Key 문제는?** \nA: 상위 1% 거래점은 merchant_id에 랜덤 suffix 붙여서 파티션 분산. 읽을 땐 여러 Key 합산.\n아니면 동적 파티션?\n\n**Q: 장애 시 데이터 유실은?** \nA: Flink Checkpointing 3분마다 + Kafka 3일 보관. 최악 3분치만 재처리.\n\n---\n## 뭘 원하냐\n\n### 1. 대용량 트래픽 처리 경험 (최우선)\n\n**보려는 것:**\n\n- TPS 5000 같은 숫자 보고 **\"어 이거 병렬 처리 해야겠네\"** 바로 떠올리는지\n- 단일 서버로 안 된다는 걸 아는지\n\n**체크 포인트:**\n\n- 파티셔닝, 샤딩 개념\n- 병렬 처리 (Kafka 파티션, Flink Parallelism)\n- Hot Key 문제 인지 여부\n\n**못 하면:**\n\n- \"음... DB에서 1분마다 SELECT 하면 되지 않을까요?\" ← 떨어짐 ㅋㅋ\n\n---\n\n### 2. 실시간 vs 배치 구분 (중요)\n\n**보려는 것:**\n\n- \"1분 단위\"라는 말 보고 **실시간 스트리밍 처리**임을 인지하는지\n- 배치로 해결 못 한다는 걸 아는지\n\n**체크 포인트:**\n\n- 실시간: Kafka, Flink/Spark Streaming\n- 배치: Airflow, Spark Batch\n- **근데 7일 평균은 배치로 미리 계산**하는 하이브리드 사고\n\n**못 하면:**\n\n- \"배치 스케줄러로 1분마다 돌리면 되지 않나요?\" ← 이것도 아웃 ㅋ\n\n---\n\n### 3. 데이터 저장소 선택 (핵심)\n\n**보려는 것:**\n\n- RDB, Redis, TimeSeries DB 각각 **언제 쓰는지** 아는지\n- \"왜 그 DB를 선택했어?\" 물어봤을 때 대답 가능한지\n\n**체크 포인트:**\n\n|저장소|용도|이유|\n|---|---|---|\n|Redis|Hot Cache (최근 1시간)|빠름, TTL 지원|\n|TimescaleDB|히스토리 분석|Time-series 특화|\n|RDB (원본)|거래 데이터|ACID, 신뢰성|\n\n**못 하면:**\n\n- \"다 MySQL에 넣으면 안 돼요?\" ← MySQL로 1분마다 10만 거래점 조회? ㅂㅂ\n\n---\n\n### 4. 시스템 설계 trade-off 이해\n\n**보려는 것:**\n\n- \"완벽한 설계\"는 없음. **트레이드오프**를 이해하는지\n- 장단점 말하면서 **왜 이 선택을 했는지** 설명 가능한지\n\n**예시:**\n\n**Q: CDC vs API 이벤트 발행 방식?**\n\n- CDC: DB 로직 안 건드림, 운영 포인트 증가\n- API: 깔끔한데 거래 서버 수정 필요\n\n**Q: Kafka vs RabbitMQ?**\n\n- Kafka: 처리량 높음, 운영 복잡\n- RabbitMQ: 간단한데 느림\n\n---\n\n### 5. 장애 대응 \n\n**보려는 것:**\n\n- \"Flink 죽으면?\" 같은 질문에 답하는지\n- **SPOF(Single Point of Failure)** 없는 설계인지\n\n**체크 포인트:**\n\n- Kafka Replication\n- Flink Checkpointing\n- Redis Cluster (Master-Replica)\n- 데이터 재처리 방안 (Kafka 메시지 보관)\n\n\n---\n\n### 6. 성능 병목 지점 파악 \n\n**보려는 것:**\n\n- \"어디가 병목일까?\" 스스로 찾아내는지\n- **롱테일 분포** 같은 힌트 보고 Hot Key 문제 떠올리는지\n\n**체크 포인트:**\n\n- 상위 1% 거래점에 트래픽 집중 → Salting 필요\n- Redis 메모리 계산 (10만 거래점 × 7일 = ?)\n- Kafka Lag 모니터링\n\n\n---\n\n### 7. 도구/기술 이해도 (기본)\n\n**필수로 알아야 하는 것:**\n\n- Kafka 기본 개념 (Topic, Partition, Consumer Group)\n- Redis 자료구조 (String, Set, Sorted Set)\n- Flink/Spark Streaming 차이\n- CDC가 뭔지\n\n**있으면 좋은 것:**\n\n- Debezium 설정 경험\n- Flink Windowing (Tumbling, Sliding)\n- TimescaleDB, ClickHouse 같은 Time-series DB\n"},{"excerpt":"스크린샷 2025-10-18 오후 5.49.35.png 문제 분석 1억 계정 규모 계산 1억 명 * 평균 히스토리 10개 = 10억개의 password_history history 평균 크기: user_id(12) + password_hash(64) + timestamp(8) + 기타 = 100바이트 총 데이터 크기: 100GB 일일 비밀번호 변경 건수 …","fields":{"slug":"/면접스터디_6주차/"},"frontmatter":{"date":"2025년 02월 11일 09:02","title":"1억명 유저의 비번 관리","tags":null},"rawMarkdownBody":"![[스크린샷 2025-10-18 오후 5.49.35.png]]\n\n## 문제 분석\n\n### 1억 계정 규모 계산\n- 1억 명 * 평균 히스토리 10개 = **10억개의 password_history**\n- history 평균 크기: user_id(12) + password_hash(64) + timestamp(8) + 기타 = **100바이트**\n- 총 데이터 크기: **100GB**\n\n### 일일 비밀번호 변경 건수 추정\n- 일반적으로 월 1-2% 사용자가 비밀번호 변경 가정\n- 1억 * 1.5% / 30일 = 매일 약 5만건의 변경\n- 초당 10 ~ 20건\n\n## 각 요구사항별 성능분석\n\n### 1. 최근 5개 비밀번호 체크\n```sql\nSELECT password_hash FROM password_history \nWHERE user_id = ? \nORDER BY created_at DESC \nLIMIT 5;\n```\n\n- 인덱스 `(user_id, created_at DESC)`  타면서 스캔\n- B-tree 인덱스에서 O(log n) + 5레코드 읽기 = 1-5ms\n- **문제없음**\n\n### 2. 3개월 이내 사용 체크\n```sql\nSELECT password_hash FROM password_history \nWHERE user_id = ? \nAND created_at > DATE_SUB(NOW(), INTERVAL 3 MONTH);\n```\n- 복합 인덱스 `(user_id, created_at DESC)` 타면서 스캔\n- 3개월치만 읽고 애플리케이션에서 비교\n- 1유저당 최대 3개월에 2-3번 변경 → 2-3레코드 확인\n- 문제없음\n\n### 3. 100번 이상 사용됐는지 체크 (⭐️)\n```sql\nSELECT COUNT(*) FROM users WHERE current_password_hash = ?;\n```\n- 1억 레코드에서 스캔 필요\n- 1억건이면 10~20초 소요 \n- 문제많음\n\n#### 실제 내 프로젝트였다면?\n- 과연 굳이 \"100번 이상 사용됐는지\" 체크해야하나... 의심\n- 기획팀에게 요구사항 완화 요청\n\t- 이게 가장 시간적, 경제적 비용을 줄일 수 있는 방법이지 않나\n- 정 안되면 정확히 100번 카운트를 해야햐나?\n\t- 90번이든 110개든 보안 효과가 비슷하면 되는 거 아닌가?\n\n#### 근사치 기반\n```java\nprivate BloomFilter<String> popularPasswordFilter;\n\npublic void initBloomFilter() {\n\tpopularPasswordFilter = BloomFilter.create(\n\t\t// 100만개의 데이터, 1% False Positive Rate 설정\n\t);\n}\n\npublic Boolean validate (String password) {\n\n\tString hash = hash(password);\n\n\t// ...\n\t\n\tif (popularPasswordFilter.mightContain(hash)) {\n\t\treturn false;\n\t}\n\t\n\treturn true;\n}\n```\n- 조회 성능 O(1)\n- 추가 인프라 필요 없음 (비용 필요없음)\n\n#### 더 정확히 체크해야한다면?\n- Redis에 집계 테이블 저장, 매일 새벽에 1번씩 업데이트\n- 아닌가? 새벽에 1번씩 Redis를 업데이트 하고 계속 Redis에 접근해서 조회해야한다면, 그냥 DB에 집계 테이블 만들어두고 새벽에 DB 접근해서 로컬 캐시 업데이트 해놓을듯 \n\n---\n\n## Claude가 말한 보완점\n- 샤딩 전략 없음\n\t- 1억 유저면 단일 DB로 못 버팀\n\t\t- 근데 배민이었나, 토스였나, 쿠팡이었나? 아직 성능좋은 단일 DB로 버틴다고 들음\n- Redis의 집게 테이블은 어떻게 동기화할거냐\n\t- CDC 써서 실시간 동기화하면 더 정확해짐\n- Redis에 접근할 때 동시성 이슈 터지면 어떻게 할거냐\n\t- update와 select 동시에 일어나면 어떻게 할거임?\n\t\t- 아니 근데 비번 변경이 동시에 일어날 일이 그렇게 많나?"},{"excerpt":"지난 회고: retrospect-2024-1 돌아보기 이제 25년이라는 게 믿기지 않을 정도로 24년이 빨리 지나갔다. 돌아보니 작년 7월에 전역을 하고 남은 반년을 의미있게 보내려고 나름대로 부지런히 산 것 같은데 우선, 24년 하반기에는 드디어 자취를 시작했다. 자취를 한 여러 이유가 있지만 무엇보다 그동안 못 해왔던 공부를 할 수 있는 공간을 만들고…","fields":{"slug":"/retrospect-2024-2/"},"frontmatter":{"date":"2024년 12월 27일 22:12","title":"2024년 하반기 회고","tags":["회고","우아한테크코스","학부연구생"]},"rawMarkdownBody":"지난 회고: [[retrospect-2024-1]]\n## 돌아보기\n이제 25년이라는 게 믿기지 않을 정도로 24년이 빨리 지나갔다. 돌아보니 작년 7월에 전역을 하고 남은 반년을 의미있게 보내려고 나름대로 부지런히 산 것 같은데 우선, 24년 하반기에는 드디어 자취를 시작했다. 자취를 한 여러 이유가 있지만 무엇보다 그동안 못 해왔던 공부를 할 수 있는 공간을 만들고 싶었다. 군복무를 하면서 항상 코딩이든, 운동이든 자기계발에 대한 갈증이 있었는데 그럴 수 있는 공간이 없어서 아쉬웠다. 또 노트북과 한 몸인 컴공생들은 다들 이런 로망이 하나쯤은 있을 것 같은데, 내가 원하는 세팅을 맞추고 작업을 하고 싶다는 생각을 오래 해왔어서 사실 자취는 핑계 정도가 맞지 않나 싶다. \n\n우선 24년 하반기에 진행했던 것들은 아래와 같다.\n> - GDG on Campus CAU 4기 Core\n> - 우테코 지원하기\n> - 학부연구생\n> - 운동 \n### 우테코\n입대를 하기 전부터 하고 싶었던 것 중에 하나였다. 전역을 하고 7기 모집 공고만 올라오길 기다렸는데 공고가 올라오자마자 자소서를 준비했던 기억이 있다.\n\n공부해야할 게 명확했던 고등학생과 달리 대학에 오고 길지 않은 시간일 수 있지만, 그래도 지금까지 공부를 해오면서 항상 내가 향하고 있는 방향이 옳은 방향일까...에 대한 의문이 은연 중에 있었던 것 같았다. 그런 의문을 우테코가 풀어줄 수 있지 않을까, 또한 내가 틀리지 않았음을 스스로 증명하고 싶어서 우테코를 지원했다.\n\n지원 과정은 많은 시간을 요구한다. 운이 좋게도 나는 2학기도 군휴학 기간이라 다른 분들에 비해 비교적 많은 시간을 쏟을 수 있었고, 그중에서 자소서에 유독 공을 많이 들였다. 자소서는 최대한 담담하게, 내가 해온 것들에 대한 이유와 그 과정에서 느끼고 배운 점들을 최대한 주관적인 관점에서 자세히 적었는데 운이 좋게 잘 통한 것 같다.\n\n프리코스와 최종 코테를 하면서 코딩을 잘하는 사람은 어딜가나 많구나... 라는 걸 체감할 수 있었다. 당시에는 그런 사람들 사이에서 불안감, 열등감만 느꼈던 것 같은데 지금 생각해보면 한 번 더 겸손해질 수 있는 기회였고 배울 수 있는 점도 찾을 수 있는 시간이었다. \n\n![[스크린샷 2024-12-29 오전 12.40.35.png]]\n일부러 발표 당일에 기대도 안하려고 했지만 긴장이 엄청 됐던 기억이 있다. 운이 좋게 찾아온 기회인만큼 올해도 열심히 참여해서 배우는 것도, 느끼는 점도 많았으면 좋겠다.\n### 학부연구생\n자취 시작과 동시에 학부연구생을 시작했다. 입대 전에 미리 컨택을 드렸던 교수님의 연구실에 마침 전역할 때쯤에 자리가 생긴다고 해서 이것도 운이 좋게 바로 시작을 할 수 있었다.\n\n연구 주제도 마침 내가 관심 있어하던 문제를 다루고 있어서 큰 고민 없이 연구를 시작했다. 지금까지 하면서 느낀 점은 내가 생각하는 `개발`이라는 과정이 연구와 크게 다르지 않다는 것이다. 오히려 연구 과정이 캡스톤이나 여타 프로젝트 활동보다 더 `개발`이라는 키워드와 가깝지 않나...라는 생각이 든다. \n\n요즘 학교를 다니면서 느끼는 건, 학부생에게 학교나 동아리에서 요구하는 개발이라는 경험이 너무 프레임워크나 특정 언어에 대한 지식 수준만 해당하는 것 같은 느낌이 있었다. 내가 생각한 개발자라는 건 결국 현실세계에 있는 문제를 해결하는 과정에서 코딩을 하나의 수단으로 쓸 수 있는 사람인데, 요즘 학교나 동아리에서는 반대로 문제가 안되는 것들을 오히려 강요하고, 그래서 본인들이 제작한 프로그램의 필요성을 강제하는 듯한 느낌이 불편하게 다가오는 것 같다.\n\n하지만 학부연구생의 신분으로 짧지만 그동안 느꼈던 점은, 내가 문제 자체에 집중할 수 있는 시간이 많아서 좋았다. 그 과정에서 문제의 본질을 고민해보고, 여러 방향으로 생각하면서 `우리가 풀어야하는 문제가 무엇인지` 라는 단계부터 시작할 수 있어서 더 몰입할 수 있었고, 그래서 더 재미있게 다가온 것 같다. \n\n그치만 우테코를 시작하면서 병행을 하기는 힘들 것 같아 1월까지만 학부연구생을 할 것 같다. 마음 같아서는 둘 다 병행을 하고 싶은데 한 편으론 이것도 내 욕심같아서 복학 후에 다시 시작하지 않을까싶다.\n### 운동\n운동은 하면 할 수록 욕심이 생겨서 어려운 것 같다. 전역 이후에도 꾸준히 일주일에 적어도 4번, 5번은 운동을 해왔는데 어느 순간 내가 드는 중량과 몸이 정체가 돼서 어떻게 더 발전시킬 수 있을지 고민이 되는 시점인 것 같다. \n\n먹는 양을 늘리는 게 답인 것 같아서 최근에는 운동만큼 먹는 것도 신경을 쓰고 있지만 유의미한 변화가 있을지는 앞으로 더 지켜봐야할 것 같다.\n\n25년에는 우테코를 하면서 어떻게 병행해나갈지 고민도 된다. 일주일에 적어도 3번, 욕심내서 4번정도 운동을 하고 싶은데 이 부분도 우테코를 시작해봐야 알 수 있을 것 같다.\n## 2025년은?\n군복무 중 밤을 샐 때마다 전역 후의 계획을 세웠는데 신기할만큼 하나하나 이뤄갈 수 있었던 24년이었다. 운도 많이 따라준 것 같고 지금까지 준비해온 것들이 유의미했음을 알 수 있던 시간이었다.\n\n25년도 어쩌다보니 휴학을 하게 되었는데 여러 사람들을 만나면서 많이 배우고, 깨닫고, 성장할 수 있는 한 해가 되었으면 좋겠다. 깊이 있는 지식을 쌓고 내실을 다질 수 있는 시간이 되도록, 커리어 내외적으로 내 가치를 키울 수 있는 시간이 되도록 노력해보고 싶다.\n\n2025년에는 새로운 것들에 불편해하지 않고 도전해보기를, 주변 사람들에게 긍정적인 영향을 끼칠 수 있는 사람이 되기를, 부족한 것들을 인정하고 메꿀 수 있는 시간이 되기를 바라면서 24년 회고와 25년 목표를 기록해본다."},{"excerpt":"12월 20일에 직접 분당 서울대병원에 있는 폐기능 검사실을 참관할 수 있는 기회가 주어졌다. 참관 기록 내용 Vmax Vyntus SPIRO 장비를 사용함 (현재 단종) 열센서 + 압력센서 Flow measurement Resolution: 1mL Accuracy: 0.1 to 14 L/s: ± 5% of reading or 0.2 L/s, whiche…","fields":{"slug":"/20241220_분당서울대병원_참관/"},"frontmatter":{"date":"2024년 12월 20일 22:12","title":"12/20 분당서울대병원 폐기능 검사실 참관","tags":["폐음연구","학부연구생"]},"rawMarkdownBody":"12월 20일에 직접 분당 서울대병원에 있는 폐기능 검사실을 참관할 수 있는 기회가 주어졌다.\n\n### 참관 기록 내용\n- Vmax Vyntus SPIRO 장비를 사용함 (현재 단종)\n\t- 열센서 + 압력센서\n\t- Flow measurement\n\t\t- Resolution: 1mL\n\t\t- Accuracy: 0.1 to 14 L/s: ± 5% of reading or 0.2 L/s, whichever is greater\n\t- Volume integration\n\t\t- Resolution: 1mL\n\t\t- Accuracy: 0.5 to 8 L: ± 3% of reading or 0.05 L, whichever is greater\n- 환자에 대한 폐기능 검사 독려는 필수사항\n\t- 시작하기 전 충분한 설명이 필요함.\n\t- 검사 도중 적합하지 않으면 환자 상태에 따라 빠르게 재시도 또는 제대로 이해 못할 경우 재설명 후 시도\n- 원활한 이해를 위해 직접 제작한 영상도 존재\n- 적합 판단을 위해 Flow-Volume 그래프를 많이 활용하고 있음\n- 호기량이 약한 후반 부분도 끝까지 측정하고 검사적합 판단 요소로 활용\n- 검사 시, 고개를 위로 10~15도 정도 향한 자세로 시행 (기도 확보)\n- 2차 감염 방지 목적으로 특수 필터 사용\n- Reference로 최정근식이 아닌, Morris식을 활용 (현재 서울대병원만 그렇다고 함.)\n- 검사는 많아야 3번, 지침서보다 적게 시행하는 듯함\n\n### 참관 후기\n랩실에 들어오고 처음 참여하게 된 연구라 타 연구들이 어떻게 진행이 되는지 자세히 알지는 못하지만, 이렇게 우리가 하고자 하는 분야에 대해 여쭤볼 사람들이 있고, 참관할 수 있다는 게 되게 좋은 기회인 것 같다. 연구의 방향성을 잡을 때 실제 현장에서의 수요가 뭔지에 대해 알 수가 없어 힘든 경우가 있는데, 이번 참관을 통해 현장에서의 요구와 우리가 목표로 해야하는 점들을 확실히 할 수 있어서 속이 시원한 기분이었다.\n\n### 연구 진행 사항\n현재 HW는 다른 분이 주로 담당해서 개발을 하고 있고, 나는 SW 개발에 집중을 하고자 한다. 목표는 우리가 만든 HW에서 측정한 값을 실시간으로 보면서 이에 맞는 피드백을 제공해주는 것인데, 마침 다른 기기로 측정한 dataset을 찾은 상태다. 그래서 나는 먼저 데이터를 시간축에 따라 읽으면서 Flow와 Volume값을 보고 이에 맞는 올바른 피드백을 제공해주는 SW 개발을 할 것 같다.\n\n### + 여담\n직접 폐기능 검사실에 방문한 김에 내 폐기능을 측정해보았다.![[민준_검사수치.jpg]]\nRef값의 80%이상이면 정상인데, 다행히 넘긴 했다. 하다보니 괜히 욕심 생기고 자존심을 건들단까... 100퍼를 넘기고 싶었다. "},{"excerpt":"2016 폐기능검사 지침 연구 간에 소프트웨어적으로 구현할 사항들 중 기존 지침에서 반영할 수 있는 내용을 알고자 2016년에 대한결핵및 호흡기학회에서 발간된 폐기능검사 지침을 참고하고자 한다. 검사 적합성 Pasted image 20241204203703.png 오류가 없는 적합한 검사가 3회 이상 나올 때까지 검사를 반복 기류-용적과 용적-시간 곡선을…","fields":{"slug":"/폐기능검사_지침_요약/"},"frontmatter":{"date":"2024년 12월 04일 12:12","title":"폐음연구 - 폐기능검사 지침 요약","tags":["폐음연구","학부연구생"]},"rawMarkdownBody":"## 2016 폐기능검사 지침\n연구 간에 소프트웨어적으로 구현할 사항들 중 기존 지침에서 반영할 수 있는 내용을 알고자 2016년에 대한결핵및 호흡기학회에서 발간된 폐기능검사 지침을 참고하고자 한다.\n## 검사 적합성\n![[Pasted image 20241204203703.png]]\n- 오류가 없는 적합한 검사가 3회 이상 나올 때까지 검사를 반복\n- 기류-용적과 용적-시간 곡선을 보고 적합성 판정\n- 가장 높은 FVC와 FEV1을 결정하고 이 두 합이 최대인 결과를 선정\n\n### 1. 검사 시작: 추정용적의 산출\n   ![[Pasted image 20241204204230.png]]\n   추적용적법을 통해 검사 시작 시간을 추정한다. 용적-시간 곡선에서 가장 기울기가 높은 곳에 접선을 그었을 때, 그 접선의 x절편이 검사 시작시간이 된다. 이때 EV값 (추정용적, back extrapolated volume)은 FVC의 5%와 150ml 중에 큰 수치보다 작아야한다.\n### 2. 검사 과정\n![[Pasted image 20241204211754.png]]\n   검사 대상자는 최대 흡기 상태에서 시작해야하고, 부드럽고 지속적인 호기를 해야한다.\n   - 조급함, 거짓시작, 최고오기기류속도 도달 시간이 120msec을 초과 시 재검\n   - 기침, 성대 폐쇄시 재검\n   - 호기의 조기 중단 또는 종료 없음: 용적-시간 곡선의 정상 부위를 보고 마지막 호기 최소 1초 동안 또는 적합한 호기 시간 후 용적 변화가 없으면 종료 시점으로 간주, 젊은 정산인의 경우 6초 이내에 끝날 수도 있음. 고령이나 폐쇄적 폐질환자는 6초보다 긴 호기가 여러번 나타날 수도 있는데, 이 경우는 검사자가 보고 더 이상 호기 불가능한 시점을 종료로 간주\n   - 기류가 새지 않음: 마우스피스 밖으로 새면 안됨\n   - 검사 도중 흡기가 있으면 안됨\n\n### 3. 검사 종료\n- 용적-시간 곡선에서 1초 이상 용적 변화가 없는 상태(25mL 미만 변화)를 유지해야함.\n\n### 검사 재현성\n![[Pasted image 20241204212429.png]]\n- 가장 높은 2개 FVC 수치들의 차이가 5%이내 또는 150 mL 이내여야 함.\n- FVC가 1.0 L 미만인 경우에는, 가장 높은 2개 수치들의 차이가 100 mL 이내여야 함.\n- 가장 높은 2개 FEV1 수치들의 차이도 150 mL 이내이어야 함.\n- 가장 높은 FVC와 FEV1 은 각기 다른 검사 결과에서 얻을 수 있음\n3개의 검사들이 재현성 기준에 안맞으면 최대 8번까지 검사를 반복한다. 검사를 하지 않기를 원하거나, 더 좋은 결과를 얻지 못할 것 같으면 가장 나은 검사 3개를 택한다.\n반복 검사 중에 FVC와 FEV1이 점점 감소하는 경우가 있는데 최초 검사치보다 20%이상 감소하는 경우 검사를 중단해야한다."},{"excerpt":"지난 회고 참고: ZeroPage_지금그때_2022 어제 중앙대학교 소프트웨어학부 학술동아리 ZeroPage에서 매년 주기적으로 열리는  행사를 다녀왔다. 이 행사는 졸업하신 선배분들과 재학생이 만나 선배분들의 그때와 우리들의 지금을 서로 공유하고 엿볼 수 있는 자리다. 후배분들은 학업이나 학교생활에 대한 본인의 고민을 털어 놓을 수 있고 이에 대한 조언…","fields":{"slug":"/ZeroPage_지금그때_2024/"},"frontmatter":{"date":"2024년 12월 01일 12:12","title":"2024 ZeroPage 지금그때","tags":["ZeroPage"]},"rawMarkdownBody":"지난 회고 참고: **[[ZeroPage_지금그때_2022]]**\n\n어제 중앙대학교 소프트웨어학부 학술동아리 [ZeroPage](https://portal.zeropage.org/)에서 매년 주기적으로 열리는 `지금그때` 행사를 다녀왔다.\n\n이 행사는 졸업하신 선배분들과 재학생이 만나 선배분들의 그때와 우리들의 지금을 서로 공유하고 엿볼 수 있는 자리다. 후배분들은 학업이나 학교생활에 대한 본인의 고민을 털어 놓을 수 있고 이에 대한 조언이나 선배분들의 경험을 들을 수 있다. 반대로 선배분들은 그런 질문들에 조언을 해주시고 요즘은 어떤 공부를 하는지, 학교 생활은 무엇이 달라졌는지 서로 이야기를 나눌 수 있는 자리이다.\n\n2023년에도 군복무 중에 휴가를 내서 참석을 했었는데 여건 상 기록을 못해서 올해는 이렇게라도 남겨보려고 한다. 올해는 약 20명정도가 모였고 재학생부터 99학번 선배님까지 평소 보기 힘든 분들까지 뵐 수 있었다.\n\n### 진행 방법\n총 3타임으로 나눠서 진행했고 매 타임마다 자유주제로 이야기를 이어갔다. 하루만에 기억이 날라간게 많아서 아쉽지만 기억나는 대로 적어보고자한다.\n\n### 공부\n최근에 든 고민 거리 중에 하나였는데, 좀 추상적으로 설명하자면, '이렇게 공부하는 게 맞는가?' 였다. 이런 고민이 든 이유는, 주변 사람들을 보면 각자 너무 재밌어하고 깊게 파고드는 기술이라든가, 개념이라든가, 그 기술 자체에 푹 빠져들어 공부하는 사람들을 많이 봐왔었다. 그러다보니 내가 공부하는 방식이 틀린 건가? 하는 생각이 종종 들었었다.\n\n지금까지는 어떠한 문제를 푸는 과정에서 필요에 의해 몇몇 개념과 기술들을 접하고 공부했는데 이러다보니 넓지만 얕은 지식만 쌓은 느낌이 들었다. 이런 고민이 들 찰나에, 선배가 해주신 말로는, 기본기가 잘 갖춰진 상태라면 아무 문제 없다, 오히려 본인은 한창 빅데이터에 푹 빠져서 공부를 했는데 요즘은 누구나 다 쓴다며 기술의 유행은 시도때도 없이 변하니까 그거에 맞게 따라갈 줄 알면 된다고 하셨다. \n\n필요에 의해 시작한 공부만큼 동기부여가 잘 된 경우가 없다는 이야기를 들었는데, 조금은 안심이 됐다. 그래도 어긋나가지는 않았구나 하는 생각이 들었다. 그렇지만 제너럴리스트는 되기 싫으니까, 공부를 해나가다가 내가 잘할 수 있는 분야를 얼른 찾아야겠다는 생각이 들긴 했다.\n\n### 군대\n아직 미필인 후배들한테는 한창 군대 이슈가 핫했다. 재작년의 나를 보는 기분이었다. 정보보호병으로 갈지, 공군을 갈지, 카투사는 붙을 수 있을지, 다 안되면 어떡하지, 등 여러 고민과 이로 인한 공부에 대한 공백 때문에 스트레스를 너무 받았었는데, 23학번 후배들도 비슷한 고민이 있는 것 같았다.\n\n이제와서 생각하면, 뭐로 가든 장단점은 있고, 대신 전역하고 복학 전까지 충분한 시간을 마련할 수 있게 군대를 가는 게 좋은 것 같다. 군대에서도, 군대에서만 배울 수 있는 게 있으니까 그거에 집중하고 평소에 하지 못했던 것들을 경험해보는 게 군복무를 잘 다녀오는 방법인 것 같다.\n\n평소 읽지 못했던 책을 읽어보고 많은 고민을 해보고, 본인에 대해 더 알아보고 취향을 찾아보는 것도 지루한 군복무를 조금은 다채롭게 만들 수 있는 방법인 것 같다. 운동을 습관화해오는 것도 추천한다.\n\n### 우리 동아리 문 닫습니다?\n![[Pasted image 20241202230437.png]]\n그렇다고 한다. 전역한 지 얼마 안돼서 동아리가 이 정도인 줄 모르고 있었는데 생각보다 활동 인원이 없는 것 같다. 선배분들 말로는 전에도 똑같은 상황이 있었다고, 걱정하지 말라고 하셨는데 회장단은 또 나름대로 고민이 많아보였다. \n\n내가 보기엔 동아리를 이끌어줄 3,4학년들이 코로나 학번이라 많이 없는 것 같다. 내가 새내기때도 열심히 활동하는 3,4학년을 보고 이거저거 참여했었는데, 지금은 고학년 부재로 참여하는 저학년분들이 없어서 아쉬운 것 같다. 그래도 애정하는 동아리인만큼, 어떻게든 동아리가 잘 이어나갔으면 좋겠다.\n\n### 2024 지금그때 회고\n![[Pasted image 20241203000143.png]]\n재학 중인 선후배도 만나고, 현직에 계신 분들도 만나면서 얼른 다시 학교 생활을 하고 싶다는 생각이 잠깐 들었다. 아직도 모르는 게 너무 많고, 배워야할 것도 너무도 많지만 그 과정이 너무 재밌고 내년, 내후년의 내가 어떤 고민을 갖고 살아갈지가 궁금해지는 하루였다. "},{"excerpt":"11월 22일에 강시혁 교수님, 권병수 교수님과 폐음 연구 관련 미팅이 있었다. 원래 우리팀의 연구는 폐질환자의 재활을 유도할 수 있는 간단한 spirometer의 제작과 사용자의 노력성 호기를 유도하고 올바른 방법을 안내할 수 있는 앱 구현이 주된 방향성이었다. 기존에 진행되었던 연구들은 대부분 간단한 기기나, 스마트폰만으로도 사용자의 폐기능을 간단하게…","fields":{"slug":"/20241122_미팅내용정리/"},"frontmatter":{"date":"2024년 11월 26일 12:11","title":"11/22 폐음연구 관련 미팅 내용 정리","tags":["폐음연구","학부연구생"]},"rawMarkdownBody":"11월 22일에 [강시혁 교수님](https://sites.google.com/view/si-hyuck-kang/home?authuser=0), [권병수 교수님](https://www.snubh.org/medical/drIntroduce.do?DP_TP=&DP_CD=IMR&sDpCdDtl=IMR&sDrSid=1029327&sDrStfNo=66098&sDpTp=)과 폐음 연구 관련 미팅이 있었다. \n\n원래 우리팀의 연구는 **폐질환자의 재활을 유도할 수 있는 간단한 spirometer의 제작**과 사용자의 노력성 호기를 유도하고 올바른 방법을 안내할 수 있는 앱 구현이 주된 방향성이었다. 기존에 진행되었던 연구들은 대부분 간단한 기기나, 스마트폰만으로도 사용자의 폐기능을 간단하게 측정하는 부분에 초점을 맞추었기에, 폐질환을 지닌 사용자의 폐기능을 주기적으로 트래킹하면서 재활 유도에 집중하려고 했다.\n\n우선 spirometer의 폐기능 측정 방식은 터빈에 자석을 부착해서 홀센서 방식으로 센싱을 하고 있고 실제 임상에서 사용되는 기기만큼의 정확도를 재현하기 위해 하드웨어를 수정해가고 있다.\n\n### 미팅 내용\n미팅을 하면서 적은 내용과 Q&A를 간단히 옮겨 적으면 아래와 같다.\n- *CHI'20 SpiroPlay* 연구 확인하기\n\t- 미팅 직전에 우리가 하고자하는 주제와 너무 비슷한 논문이 있었음, 바로 읽어볼 예정\n- `터빈 + 자석` 과 같은 홀센서로 spirometer를 구현하는게 특허에 걸리는지 확인하기\n- 폐질환자를 트래킹하는 과정에서 FVC가 해당 기간 내에 10% 이상 감소하면 악화로 판단\n\t- 매 측정마다 오차를 줄이는 게 중요\n\t- 실제 임상 기기와의 값 차이를 줄이는 게 중요\n\t- `일관성`이 가장 중요할듯\n\t- 기존 제작하던 터빈 형태는 바람이 약하더라도 관성 때문에 힘이 약해져도 계속 돌아가게 되는 데, 이 부분이 오차로 작용할 가능성 있음, 어떻게 해결할지?\n- 자가폐기능검사에 대한 수요는 점차 증가하고 있음\n\t- 폐기능 검사실 포화라고 함\n\t- 특히 어린이 천식 환자\n- 폐기능 지침에 따르면 최소 3번에서 최대 8번까지 검사를 시행하고 이때 Flow Volume Curve를 보고 검사를 잘했는지 판단. \n- 정확성 높은 기기도 중요하지만, 옆에서 끝까지 바람을 불게 해주는 `독려`가 중요.\n\t- `독려`를 해줄만한 SW가 중요\n\t- 실제로는 검사해주는 사람이 엄청 옆에서 독려해준다고함.\n- 실제 임상에서는 폐활량계의 다양한 파라미터까지 알려고 하지는 않음. \n\t- 기본적인 파라미터를 정확성, 일관성있게 뽑는 게 중요할듯\n- Flow Volume Curve 모양도 진단 과정에서 중요하다고 함\n- ILD의 경우 FVC, 천식과 COPD의 경우 FEV 중요\n\n### 미팅 결과\n연구 방향성을 바꿀 필요를 느꼈다. 재활, 게임 형식의 결과물보다 일관성 있고 정확도 있는 측정값을 내는 HW가 우선이 되어야할 것 같고, 폐기능검사 지침을 참고해서 사용자가 집이나 병원이 아닌 곳이더라도 올바른 방식으로 폐기능 검사를 유도할 수 있는 SW 구현에 집중해야할 것 같다."},{"excerpt":"mobile spirometry 관련 자료로 돌아가기 과제명 SpiroSmart: Using a Microphone to Measure Lung Function on a Mobile 발행년월 2012-09 링크 https://dl.acm.org/doi/10.1145/2370216.2370261 요약 SpiroSmart는 내장 마이크를 활용해 폐활량 측정을…","fields":{"slug":"/spirosmart/"},"frontmatter":{"date":"2024년 11월 19일 17:11","title":"논문 요약 - SpiroSmart: Using a Microphone to Measure\rLung Function on a Mobile Phone","tags":["폐음연구","논문리뷰","학부연구생"]},"rawMarkdownBody":"**[[mobile spirometry 관련 자료]]로 돌아가기**\n\n| 과제명  | SpiroSmart: Using a Microphone to Measure Lung Function on a Mobile |\n| ---- | ------------------------------------------------------------------- |\n| 발행년월 | 2012-09                                                             |\n| 링크   | https://dl.acm.org/doi/10.1145/2370216.2370261                      |\n\n## 요약\n- SpiroSmart는 내장 마이크를 활용해 폐활량 측정을 수행하는 저가용 모바일 폰 애플리케이션\n- 데이터 변환 과정 아래 참고\n-  측정 파라미터\n\t- FVC\n\t- FEV1\n\t- FEV1 / FVC\n\t- PEF\n- 활용 디바이스: iPhone 4s\n- 52명의 피실험자 대상으로 임상에서 사용하는 기기와 5.1% 오차 존재 (2012년 기준).\n\n## 연구의 주된 알고리즘\n마이크를 통해 녹음된 음성 데이터를 폐기능 평가에 필요한 데이터로 변환하는 게 목표.\n### **1. 입력 데이터: 압력 신호 p(t)**\n- 마이크로폰은 입에서 나오는 압력 신호를 수집\n- 이 신호는 **교류 결합(AC-coupled)** 특성을 가지며, 실제 압력의 비례적인 측정값으로 제공\n\n### **2. 압력 손실 보정**\n\n#### **(1) 거리 및 소리 반사 보정**\n- 입에서 스마트폰 마이크까지의 거리에서 발생하는 압력 손실을 보정\n- 사용자의 머리 주변에서 발생하는 소리 반사와 회절 효과도 모델링.\n\n#### **(2) Inverse Radiation Modeling**\n- 소리의 전파를 구체적으로 모델링하기 위해 구형 장애물(spherical baffle)의 음향 전달 함수를 사용 (함수 내용은 논문 참고)\n- 이 모델은 시간 도메인에서 역변환하여 FIR 필터링을 통해 신호에 적용\n\n### **3. 흐름 속도 변환**\n\n#### **(1) 압력을 흐름 속도로 변환**\n- 입술에서의 난류 흐름을 모델링하여 압력($plips​(t)$)을 공기 흐름 속도($ulips(t)$)로 변환\n- 관련 계산식도 논문 참고\n\n### **4. 특징 추출**\nSpiroSmart는 신호로부터 의미 있는 특징을 추출하기 위해 세 가지 주요 방법을 사용\n\n#### **(1) 시간 도메인: 신호 Envelope 계산**\n- 신호의 Hilbert 변환을 사용해 Envelope 계산\n- Envelope는 신호의 저주파 에너지를 나타내며, 공기 흐름 속도의 근사값으로 간주될 수 있음\n#### **(2) 주파수 도메인: Spectogram Processing**\n- 신호를 짧은 시간 프레임(30ms)으로 나누어 각 프레임의 FFT 계산\n- local resonance을 추출해 공기 흐름 속도와의 비례 관계를 파악\n#### **(3) 선형 예측 코딩(LPC)**\n- LPC를 사용하여 신호의 원천 파워와 음성 통로 필터(vocal tract filter)를 분리\n- 음성 통로 필터의 \"소스 파워\"는 폐에서 발생하는 흐름 속도의 근사값을 제공\n\n### **5. 머신 러닝 모델**\n\n#### **(1) 폐 기능 지표 회귀**\n- 추출된 특징(예: 신호 Envelope, 공명, LPC)을 사용하여 강제 폐활량(FVC), 1초 강제 호기량(FEV1), 최대 호기 속도(PEF)를 예측\n- 특징 값은 모델(bagged decision tree)을 통해 지표로 변환\n\n#### **(2) 곡선 모양 회귀**\n- 폐 기능 곡선의 모양(예: Flow-Volume 곡선)을 예측하기 위해 CRF(Conditional Random Field를 사용\n- 곡선의 형상을 정규화한 후, 예측된 지표 값을 사용해 곡선을 스케일링\n\n### **6. 결과 후처리**\n- 예측된 값은 Savitzky-Golay 필터(3차 다항식)를 사용해 잡음을 제거하고 부드럽게 만둚\n- 물리적으로 불가능한 곡선(예: 부피가 단조 증가하지 않는 곡선)은 제거"},{"excerpt":"mobile spirometry 관련 자료로 돌아가기 과제명 스마트기기 내장 마이크기반 폐질환 진단기기 개발 발행년월 2019-11 연구기관 원광대학교 링크 https://scienceon.kisti.re.kr/srch/selectPORSrchReport.do?cn=TRKO202000001587#; 요약 모바일 핸드폰의 내장 마이크를 활용해 사용자의 호기…","fields":{"slug":"/스마트기기 내장 마이크기반 폐질환 진단기기 개발/"},"frontmatter":{"date":"2024년 11월 18일 12:11","title":"논문 요약 - 스마트기기 내장 마이크기반 폐질환 진단기기 개발","tags":["폐음연구","논문리뷰","학부연구생"]},"rawMarkdownBody":"**[[mobile spirometry 관련 자료]]로 돌아가기**\n\n| 과제명  | 스마트기기 내장 마이크기반 폐질환 진단기기 개발                                                      |\n| ---- | ------------------------------------------------------------------------------- |\n| 발행년월 | 2019-11                                                                         |\n| 연구기관 | 원광대학교                                                                           |\n| 링크   | https://scienceon.kisti.re.kr/srch/selectPORSrchReport.do?cn=TRKO202000001587#; |\n\n## 요약\n- 모바일 핸드폰의 내장 마이크를 활용해 사용자의 호기시 음성 데이터를 기반으로 폐기능 평가.\n- VFCDM으로 주파수 분석\n\t- SPWV, STFT, WT, VFCDM 중 VFCDM이 가장 결과가 정확했음\n- 측정 파라미터\n\t- FVC\n\t- FEV1\n\t- FEV1 / FVC\n\t- PEF\n- 추가로 앱과 클라우드 서비스 구현\n- 활용 디바이스: iPhone 5s\n- 오차율: 2~3%\n\n## 연구 배경 및 필요성\n- **만성 호흡 질환의 심각성**\n    - WHO에 따르면 만성 폐쇄성폐질환(COPD) 환자는 전 세계적으로 6,400만 명, 천식 환자는 2억 3,500만 명에 달함.\n    - 국내에서는 40세 이상 COPD 유병률이 14.6%, 65세 이상은 30.2%로 연령 증가에 따라 높은 비율을 보임.\n- **자가 진단의 필요성**\n    - 현재 천식 및 COPD 진단은 폐활량계(spirometry test)를 통해 이루어짐. 이는 병원 방문이 필수적이며 지속적인 경과 추적이 어려운 문제가 있음.\n    - 정기적인 spirometry 검사를 통해 조기 진단이 가능하지만, 환자의 시간적·물리적 제약으로 인해 검사율이 낮음.\n    - “언제 어디서나 간편하게” 진단할 수 있는 스마트기기 기반 솔루션에 대한 수요 증가.\n\n## 연구 목표\n- **스마트기기 활용**\n    - 스마트폰 및 웨어러블 기기의 내장 마이크를 활용해 폐활량계를 대체할 수 있는 기술 개발.\n- **진단 알고리즘 및 플랫폼**\n    - 호흡 데이터를 정밀 분석하여 임상적으로 활용 가능한 지표(FVC, FEV1, FEV1/FVC, PEF)를 측정.\n    - 이를 기반으로 천식 및 COPD를 조기 진단하고 관리할 수 있는 애플리케이션 및 클라우드 플랫폼 구현.\n\n## 연구 내용\n- 특별한 **부가 장치 없이 스마트폰 내장 마이크 기반으로 호기시 신호를 측정**\n- **VFCDM을** 활용하여 임상에서 사용되는 PFT parameters(FVC, FEV1, FEV1/FVC, PEF)를 검출\n\t- 마이크를 이용하여 측정된 오디오 신호를 VFCDM을 활용하여 주파수 분석을 통한 noise를 제외한 실제 호기시 신호만을 검출\n\t- SPWV, STFT, WT 등 이전의 시간-주파수 분석 방법보다 VFCDM은 더 높은 해상도가 나타남\n\t- 검출된 신호를 활용하여 PFT parameters 평가\n- 알고리즘을 기반으로 스마트폰 어플리케이션 및 클라우드 플랫폼 개발\n\t- 실제 임상에서 사용되는 프로토콜을 기반으로 측정 횟수 및 검출 parameters 및 그래프 출력 ![[Pasted image 20241119221121.png]]\n\t- 측정된 PFT 결과 관리 및 모니터링을 위한 클라우드 플랫폼을 개발 ![[Pasted image 20241119221206.png]]\n\t- 임상에서 중요하게 사용되는 parameter인 FEV1/FVC의 정확도 검증을 위하여 13명의 실험자를 대상으로 검증한 결과 absolute error mean 4.12 및 standard deviation 3.45로 높은 정확도가 나타남 ![[Pasted image 20241119223351.png]]\n\n\n## 주요 기술 및 성과\n1. **VFCDM 및 Resonance Tracking**\n    - 노력성 호기 신호에서 목소리나 환경 소음을 제거해 호흡 데이터를 정확히 분석.\n    - FVC, FEV1, FEV1/FVC 등의 임상 지표를 정밀하게 계산.\n2. **스마트기기 기반 시스템**\n    - 병원 방문 없이 간단한 호흡만으로 천식 및 COPD를 검사할 수 있는 스마트폰 앱 개발.\n    - 클라우드 플랫폼을 통해 데이터를 저장하고 장기적으로 관리.\n3. **비교 분석 결과**\n    - 임상 검사의 주요 지표(FEV1/FVC 비율 등)와 비교했을 때, 2~3% 내외의 오차율로 실제 활용 가능성을 입증.\n\n## 연구 의의 및 기대 효과\n1. **의료 접근성 개선**\n    - 의료기관 방문 없이 스마트기기만으로 폐질환을 진단하고 관리 가능.\n    - 의료 인프라가 부족한 지역에서도 활용 가능.\n2. **조기 진단 및 관리**\n    - 천식 및 COPD를 조기에 발견하고, 환자의 상태를 지속적으로 추적 관리할 수 있음.\n3. **국민 건강 증진**\n    - 간편한 진단 시스템으로 일반인의 질환 발견률 증가.\n    - 만성 폐질환의 조기 발견 및 치료 기회 확대.\n\n## 연구의 한계 및 개선 방향\n- 다양한 환경에서 신호 정밀도를 유지하기 위한 알고리즘 개선 필요.\n- 웨어러블 기기와의 통합 및 사용자 편의성 향상을 위한 추가 연구.\n"},{"excerpt":"관련 논문 목록 spirosmart 스마트기기 내장 마이크기반 폐질환 진단기기 개발 시중에서 파는 모델 목록 Spirobank Smart SP70BPasted image 20241121012439.png SP80BPasted image 20241121012724.png SPM-A Pasted image 20241121013623.png ETC 삼성리서치 …","fields":{"slug":"/mobile spirometry 관련 자료/"},"frontmatter":{"date":"2024년 11월 17일 12:11","title":"mobile spirometry 관련 논문","tags":["폐음연구","학부연구생"]},"rawMarkdownBody":"### 관련 논문 목록\n- [[spirosmart]]\n- [[스마트기기 내장 마이크기반 폐질환 진단기기 개발]]\n\n### 시중에서 파는 모델 목록\n- [Spirobank Smart](https://spirometry.com/en/products/spirobank-smart/)\n- SP70B![[Pasted image 20241121012439.png]]\n- SP80B![[Pasted image 20241121012724.png]]\n- SPM-A ![[Pasted image 20241121013623.png]]\n### ETC\n- [삼성리서치 연구진 스마트폰 폐 기능 측정 기술로 국제학술대회 최우수상](https://www.khan.co.kr/economy/economy-general/article/202004231115001)\n\t- 관련 논문 찾는 중\n\n### 자료 비교\n\n|                 | [[spirosmart]]                   | [원광대 연구](https://minjun.blog/%EC%8A%A4%EB%A7%88%ED%8A%B8%EA%B8%B0%EA%B8%B0%20%EB%82%B4%EC%9E%A5%20%EB%A7%88%EC%9D%B4%ED%81%AC%EA%B8%B0%EB%B0%98%20%ED%8F%90%EC%A7%88%ED%99%98%20%EC%A7%84%EB%8B%A8%EA%B8%B0%EA%B8%B0%20%EA%B0%9C%EB%B0%9C/) |\n| --------------- | -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 임상기기 대비 오차율     | 5.1%                             | 2~3%                                                                                                                                                                                                                                        |\n| 측정 파라미터         | FVC<br>FEV1<br>FEV1 / FVC<br>PEF | FVC<br>FEV1<br>FEV1 / FVC<br>PEF                                                                                                                                                                                                            |\n\n\n|                 | [Spirobank Smart](https://spirometry.com/en/products/spirobank-smart/)   | SP70B                                                                    | SP80B                                                                    | SPM-A                          |\n| --------------- | ------------------------------------------------------------------------ | ------------------------------------------------------------------------ | ------------------------------------------------------------------------ | ------------------------------ |\n| 임상기기 대비 오차율     | Unknown                                                                  | Unknown                                                                  | Unknown                                                                  | Unknown                        |\n| 측정 파라미터         | FVC<br>FEV1<br>FEV1 / FVC<br>PEF<br>FEV / FVC <br>FEV6<br>FEF2575<br>... | FVC<br>FEV1<br>FEV1 / FVC<br>PEF<br>FEV / FVC <br>FEV6<br>FEF2575<br>... | FVC<br>FEV1<br>FEV1 / FVC<br>PEF<br>FEV / FVC <br>FEV6<br>FEF2575<br>... | FVC<br>VC<br>MVV<br>40 more... |\n| Flow range      | ±16 L/s                                                                  | 0 L/s ~ 16 L/s                                                           | 0 L/s ~ 16 L/s                                                           | 1 L/s ~ 16 L/s                 |\n| Volume accuracy | ±2.5% or 0.05 L                                                          | ±3% or 0.05 L                                                            | ±3% or 0.05 L                                                            | ±3% or 0.05 L                  |\n| Flow accuracy   | ±5.0% or 0.20 L/s                                                        | ±5.0% or 0.2 L/s                                                         | ±5.0% or 0.2 L/s                                                         | ±10% or ±0.3 L/s               |\n"},{"excerpt":"과제 요약 apply.techcourse.co.kr_assignment_14_mission_52.png 과제 진행 소감 문제 요구 사항 파악 앞서 진행했던 것보다 요구하는 게 많았던 이번 주 과제였던 것 같습니다. 처음 과제를 받았을 때는 구현해야할 사항들이 많아서 쫓기는 마음으로 시작을 했었는데, 이 때문에 후반가서 잘못 이해하고 있던 게 있었습니다. …","fields":{"slug":"/우아한테크코스_7기_BE_프리코스_4주차_회고/"},"frontmatter":{"date":"2024년 11월 10일 12:11","title":"우아한테크코스 7기 BE 프리코스 4주차 회고","tags":["프리코스","우아한테크코스"]},"rawMarkdownBody":"## 과제 요약\n![[apply.techcourse.co.kr_assignment_14_mission_52.png]]\n\n## 과제 진행 소감\n### 문제 요구 사항 파악\n앞서 진행했던 것보다 요구하는 게 많았던 이번 주 과제였던 것 같습니다. 처음 과제를 받았을 때는 구현해야할 사항들이 많아서 쫓기는 마음으로 시작을 했었는데, 이 때문에 후반가서 잘못 이해하고 있던 게 있었습니다.\n\n![[Pasted image 20241111004043.png]]\n이 부분을 보고 사용자가 특정 아이템을 구매하면, 그만큼을 메모리에서 구현된 재고에서 차감하고, 이를 다시 products.md에도 반영을 해야하는 줄 알았습니다. 모든 기능을 구현하고, 기본으로 제공해주는 테스트를 통과한 뒤에, 온라인에 제출을 했는데 케이스 1개를 통과하지 못한 상황이 발생했습니다. 여러 방면으로 삽질을 하다가 다행히 잘 못 이해한 부분을 찾았는데, 이런 사소한 부분에 대한 체크가 중요하다는 걸 다시 한 번 느꼈던 것 같습니다.\n\n### 지원서나 중간 회고에서 현실적인 목표를 설정하고 이를 달성했다고 생각하나요? 그 이유는 무엇인가요?\n지원서에서 이번 프리코스 기간 동안 테스트 코드를 작성하는 데에 익숙해지는 것을 목표로 잡았습니다. 앞서 진했던 1,2,3주의 과제와 달리 이번 주차 과제에서는 테스트 코드로 단위 테스트를 하기 어려웠던 것 같습니다. \n\n지난 과제에서는 어떤 형식으로 특정 값을 반환하는 메소드를 만들어야겠다는 확실한 판단을 갖고 메소드를 만들어서 이를 테스트를 하는 의의가 있었습니다. 하지만 이번 과제에서는, 특히 프로모션에 대한 기능을 구현하면서 어떠한 메소드를 만들어도 계속 그 기능과 반환값을 수정하는 등, 메인 코드들이 변경되는 경우가 많이 생겼습니다. 그렇기에 어떤 기능을 구현하는 코드의 테스트 코드를 작성해도 전체 개발 간에 메인 코드를 지속적으로 수정하면서 테스트 코드까지 같이 수정해야해서 오히려 개발 시간이 길어지는 현상이 생기기도 했습니다. \n\n테스트 코드를 작성하는 데 익숙해져야겠다는 목표는 달성했다고 생각을 하고, 이를 달성하면서 전체 서비스를 어떤 식으로 구현해야할지에 대한 확실한 판단이 선행되어야 겠다는 점도 깨달았습니다.\n### 중간 회고에서 조정한 목표가 실제 목표 달성에 도움이 되었나요? 목표를 달성하는 데 어떤 점이 효과적이었다고 생각하나요?\n중간 회고 이후 기록하는 과정에 소모되는 시간이 많이 줄었습니다. 프리코스 기간동안 거의 매일 코딩이나 피어리뷰를 했었는데 이를 하면서 새롭게 깨달은 내용이나, 다음 과제간 신경써야할 부분을 간단히라도 기록을 했었습니다. \n\n특히 테스트 코드 작성에 대한 점을 많이 기록을 했었는데, 이 덕에 확실히 테스트 코드를 통해 개발을 하는 과정이 익숙해진 것 같고, 다양한 방식의 테스트 코드를 작성할 수 있었습니다.\n### 각 미션의 목표를 달성하기 위해 세운 계획을 잘 이행했나요? 그 과정에서 어떤 전략이 효과가 있었나요?\n우테코에서 준 공통 피드백을 꼼꼼히 자주 읽던게 각 미션 목표를 이행하는데 많은 도움이 된 것 같습니다. \n\n사실 코딩을 하고 서로 피어 리뷰를 진행하면서도 '뭐가 정답일까', 혹은 '어떤 스타일로 코드를 작성하는 게 좋은건가' 라는 생각이 있었습니다. 피드백을 읽는 과정에서 역시 코딩을 하는 과정에서 정답은 없다는 걸 깨닫기는 했지만, 그래도 코드를 작성하는 긍정적인 컨벤션을 어깨넘어로 배울 수 있었고, 이를 체화하는 과정에서 각 미션에서 제공해준 목표를 자연스럽게 달성할 수 있었던 것 같습니다.\n### 몰입하고 함께 성장하는 과정을 통해 인상 깊었던 경험이나 변화가 있었나요?\n과제를 제출하고 서로 리뷰를 진행했던 게 가장 기억에 남는 것 같습니다. 다른 사람의 코드를 이렇게 깊게, 오랫동안 보고 분석한 적이 처음이었는데, 리뷰를 하고 받는 과정에서 배운 게 굉장히 많았고, 한 가지 주제에서 나랑 같은 코드가 하나도 없다는 점이 꽤 재밌게 느껴졌습니다.\n\n우선, 처음에는 코드 리뷰가 쉽지는 않았습니다. 다른 사람의 코드와 생각을 이해하는 과정이 꽤 오랜 시간과 집중을 필요로 하는 일임을 알 수 있었고, 반대로 그만큼 저는 코드를 더 가독성 좋게, 이해하기 쉽게 작성해야겠다는 생각도 했습니다. 좋은 리뷰를 해주고 싶은 만큼 자바라는 언어와, 객체 지향이라는 개념을 공부할 수 있었고 학습한 만큼 상대방에게 좋은 피드백을 줄 수 있다는 것도 뿌듯했습니다. \n\n코드 리뷰를 하면서 같은 고민을 나눌 수 있는 점도 좋았습니다. 과제를 구현하면서 혼자 했던 고민들, 리뷰 과정에서 생긴 해결되지 않은 문제들을 나누고, 이야기 하면서 제 궁금증을 해결할 수 있었습니다.\n\n그리고 무엇보다, 코드 리뷰를 하면 저보다 수준이 높고, 많은 손을 거친 코드들을 볼 수 있는데, 이분들의 코드를 보면서 제 코드를 개선시켜날 수 있는 점이 좋았습니다. 코드 보는 안목이 잡혀나가는 것 같고, 저만의 기준이 생기면서 이를 다음 과제에 적용해나가는 과정이 꽤나 재미있게 느껴졌습니다. "},{"excerpt":"과제 요약 apply.techcourse.co.kr_assignment_14_mission_49 2.png 과제 진행 소감 MVC, 디자인 패턴 꼭 적용해야하나? 1, 2주차는 시작과 동시에 기능에 따라 코드를 분리하려고 노력했었지만, 이번 3주차에서는 우선적으로 기능 구현에 초점을 두었습니다. 1, 2주차보다는 조금 더 빠르게 구현을 해보고 싶어서 코드…","fields":{"slug":"/우아한테크코스_7기_BE_프리코스_3주차_회고/"},"frontmatter":{"date":"2024년 11월 04일 12:11","title":"우아한테크코스 7기 BE 프리코스 3주차 회고","tags":["프리코스","우아한테크코스"]},"rawMarkdownBody":"## 과제 요약\n![[apply.techcourse.co.kr_assignment_14_mission_49 2.png]]\n\n## 과제 진행 소감\n### MVC, 디자인 패턴 꼭 적용해야하나?\n1, 2주차는 시작과 동시에 기능에 따라 코드를 분리하려고 노력했었지만, 이번 3주차에서는 우선적으로 기능 구현에 초점을 두었습니다. 1, 2주차보다는 조금 더 빠르게 구현을 해보고 싶어서 코드의 구조가 조금 망가지더라도 기능구현을 먼저 해두고, 필요에 따라 중간에 분리를 하거나 완성 후에 코드 분리를 진행했습니다.\n\nMVC 패턴을 이번 프리코스를 하면서 처음 적용해보았는데, 1, 2주차 기간에는 처음부터 이 패턴을 적용하느라 억지로 코드를 작성한 감이 있었습니다. 그렇다보니 이 패턴의 장점이나, 필요성 보다는 틀에 맞추면서 코딩을 하는 듯한 느낌을 받았었는데, 이번에는 반대였습니다. \n\n오히려 막무가내로 코딩을 하는 과정에서 어느정도 정형화 된 틀의 필요성을 느꼈고, 특히 Controller와 View의 분리의 필요성을 느꼈습니다. 입력값의 유효성을 판단해주는 과정을 처음에는 View에서 해줘야 된다고 생각했었습니다. 사용자의 입력을 받는 역할이 View니까, View가 마찬가지로 재요구하기 위해 Validation까지 해줘야하지 않나? 로 시작해서 코딩을 했었는데, View와 Util의 의존성이 점점 커지는 것 같아서 Controller에서 입력값의 유효성을 판단하도록 코드를 수정했고, View는 본래의 기능에 충실할 수 있었습니다. \n\n1, 2, 3주차의 프리코스를 경험하면서 디자인 패턴을 공부하기 위해 억지로 그 패턴에 적용해보는 것도 필요하다고 생각이 들었고, 반대로 막무가내로 코딩을 해보는 것도 그 패턴의 중요성을 느낄 수 있는 방법일 거라고 느꼈습니다. 그리고 디자인 패턴이라는 게 억지로 만든 거라기 보다는, 기능에 따라 코드를 분리하면서 자연스럽게 생긴 형식이라는 걸 다시 한 번 느낄 수 있었던 것 같습니다.\n\n### 사소하지만 중요한 것들\n매 주차별 미션에서 신경을 쓰는 부분이지만 아직 부족한 점들이 있는 것 같습니다. 함수와 변수의 명명, 접근 제한자 같은 부분들을 1주차에서 많이 놓쳐서 피드백을 받았는데, 2, 3주차에 걸쳐 개선해보려고 노력했습니다. 명명 규칙의 경우, 단순하지만 처음 보는 사람이 의미를 바로 파악할 수 있는 이름으로 지으려고 했는데, 만족스럽지 않은 경우도 있어서 리뷰를 받아보면서 개선해나가고 싶었습니다."},{"excerpt":"과제 요약 apply.techcourse.co.kr_assignment_14_mission_46.png 과제 진행 소감 지원서에 작성한 목표를 얼마나 달성하고 있다고 생각하나요? 그 이유는 무엇인가요? 지원서에 작성한 목표는 크게 4개입니다. 코드에 의미 부여 및 구현 능력 향상 자바에 대한 이해 심화 다른 사람의 코드 리뷰 블로그 기록 및 정리 이 중에…","fields":{"slug":"/우아한테크코스_7기_BE_프리코스_2주차_회고/"},"frontmatter":{"date":"2024년 10월 28일 11:10","title":"우아한테크코스 7기 BE 프리코스 2주차 회고","tags":["프리코스","우아한테크코스"]},"rawMarkdownBody":"## 과제 요약\n![[apply.techcourse.co.kr_assignment_14_mission_46.png]]\n\n## 과제 진행 소감\n### 지원서에 작성한 목표를 얼마나 달성하고 있다고 생각하나요? 그 이유는 무엇인가요?\n지원서에 작성한 목표는 크게 4개입니다.\n\n- 코드에 의미 부여 및 구현 능력 향상\n- 자바에 대한 이해 심화\n- 다른 사람의 코드 리뷰\n- 블로그 기록 및 정리\n\n이 중에서 절반 정도 달성하고 있다고 생각합니다. \n\n이번 프리코스를 진행하면서 그 어느때보다 '확장가능한 코드'를 작성하려고 노력하고 있습니다. 지금까지 해온 코딩은 대부분 1회성 코드였기 때문에 원하는 결과물을 잘 도출해내는지에 대해서만 집중했다면, 이번 기간동안에는 추후에 다른 사람이 개발을 이어가더라도 문제 없이 진행할 수 있게 각 클래스, 매서드가 자기 일을 하게 만들고 가독성 있게 코드를 작성하려고 신경 쓴 것 같습니다. 그 과정에서 자바의 Stream API도 학습하면서 전보다 더 효율적인 코딩을 할 수 있게 되었습니다.\n\n코드리뷰는 처음이었습니다. 생각보다 다른 사람이 쓴 코드의 구조와 기능을 이해하는데 오래 걸린 적도 있고, 무엇보다 코드를 작성하는 데 있어서 정답은 없지만 오답은 있다고 생각하여 조심스럽게 리뷰를 한 적도 있었습니다. 리뷰를 잘 해보고 싶다는 생각도 들었는데, 그만큼 자바라는 언어와 객체지향이라는 개념에 대해 잘 알아야한다고 느꼈고, 2주차부터는 좀 더 개선된 리뷰를 해주고 싶다는 생각도 들었습니다. 리뷰를 하고 받는 과정에서 다른 사람의 풀이법도 배우고 제가 쓴 코드의 문제점과 개선점을 파악할 수 있었습니다. 이를 반영하여 2주차 과제를 했는데, 아직까지도 개선점이 많다고 느끼고 있습니다. \n\n계획했던 것만큼 기록에 많은 시간을 투자하지 못하고 있는 것 같습니다. 원래는 매일 기록을 하려고 계획했었는데, 아직까지는 코드를 작성하고 수정하는 과정에 많은 시간이 필요한 것 같습니다. 그렇게 시간을 소비하는 만큼 코드가 개선되는 게 보여서 손을 떼지 못하고 있는 것 같고, 목표를 수정할 필요성을 느끼고 있습니다.\n\n### 지원서에 작성한 목표를 변경해야 한다고 생각하시나요? 그렇다면 그 이유와 어떤 목표로 변경하고 싶으신가요?\n지금까지는 기록이라는 과정에 꽤 많은 힘을 주고 있느라 쉽게쉽게 블로그에 포스팅을 하지 못했던 것 같습니다. 이 점 때문에 위에서 말했듯 매일 기록을 하려고 했던 계획을 못 지키고 있는데 단위를 과제 기간에 맞게, 과제 제출 후 다른 사람의 코드 리뷰를 하면서 제 코드의 개선점을 파악하며 기록을 해보려고 합니다.\n\n코드를 작성하는 중간에는 제가 뭘 잘 못하고 있는지 파악이 안되기 때문에 리뷰를 하고 받은 후에 다음 주차 과제를 시작하기 전, 회고를 작성하면 좋을 것 같습니다.\n\n### 프리코스를 진행하면서 눈에 띄는 변화나 깨달은 점이 있나요?\n어느 순간 과연 '내가 프로그래밍을 재밌어할까?'라는 막연한 의문이 들었던 것 같습니다. 초등학생때부터 찾아서 할 정도로 좋아했었는데 시간이 지나면서 어느정도 의무감에 공부를 해왔던 것 같습니다. \n\n하지만 이번 프리코스를 진행하면서 노트북 앞에 앉아있지 않더라도 계속해서 제가 쓴 코드에 대해 고심하고, 테스트 코드는 어떻게 작성해야하는지 고민하면서 이 과정에 깊게 몰입할 수 있었습니다. 코드리뷰를 하면서도 저와는 다르게 풀이하는 과정도 배울 수 있었고,  아직도 제가 배워야할 게 많다는 점이 또 다른 학습 동기로 다가온 것 같습니다. 이 일련의 과정이 저에겐 재미있었고, '이래서 내가 프로그래밍을 좋아했구나' 다시금 알 수 있게된 시간이었습니다. \n"},{"excerpt":"과제 요약 Pasted image 20241020194900.png 과제 진행 소감 구현 요구사항에 대한 난이도 자체는 너무 평이했다. 아무리 프리코스더라도 이래도 되나? 싶을정도로 쉬워서 지난 기수도 찾아보니까 확실히 작년에 비해 난이도가 쉬웠던 것 같다. 그 이유가 뭔지 생각해보니, 과제에서 제한을 둔 사항이 이번에 훨씬 적었다. 대신 그만큼 예외 상…","fields":{"slug":"/우아한테크코스_7기_BE_프리코스_1주차_회고/"},"frontmatter":{"date":"2024년 10월 20일 12:10","title":"우아한테크코스 7기 BE 프리코스 1주차 회고","tags":["프리코스","우아한테크코스"]},"rawMarkdownBody":"## 과제 요약\n![[Pasted image 20241020194900.png]]\n\n## 과제 진행 소감\n구현 요구사항에 대한 난이도 자체는 너무 평이했다. 아무리 프리코스더라도 이래도 되나? 싶을정도로 쉬워서 지난 기수도 찾아보니까 확실히 작년에 비해 난이도가 쉬웠던 것 같다. 그 이유가 뭔지 생각해보니, 과제에서 제한을 둔 사항이 이번에 훨씬 적었다. \n\n대신 그만큼 예외 상황이 많이 생긴 것 같다. 입력 요구사항이 명확하지 않은 만큼 쉬웠지만 반대로 생각하면 예외가 많이 생겨서 하면 할 수록 예외처리를 많이 했던 것 같다. \n\n지금 생각하면 현실에서 일어날 법한 상황과 더 유사하지 않나 생각이 들고, 그만큼 진짜로 운영하고자 하는 시스템 속에서는 다양한 예외에 대한 처리가 필요하지 않나 생각이 든다.\n\n### MVC 패턴\n이론으로만 알고 있던 MVC 패턴을 처음으로 적용해보려고 시도해봤다. \n1. Model은 Controller와 View에 의존하지 않아야 한다.\n2. View는 Model에만 의존해야 하고, Controller에는 의존하면 안된다.\n3. View가 Model로부터 데이터를 받을 때는 사용자마다 다르게 보여주어야하는 데이터에 대해서만 받아야한다.\n4. Controller는 Model과 View에 의존해도 된다.\n5. View가 모델로부터 데이터를 받을 때, 반드시 Controller에서 받아야한다.\n위 다섯 가지 규칙에 따라 구현을 했는데, 다른 사람들의 리뷰를 얼른 받아보고 싶다. 본 과제를 하는데 이 패턴이 과연 필요할까 생각도 들고 그럼 어떤 패턴으로 구현하는게 좋을까 이야기 해보고 싶다.\n\n### 예외처리\n아마 가장 많은 시간을 투자한 부분이지 않을까 생각이 든다. 처음에 기능 구현은 금방 끝났는데 여러 테스트 케이스를 작성할 때마다 새로운 예외를 발견해버렸다. \n\n사용자의 입장에서 오류가 왜 났는지 피드백을 주고자 오류의 종류마다 새로운 IllegalArgumentException을 던져줬는데 과연 이게 좋은 방향일지 의문이 든다. \n\n적은 메소드로 여러 예외를 처리하는 게 좋을지, 나눌 수 있는 만큼 케이스마다 새롭게 예외처리를 해주는 게 좋을지 다른 사람의 의견도 궁금하다. 실제 서비스는 어떻게 운영이 될까, 개발자들은 어떤 방향성을 가지고 예외처리를 하는게 좋을까, 단순화가 좋은지 구체화가 좋은지 가장 고민을 많이 했던 부분인데 이번 과제는 앞서 말한 것처럼 사용자가 잘못 입력을 했을 때 그에 맞는 피드백을 주고 싶어서 구체화를 목표로 진행했다.\n"},{"excerpt":"기존 HCSLAB 폐음 연구팀에서 사용하던 데이터의 질이 좋지 않아 다른 폐음 데이터셋을 찾던 와중 ICBHI Respiratory Sound Database (The Respiratory Sound database - ICBHI 2017 Challenge)을 발견했다. 폐음 연구 분야에서는 유명한 데이터셋이고 Kaggle에서도 여러 사람들이 활발히 분석…","fields":{"slug":"/Respiratory Sound Database 유효성 분석/"},"frontmatter":{"date":"2024년 10월 13일 12:10","title":"Respiratory Sound Database 유효성 분석","tags":["폐음연구","학부연구생"]},"rawMarkdownBody":"기존 [HCSLAB](https://sites.google.com/view/hcslab-cau/home?authuser=0) 폐음 연구팀에서 사용하던 데이터의 질이 좋지 않아 다른 폐음 데이터셋을 찾던 와중 [ICBHI Respiratory Sound Database (The Respiratory Sound database - ICBHI 2017 Challenge)](https://paperswithcode.com/dataset/icbhi-respiratory-sound-database)을 발견했다. 폐음 연구 분야에서는 유명한 데이터셋이고 [Kaggle](https://www.kaggle.com/datasets/swapnilpanda/respiratory-sound-location)에서도 여러 사람들이 활발히 분석을 해놓은 게 많아서 우리 연구에도 쓸 수 있을지 그 결과를 보고자 한다.\n\n**알고자 하는 건 2개다.**\n1. **Dataset에서 wheeze와 crackle을 분류할 수 있는지**\n2. **1번과의 연관성 유무에 상관없이, 질병과 폐음 사이에 연관성이 있는지**\n\n## Respiratory Sound Database \n본 데이터는 원본 dataset 중 일부이다. 아쉽지만 기존 데이터 중 어떤 근거로 이 부분만 골라왔는지에 대한 설명이 없다.\n\n### 요약\n#### Contents 개요\n- 126명 대상 (어린이, 성인, 노인 등 전연령대)\n- 920개 .wav sound files\n- 920개 annotation .txt files\n- 각 환자별 질병 설명 .txt files\n\n#### 수집 기기\n- AKG C417L Microphone (AKGC417L)\n- 3M Littmann Classic II SE Stethoscope (LittC2SE)\n- 3M Litmmann 3200 Electronic Stethoscope (Litt3200)\n- WelchAllyn Meditron Master Elite Electronic Stethoscope (Meditron)\n\n#### 질병 종류 및 숫자\n\n| Disease                  | Num of People |\n| :----------------------- | ------------: |\n| COPD (만성폐쇄성폐질환)          |            64 |\n| Healthy                  |            26 |\n| URTI (상기도감염)             |            14 |\n| Bronchiectasis (기관지 확장증) |             7 |\n| Bronchiolitis (모세기관지염)   |             6 |\n| Pneumonia (폐렴)           |             2 |\n| Asthma (천식)              |             1 |\n\n#### Chest Location\n![[chest location.png]]\n- a. Trachea (Tc)\n- b. Anterior left (Al)\n- c. Anterior right (Ar)\n- d. Posterior left (Pl)\n- e. Posterior right (Pr)\n- f. Lateral left (Ll)\n- g. Lateral right (Lr)\n\n## [CNN: Detection of wheezes and crackles](https://www.kaggle.com/code/eatmygoose/cnn-detection-of-wheezes-and-crackles)\n### Overview\nwheeze와 crackle을 식별하는 CNN 구현에 관한 코드. crackle 감지는 평이한데, wheeze와 wheeze & crackle이 같이 있는 소리의 경우 분류의 정확도가 비교적 낮음. 전반적인 검증 정확도는 약 70%.\n![[Accuracy and Loss about detection of wheezes and crackles.png]]\n![[Result of detection of wheezes and crackles.png]]\niteration을 돌려도 Loss가 불규칙하게 튀는 이유가 뭔지 모르겠다. 정확도도 그리 높은 편은 아니라서 추후 연구할 때 wheeze와 crackle을 학습하는 용도로는 부적하지 않을까 생각 중. 폐음이 측정 위치에 따라 소리의 질 차이가 큰데 본 코드에서는 위치에 상관없이 cnn 모델에 학습을 시켜서 이런 결과가 나오지 않았나 추측 중. d, e 구역에서 측정한 wav 파일이 뚜렷하게 잘 들리므로 이것들만 학습을 시켜서 다시 테스트 해볼 필요는 있어보임.\n## [CNN: Disease Classification, Linked Features (95%)](https://www.kaggle.com/code/markdenton/cnn-disease-classification-linked-features-95/notebook)\n### Overview\n음성 데이터를 기반으로 질병을 식별하는 CNN 구현에 관한 코드. 식별이 잘되는 편, 정확도는 95%, loss는 0.2.\n![[Accuracy and Loss about disease claaification.png]]\n![[Result of Disease classification.png]]\n질병 종류 중 가장 많이 있는 상위 6개의 class에 한해서 학습 및 테스트함. 오른쪽 자료를 보면, COPD를 제외한 다른 질병에 대한 학습 데이터 수가 너무나도 적어서 유의미한 데이터라고는 보기 힘들 것 같음. \n\n## 생각해볼 것들\nCOPD를 제외한 다른 질병에 대한 음성 파일이 너무 적은 것 같다. 본 데이터만으로 CNN 모델을 학습시키기에는 부적절하다고 생각이 들고, 원본 데이터셋에 질병별로 음성 파일이 골고루 있는지 확인해볼 필요가 있어보인다. 또 원본 데이터셋에 대한 [Benchmark](https://paperswithcode.com/dataset/icbhi-respiratory-sound-database)가 있는데 이것들에 대해 알아보는 것도 좋을 것 같다.\n\n"},{"excerpt":"학>SIGCHI 2024 1. Touching the Moon: Leveraging Passive Haptics, Embodiment and Presence for Operational Assessments in Virtual Reality Intro 요약 다시금 달에 가기 위해 인력, 통신, 하드웨어, 소프트웨어 및 데이터 등 새로운 솔루션들이 뒷받침되…","fields":{"slug":"/interesting topic among sigchi 2024/"},"frontmatter":{"date":"2024년 09월 07일 12:09","title":"sigchi 2024 관심 주제","tags":["학부연구생"]},"rawMarkdownBody":"학>[SIGCHI 2024](https://programs.sigchi.org/chi/2024)\n## [1. Touching the Moon: Leveraging Passive Haptics, Embodiment and Presence for Operational Assessments in Virtual Reality](https://programs.sigchi.org/chi/2024/program/content/147838)\n\n### Intro 요약\n다시금 달에 가기 위해 인력, 통신, 하드웨어, 소프트웨어 및 데이터 등 새로운 솔루션들이 뒷받침되고 있음. 달과 같은 더 밝은 빛, 더 어두운 그림자, 감소된 중력이 있는 상황 속에서 우주인이 부피가 크고 제한적인 우주복을 입고 장애물을 탐색해야함. 이러한 독특한 상황들을 시뮬레이션 하기 위해 VR이 활용되고 있음.\n\nVR은 달의 환경 조건을 시각화하고 예상되는 시나리오를 테스트하는데 이상적인 도구이지만 시청각적 특성만 제현가능하다는 점 때문에 달을 완벽히 구현하는데 한계가 있음. \n\n**본 연구에서는 장갑과 물리적 모형을 이용해 실제와 비슷한 촉각적, 운동 감각을 구현**하고 가상 신체에 대한 구체화 감각을 향상시키려는 노력을 함.\n\n## [2. Mindfulness-based Embodied Tangible Interactions for Stroke Rehabilitation at Home](https://programs.sigchi.org/chi/2024/program/content/146728)\n\n### Intro 요약\n전 세계적으로 뇌졸중 환자 수가 증가하며 재활 비용이 상승하고 있음. 경제적인 문제 이외에도 물리 치료사도 부족하기 때문에 가정에서 재활 활동을 하기 어려움. 최근에는 촉각으로 상호 작용할 수 있는 도구를 통해 재활을 하기 시작했는데, HCI 분야에서 웨어러블 기기 분야로 연구를 하고 있음.\n\nMindfulness-based interventions는 신체적, 심리적으로 뇌졸중 회복에 도움이 된다고 함. 본 연구에서는 **Mindfulness-based interventions와 촉각을 결합하여 가정에서 재활을 위해 구체화할 수 있는 기술 설계를 연구함.** 이 연구는 Mindfulness-based Embodied Tangible Interactions(MBETI)에 대한 디자인 원칙 개발에 기여함.\n\n## [3. “I know I have this till my Last Breath”: Unmasking the Gaps in Chronic Obstructive Pulmonary Disease (COPD) Care in India](https://programs.sigchi.org/chi/2024/program/content/147082)\n\n### Intro 요약\n비전염성 질환(NCD: Non-communicable disease)은 전 세계 사망자의 74%를 차지함. 이러한 비전염성 질환 중 만성 호흡기 질환(CRD: Chronic Respiratory Diseases)은 사망률에 크게 기여함. 최근 20년 사이에 사망률 28.5%, 유병률 39.8% 증가. 그 중 만성 폐쇄성 폐질환(COPD: Chronic Obstructive Pulmonary Disease)은 흔하지만 진단하기가 어려워 전 세계 사망 원인 중 3위를 차지함. 세계보건기구(WHO)는 심각성을 인지하고 NCD 예방  및 관리를 위한 세계 행동 계획과 지속 가능한 개발을 UN 2030 의제에 포함 시킴.\n\n**COPD와 같은 CRD로 인한 사망의 90%는 저소득 및 중소득 국가에서 발생**. 2016년, CRD는 인도의 총 사망 및 장애 조정 생명 연수(DALY)의 10.9%와 6.4%를 차지, 이 중 CRD로 인한 총 DALY의 75.6%가 COPD에 기인. **인도의 의료 인프라에 불균형이 있기 때문**. 대기 오염이 심화되면서 인도에 상당한 사회경제적 부담이 생김. 2016년 인도에서 COPD로 인한 총 DALY 중 53.7%가 대기 오염에 기인. 병원과 병상이 인도 인구에 비해 현저히 적음.\n\nHCI 연구원들은 최근 몇 년 동안 CRD에 점점 더 관심을 보이고 있으며 디지털 건강 모니터링 및 웨어러블 장치, 원격 진료 및 원격 의료 솔루션, 행동 개입 및 게임화, 자기 관리를 포함한 CRD 치료의 다양한 측면을 다루고 있음.\n\n## [4. Evaluating ActuAir: Building Occupants' Experiences of a Shape-Changing Air Quality Display](https://programs.sigchi.org/chi/2024/program/content/146904)\n\n### Intro 요약\n건물이 점점 더 센서가 많아지고 기후 변화 압박 속에서 인식 및 웰빙 목적으로 건물 내 환경 데이터를 사용하는 데 대한 관심이 커지고 있음. 그에 비해 대형 모양 변경 디스플레이를 중심으로 한 연구에서는 거주자의 공기 질 데이터 경험에 대한 연구는 별로 없음.\n\nActuAir 시스템은 생체 모방 개념에서 영감을 받은 모듈식 맞춤형 룸 디바이더로, 팽창과 LED 애니메이션으로 AQ(Air Quality)를 표시. 이와 같은 대규모 소프트 로봇 및 모양 변경 반응형 아키텍쳐는 미래 스마트 빌딩 설계 및 HCI/HBI 연구에 기여함."},{"excerpt":"contents: 0-1. CA Intro Integrating TLB, Cache, Memory Aliasing in virtually addressed cache The same virtual address of different processes can be mapped to different physical address Wrong cache hi…","fields":{"slug":"/5-4. Virtual memory Part 2/"},"frontmatter":{"date":"2024년 08월 24일 12:08","title":"Virtual memory Part 2","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Integrating TLB, Cache, Memory\n\n### Aliasing in virtually addressed cache\n\n- The same virtual address of different processes can be mapped to different physical address\n\t- Wrong cache hit can occur\n\n- Different virtual addresses of different process can be mapped to the same physical address <br>(when some memory space is shared by multiple processes)\n\t- The physical memory can be cached in two different locations\n\t- Coherency problem can happen <br>One program writes the data without the other program being aware that the data had changed\n\n<br>\n\n  \n\n#### Simple solution\n\n- Flush cache at context switching -> too high miss rate\n\t- Context switch: In multi-process environments, multiple processes share a single CPU\n\n<br>\n\n  \n\n## Hybrid cache: virtually-indexed  & physically-tagged cache\n\n- No aliasing problem\n\n- TLB & cache are accessed in a parallel manner (fast)\n![[01 13.jpg]]\n<br>\n\n- 32-bit virtual address\n\n- Page size = $2^p$ Bytes\n\n- Physical memory size =  $2^t$ Bytes (t-bit physical address)\n\n- Block size = $2^m$ words\n\n- Num of sets in a cache = $2^s$ sets\n![[02 13.jpg]]\n\n\n  \n\n### Typical multi-level cache setup with TLB\n\n- Typical L-1: hybrid cache (virtually-addressed, physically tagged)\n\t- To reduce hit time and miss rate\n\n- Typical L-2: physically-addressed cache\n\t- For simple implementation\n\t- In addition, usually L-2 si large<br>So, because p < s + m + 2, we cannot use hybrid cache"},{"excerpt":"contents: 0-1. CA Intro Main challenge in using main memory In multi-process environments, multiple processes share main memory at the same time. So depending on which processes run concurrently, the…","fields":{"slug":"/5-3. Virtual memory Part 1/"},"frontmatter":{"date":"2024년 08월 23일 12:08","title":"Virtual memory Part 1","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Main challenge in using main memory\n\nIn multi-process environments, multiple processes share main memory at the same time.\n\nSo depending on which processes run concurrently, the following thing are dynamically changed.\n\n- The total amount of memory that each process can use\n\n- The memory address of data used in processes\n\n- The physical location of data (main memory or disk)\n\n  \n\n## Virtual Memory (VM)\n\n**Provides each process an illusion of the exclusively-use of large memory** <br>\n\nProcesses think that they use their own memory that can store everything related to them\n\n- CPU and OS manage the mapping between the virtual memory, physical memory and disk\n![[01 12.jpg]]\n\n<br>\n\n  \n\n### Advantages\n\n- Processes do not need to think about the effect of other processes in using memory\n\n    - The memory space used by processes is fixed virtually\n\n    - Simple development of programs\n\n- Virtual addresses of different processes are mapped to different physical addresses\n\n    - Only OS can manage this mapping information\n\n    - One process cannot access another's data\n\n<br>\n\n  \n\n### Term\n\n- **Page**: the minimum unit of information in virtual memory containing multiple blocks\n\n- **Page fault**: when an requested page is not present in main memory\n\n- **Virtual address**: an address that corresponds to a data location in virtual memory\n\n- **Physical address**: an address that corresponds to a data location in physical memory\n\n- **Disk address**: an address that corresponds to a data location in disk\n\n<br>\n\n  \n\n### Address translation (address mapping)\n\nIn virtual memory, pages are mapped from virtual address to physical or disk addresses\n\n- At this time, **fully associative placement** is used\n![[02 12.jpg]]\n\n<br>\n\n  \n\n### VM address translation\n\n- 32-bit virtual memory address\n\n- Virtual memory size: $2^{32}$ Bytes = 4GB\n\n- Page size: 4KB = $2^{2+10}$ Bytes\n\n- Physical memory size: 1GB = $2^{30}$ Bytes\n\n- Num of physical pages = $2^{18}$\n\n  \n\n#### Total page table size\n\nNum of PTEs $\\times$ PTE size = num of virtual pages $\\times$ 4Bytes<br>\n\n= Virtual memory size / page size $\\times$ 4Bytes<br>\n\n= $2^{32} / 2^{12} \\times 2^2$ Bytes = $2^{32 - 12 + 2}$ Bytes = 4MB\n\n<br>\n\n  \n\n## TLB (translation Lookaside Buffer)\n\nSince the page tables are stored in main memory, every memory access by a program can take at least twice as long<br>: one memory access to obtain the physical address and a second access to get the data<br>\n\n<br>\n\n**TLB** is a cache that keeps tract of recently used address mappings to try to avoid an access to the page table.<br>\n\n: cache of page table\n![[03 10.jpg]]\n\n\n  \n\n### Typical TLB structure\n\n- TLB size: 16 ~ 512 page entries\n\n- Fully associative TLBs (used in systems that use small TLBs) <br>or Small associative TLBs (used in systems that use large TLBs)\n\n- Replacement policy: random (for fast handling)\n\n- Hit time: 0.5 ~ 1 clock cycle\n\n- Miss penalty: 10 ~ 100 clock cycles\n\n- Miss rate: 0.01% ~ 1%\n\n<br>\n\n  \n\n### Integrating TLB, Cache, memory\n\n- Fully-associative TLB\n\n- Physical memory size = 4GB (=$2^{32}$)\n\n- Page size = 4KB = (=$2^{12}$)\n\n- Direct mapped cache\n\n- Num of cache blocks = $2^8$\n\n- Cache block size = $2^4$ word\n![[04 7.jpg]]\n\n  \n\n### Workflow\n\n- Access TLB first\n\n- Access cache using physical addresses: \"physically addressed cache\"\n\n<br>\n\n  \n\n### Physically addressed cache\n\n- Physically indexed & physically tagged <br>Both the cache index and tag are physical addresses\n![[05 6.jpg]]\n\n<br>\n\n  \n\n- 32-bit virtual address\n\n- Page size = $2^p$ Bytes\n\n- Physical memory size =  $2^t$ Bytes (t-bit physical address)\n\n- Block size = $2^m$ words\n\n- Num of sets in a cache = $2^s$ sets\n![[06 4.jpg]]\n\n<br>\n\n  \n\n### Scenario\n\n1. TLB -> hit, Cache -> hit, VM -> hit\n\n    - Best case\n\n    - TLB가 hit이므로 Page table 볼 필요가 없음\n\n    - 즉 main memory 접근 필요 없음\n\n    - 또 Cache가 hit이므로 TLB에 의해 가상주소 -> 실제주소, 이 실제주소로 Cache 접근\n\n2. TLB -> miss, Cache -> hit, VM -> hit\n\n    - TLB가 miss이므로 Page table에 접근해서 가상주소 -> 실제주소 변환 필요 (메모리 접근 1회 필요)\n\n    - Cache는 hit이므로 더 이상 메모리 접근 없음\n\n3. TLB -> miss, Cache -> miss, VM -> miss\n\n    - Worst case\n\n    - 최악의 경우로 memory에서 miss 발생 -> page fault\n\n    - 즉 valid bit가 0이므로 OS가 제어를 넘겨받음\n\n4. VM -> miss면, Cache와 TLB가 무조건 miss\n\n    - 계층구조를 이루고 있기 때문에 hit가 생길 수 없음\n\n<br>\n\n  \n\n### Virtually addressed cache\n\n- Virtually indexed & virtually tagged <br>Both the cache index and tag are virtually address\n![[07 3.jpg]]\n\n<br>\n\n  \n\n- 32-bit virtual address\n\n- Page size = $2^p$ Bytes\n\n- Physical memory size =  $2^t$ Bytes (t-bit physical address)\n\n- Block size = $2^m$ words\n\n- Num of sets in a cache = $2^s$ sets\n![[08 2.jpg]]\n\n  \n\n### Physically-addressed cache VS virtually-addressed cache\n![[09 3.jpg]]\n\n<br>"},{"excerpt":"contents: 0-1. CA Intro Associative caches Support more flexible placement of blocks\n01 11.jpg Fully associative cache A cache structure in which a block can be placed in any location in the cache Re…","fields":{"slug":"/5-2. Improving cache performance/"},"frontmatter":{"date":"2024년 08월 22일 12:08","title":"Improving cache performance","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Associative caches\n\nSupport more flexible placement of blocks\n![[01 11.jpg]]\n\n  \n\n<br>\n\n  \n\n### Fully associative cache\n\n- A cache structure in which a block can be placed in any location in the cache\n\n- Requires all entries to be searched\n\n<br>\n\n  \n\n### N-way set associative cache\n\n- A cache that has N locations where each block can be placed\n\n- Requires N entries to be searched\n\n- The set containing a memory block <br> (Block address) modulo (num of sets in the cache)\n\n- Direct-mapped cache = 1-way set associative cache\n\n- Full-associative cache = M-way set associative cache <br>(where M is num of cache blocks in the cache)\n\n<br>\n\n  \n\n### Associative cache address\n\n- 32-addresses\n\n- num of cache blocks: $2^n$ blocks\n\n- num of sets in the cache: $2^s$ sets (each set contains $2^{n-s}$ blocks: $2^{n-s}$-way set associative cache)\n\n- Block size: $2^m$ words ($2^{m+2}$ bytes)\n\n<br>![[02 11.jpg]]\n\n\n  \n  \n\n### Implementation of 4-way set associative cache\n![[03 9.jpg]]\n\n  \n\n### How much associativity\n\nIncreasing associativity makes **flexibility & complexity increase**. <br>\n\nWe have to find moderate amount of set size.\n\n<br>\n\n  \n\n### Block replacement policy\n\nIn set associative cache, if we have to make room for another block, one of blocks in a cache set must be removed\n\n- Find non-valid entries and replace one of them\n\n- If there are no non-valid entries, then choose one of valid entries in the set based on\n\n    - Least-recently used (LRU)\n\n    - Random\n\n<br>\n\n  \n\n## Multi-level caches\n\nUse primary (level-1, L-1) and secondary (level-2, L-2) caches\n\n- L-1 cache: placed close to (attached to) CPU\n\n    - Small, but very fast\n\n- L-2 cache: placed a little bit far from CPU\n\n    - Accessed on L-1 cache misses\n\n    - Larger and slower than L-1 cache, but still faster than main memory\n\n    - Main memory is accessed on L-2 cache misses\n\n<br>\n\n  \n\n### Practice 1\n\n- CPU base CPI = 1\n\n- L-1 miss rate = 2%\n\n- Main memory access time = 100ns\n\n- Clock period = 0.25ns\n\n  \n\n**CPI of a single-level cache system = CPU base CPI + memory stall CPI** <br>\n\n= CPU base CPI + L-1 miss rate * main memory access clock cycles <br>\n\n= CPU base CPI + L-1 miss rate * main memory access time / clock period <br>\n\n= $1 + 0.02 * (100 * 10^{-9}) / (0.25 * 10^{-9})$ <br>\n\n= $1 + 8 = 9$\n\n<br><br>\n\n  \n\n### Practice 2\n\n- CPU base CPI = 1\n\n- L-1 miss rate = 2%\n\n- **Global miss rate = 0.5% (Both L-1 & L-2 are missed)**\n\n- L-2 access time = 5ns\n\n- Main memory access time = 100ns\n\n- Clock period = 0.25ns\n\n  \n\n**CPI of a 2-level cache system = CPU base CPI + memory stall CPI** <br>\n\n= CPU base CPI + L-1 miss rate * L-1 miss penalty + global miss rate * L-2 miss penalty <br>\n\n= CPU base CPI + L-1 miss rate * L-2 access time / clock period + global miss rate * main memory access time / clock period <br>\n\n= $1 + 0.02 * (5 * 10^{-9}) / (0.25 * 10^{-9}) + 0.005 * (100 * 10^{-9}) / (0.25 * 10^{-9})$ <br>\n\n= $1 + 0.4 + 2 = 3.4$\n\n<br><br>\n\n  \n\n### Considerations\n\n#### Designing L-1 cache\n\n- Focus on minimizing hit time -> to yield a short clock period <br>(the MEM stage time & IF stage time are determined based on the L-1 cache hit time)\n\n  \n\n#### Designing L-2 cache\n\n- Focus on minimizing miss rate -> to avoid main memory\n\n  \n\n#### Therefore, in multilevel caches,\n\n- L-1 cache and its blocks size is smaller than a single-level cache\n\n    - to reduce hit time and miss penalty\n\n- L-2 cache is larger than a single-level cache\n\n    - to reduce miss rate"},{"excerpt":"contents: 0-1. CA Intro Memory hierarchy Locality Temporal locality     - Items accessed recently are likely to be accessed again soon Spatial locality     - Items near those accessed recently are li…","fields":{"slug":"/5-1. Cache overview/"},"frontmatter":{"date":"2024년 08월 21일 12:08","title":"Cache overview","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Memory hierarchy\n\n### Locality\n\n- **Temporal locality**\n\n    - Items accessed recently are likely to be accessed again soon\n\n- **Spatial locality**\n\n    - Items near those accessed recently are likely to be accessed soon\n\n<br>\n\n  \n\n## Memory structure\n\n- **SRAM** (cache memory attached to CPU)\n\n    - Fastest (o.5ns ~ 2.5ns)\n\n    - most expensive\n\n    - smallest\n\n- **DRAM** (main memory)\n\n    - Faster (50ns ~ 70ns)\n\n    - more expensive\n\n    - smaller\n\n- **Disk** (HDD, SSD)\n\n    - Slowest (5ms ~ 20ms)\n\n    - cheapest\n\n    - largest\n\n<br>\n\n  \n\n### Use hierarchy\n\n- Copy recently accessed (and nearby) items from disk to smaller DRAM memory\n\n- Copy more recently accessed (and nearby) items from DRAM to smaller SRAM memory\n\n<br>\n\n  \n\n### Term\n\n- **Block**\n\n    - The minimum unit of information\n\n    - It can be either present or not present in a cache\n\n- **Hit**\n\n    - Accessed data is present\n\n    - Hit ratio: # of hits / # of accesses\n\n- **Miss**\n\n    - Accessed data is absent\n\n    - Block is copied from lower level (Additional time taken)\n\n    - Miss ratio: # of misses / # of access (= 1 - hit ratio)\n\n<br>\n\n  \n\n## Direct mapped cache\n\nEach memory location can be mapped directly to exactly one location in the cache\n![[01 10.jpg]]\n  \n\n\n\n  \n\n- Cache address = (Block address) modulo (# of blocks in cache)\n\n- Num of blocks in cache is power of 2 (e.g., 2, 4, 8, 16, 32, ...)\n\n- The cache address is determined by the low-order bits of block address\n\n- Tags contain the address information of the data (the high-order bits of the address)\n\n- To avoid using meaningless information, add a valid bit for each cache block\n\n    - Valid bit = 1 (the cache block contains valid information)\n\n    - Valid bit = 0 (the cache block contains invalid information)\n\n    - Initially, the valid bits of all cache blocks are set to 0\n\n<br>\n\n  \n\n### Cache address\n\n- 32-bit addresses\n\n- num of cache blocks: $2^n$ blocks (the lowest n bits of the block address are used for the index)\n\n- Block size: $2^m$ words ($2^{m+2}$ bytes)\n\n    - m bits are used for the word within the block, 2 bits are used for the byte within the word\n\n![[02 10.jpg]]\n\n  \n\n### Cache size\n![[03 8.jpg]]\n\n\n**Cache size** <br>\n\n= Cache table size <br>\n\n= Num of cache block $\\times$ (valid bit length + tag length + block size(data length))\n\n  \n\n### Practice 1\n\n- 32-bit addresses\n\n- Num of cache blocks: $2^{10}$ blocks\n\n- Block size: $2^0$ words ($2^2$ bytes)\n\n  \n\n**Cache size**<br>\n\n= $2^{10} \\times (1 + (32 - (10 + 0 + 2)) + 32)$ <br>\n\n= $2^{10} \\times 53$ bits\n\n<br><br>\n\n  \n\n### Practice 2\n\n- 32-bit addresses\n\n- Num of cache blocks: 64 blocks\n\n- Block size: 4 words\n\n  \n\n**Cache size**<br>\n\n= $2^{6} \\times (1 + (32 - (6 + 2 + 2)) + 128)$ <br>\n\n= $2^{6} \\times 151$ bits\n\n<br>\n\n  \n\n## More about\n\n- If we increase the size of blocks, this may help reduce miss rate due to spatial locality\n\n- But, Larger blocks -> a smaller number of cache blocks -> more competition -> increased miss rate\n\n- Increased miss penalty (the time for copying from lower level)\n\n<br>\n\n  \n\n## Handling cache misses\n\nOn cache hit, CPU proceeds normally. (requiring 1 clock cycle<br>\n\nBut, on cache miss, the control unit of the CPU\n\n- **Step 1: stalls the CPU pipeline**\n\n- **Step 2: copies a block from the next level of hierarchy (e.g., memory)**\n\n- **Step 3: does the stalled task**\n\n    - Restarts instruction fetch (IF stage) <br> if the cache miss happened when fetching an instruction from the instruction memory\n\n    - Completes data access (MEM stage) <br> if the cache miss happened when loading data from the data memory\n\n<br>\n\n  \n\n### Handling writes\n\nWhen will the newly-updated data in the cache be written to the lower-level memory (e.g., main memory)\n\n- **Write-through**: Update both cache and lower-level memory at the same time\n\n- **Write-back**: Just update cache\n\n    - Keep track of which block is dirty (used)\n\n    - When a dirty block is replaced, write it back to the lower-level memory\n\n|               | Pros                                                                        | Cons                                                                               |\n| ------------- | --------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |\n| Write-through | - Consistency between cache and memory is guaranteed<br>- Easy to implement | - Slow write speed                                                                 |\n| Write-back    | - Fast write speed<br>(if there is no replacement)                          | - Consistency between cache and memory is not guaranteed<br>- Complex to implement |\n\n<br>\n\n  \n\n#### Write-through with write buffer\n\nTo reduce the delay of write operations on the write-through method, <br>we can use a write-buffer (much faster to access than memory)\n\n- A write buffer folds data waiting to be written to lower-level memory\n\n    - **Step 1: Update both cache and write buffer**\n\n    - **Step 2: The processor continues the program execution without waiting**\n\n        - The memory takes the updated data from the write buffer\n\n- If the buffer is full, the processor must stall until there is an empty position <br>\n\nThe write buffer can be also used to improve the performance of write-back\n\n- If all the blocks in cache are dirty\n\n<Br>\n\n  \n  \n\n### Handling write misses\n\nIf there is no requested block in the cache, it causes write misses\n\n- **Write-allocate**\n\n    - First, fetch the block to cache\n\n    - And then, handle the write operation\n\n- **Write around**\n\n    - Just update the portion of the block in lower-level memory, but not put it in cache\n\n    - It is good when we need to initialize memory space\n\n<br>\n\n  \n  \n\n## Real-world example\n\nEmbedded MIPS processor with 12-stage pipeline\n\n- Split cache: **I-cache** (for instructions) and **D-cache** (for data)\n\n- Each 16KB: 256 blocks $\\times$ 16 words per block\n\n![[04 6.jpg]]\n\n<br>\n\n  \n\n## Cache performance\n\nCPU time = clock cycle $\\times$ clock period <br>\n\n= (CPU execution clock cycles + memory-stall clock cycles) $\\times$ clock period\n\n- **CPU execution clock cycles**\n\n    - The clock cycles that CPU spends executing the program\n\n    - Cache hit time is included\n\n- **Memory-stall clock cycles**\n\n    - The clock cycles that CPU spends waiting for the memory access\n\n    - Mainly from cache misses\n\n<br>\n\n  \n\n### Memory-stall clock cycles\n\nSimplifying assumption: the read and write miss penalties are the same <br>\n\n  \n  \n\n**Num of memory accesses $\\times$ Miss rate $\\times$ Miss penalty** <br>\n\n= Num of misses $\\times$ Miss penalty<br>\n\n  \n\n**In MIPS, we have two different cache (instruction (I-cache) and data (D-cache))**<br>\n\nNum of memory accesses $\\times$ Miss rate $\\times$ Miss penalty<br>\n\n= Num of **instruction memory** access $\\times$ **I-cache** miss rate $\\times$ **I-cache** miss penalty<br>\n\n$+$ Num of **data memory** access $\\times$ **D-cache** miss rate $\\times$ **D-cache** miss penalty\n\n<br>\n\n  \n\n### Practice 1\n\n- Base CPI (on cache hit) = 2\n\n- Instruction-cache miss rate = 2%\n\n- Data-cache miss rate = 4%\n\n- Miss penalty = 100 cycles\n\n- Load & stores are 36% of instructions\n\n<br>\n\n  \n\n**Miss-stall clock cycles (when there are I instructions)**\n\n- For instructions: I $\\times$ 0.02 $\\times$ 100 = 2 $\\times$ I\n\n- For data: I $\\times$ 0.36 $\\times$ 0.04 $\\times$ 100 = 1.44 $\\times$ I\n\n<br>\n\n  \n\n**CPU time**\n\n- Actual CPU time: (2 $\\times$ I + 2 $\\times$ I + 1.44 $\\times$ I) $\\times$ clock period = 5.44 $\\times$ I $\\times$ clock period\n\n- Ideal CPU time: (no cache misses = perfect cache): 2 $\\times$ I $\\times$ clock period\n\n<br>\n\n  \n  \n\n$$\n\n\\frac{Ideal\\;performance}{Actual\\;performance} = \\frac{Actual\\;CPU\\;time}{Ideal\\;CPU\\;time} = \\frac{I \\times actual\\;CPI \\times clock\\;period}{I \\times ideal\\;CPI \\times clock\\;period} \\\\ = \\frac{Actual\\;CPI}{Ideal\\;CPI} = \\frac{5.44}{2}\n\n$$\n\n<center>\n\n<strong>\n\n    \"The performance with the perfect cache is better by 2.72\"\n\n</strong>\n\n</center>\n\n<br>\n\n  \n\n### Practice 2\n\nSuppose the processor is made faster, but the memory system is not\n\n- Base CPI (on cache hit) = **2 -> 1**\n\n- Instruction-cache miss rate = 2%\n\n- Data-cache miss rate = 4%\n\n- Miss penalty = 100 cycles\n\n- Load & stores are 36% of instructions\n\n\n|             | Memory-stall clock cycle    | Memory-stall CPI |\n| ----------- | --------------------------- | ---------------- |\n| For I-cache | 2 $\\times$ I                | 2                |\n| For D-cache | 1.44 $\\times$ I             | 1.44             |\n|             | CPU time                    | CPI              |\n| Actual      | 4.44 $\\times$ I $\\times$ CP | 4.44             |\n| Ideal       | 1 $\\times$ I $\\times$ CP    | 1                |\n\n  \n\n<center>\n\n<strong>\n\n    \"The performance with the perfect cache is better by 4.44\"\n\n</strong>\n\n</center>\n\n  \n\n<center>\n\n<strong>\n\n    But the gap between actual and ideal case is same as 3.44\n\n</strong>\n\n</center>"},{"excerpt":"contents: 0-1. CA Intro Code scheduling There are three types of critical dependencies Read after write Write after read Write after write If two instructions have one of the above dependencies, the …","fields":{"slug":"/4-6. Exceptions/"},"frontmatter":{"date":"2024년 08월 20일 12:08","title":"Exceptions","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Code scheduling\n\nThere are three types of critical dependencies\n\n- Read after write\n\n- Write after read\n\n- Write after write\n\nIf two instructions have one of the above dependencies,<br>\n\n**the execution order these two instructions must be maintained**\n\n  \n\n## Exceptions\n\n### Exceptions VS Interrupts in MIPS\n\n- Exception: arises within the CPU (internally)\n\n- Interrupt: from an external I/O controller (externally)\n\n| Type of event                  | From where | MIPS terminology       |\n| ------------------------------ | ---------- | ---------------------- |\n| I/O device reques              | External   | Interrupt              |\n| Invoke OS from a user program  | Internal   | Exception              |\n| Arithmetic overflow            | Exception  | Exception              |\n| Using an undefined instruction | Internal   | Exception              |\n| HW malfunctions                | Either     | Exception or interrupt |\n\n\n<br>\n\n  \n\n### How to handle\n\n- Step 1: Save the address of the offending instruction in the EPC (Exception Program Counter)\n\n    - EPC is a 32-bit register\n\n- Step 2: Save the reason for the exception in the Cause register\n\n    - Cause is a 32-bit register (some bits are unused)\n\n- Step 3: Jump to the exception handler corresponds to the cause\n\n    - The handler address for undefined opcode: $8000\\;0000_{hex}$\n\n    - Overflow: $8000\\;0180_{hex}$\n\n    - But sometimes without saving the reason for the exception, it jumps to the exception handler\n\n- Step 4: Do actions\n\n    - Read the cause and determine the action required\n\n    - If recoverable, take a corrective action and use EPC to return to a program\n\n    - Otherwise, terminate the program and report error using EPC, cause, ...\n![[01 9.jpg]]\n\n<br>\n\n  \n\n### Exceptions according to the stage\n\nExceptions can occur in any stage (except WB)\n\n- IF: Invalid memory access (memory fault)\n\n    - e.g., when PC holds an invalid memory address value\n\n- ID: Undefined instruction\n\n    - e.g., `abc $t0, $t1, $t2`\n\n- EX: Overflow\n\n    - e.g., when we use add, addi, and sub instructions\n\n- MEM: Invalid memory access (memory fault)\n\n    - e.g., when a computed target memory address is abnormal\n\nRegardless of the stage, the cause of exceptions is stored in the Cause register<br>\n\nThen, guess which instruction caused the exception based on the cause\n\n<br>\n\n  \n\n### Multiple exceptions\n\nMultiple instructions are executed in different stages at the same time, which means multiple exceptions can occur in the same clock cycle.\n\n#### How to prioritize multiple exceptions?\n\n- In MIPS, earliest instruction first\n\n- Flush subsequent instructions"},{"excerpt":"contents: 0-1. CA Intro Pipelined datapath We need registers between stages to hold information produced in previous stage and make isolation\n01 8.jpg Data hazards When an instruction depends on the …","fields":{"slug":"/4-5. Handling hazards/"},"frontmatter":{"date":"2024년 08월 19일 12:08","title":"Handling hazards","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Pipelined datapath\n\nWe need registers between stages **to hold information produced in previous stage and make isolation**\n![[01 8.jpg]]\n\n  \n\n## Data hazards\n\nWhen an instruction depends on the completion of data access by a previous instruction, it causes data hazards.\n![[07 2.jpg]]\n\n  \n\n### How to detect & when to forward\n\n- **Step 1: Pass register numbers along pipeline**\n\n    - if I-format or branch instruction, Rd is invalid value\n\n- **Step 2: Check the following data hazard conditions**\n\n    - `EX/MEM.RegisterRd == ID/EX.RegisterRs`\n\n    - `EX/MEM.RegisterRd == ID/EX.RegisterRt`\n\n    - `MEM/WB.RegisterRd == ID/EX.RegisterRs`\n\n    - `MEM/WB.RegisterRd == ID/EX.RegisterRt`\n\n- **Step 3: If there is a data hazard, then do forwarding**\n\n    - But only if the forwarding instruction writes to a register\n\n        - Check the RegWrite signal in `EX/MEM.RegWrite` and `MEM/WB.RegWrite` is `1`\n\n    - And only if Rd for the forwarding instruction is not `$zero`\n\n        - `$zero` cannot be overwritten\n\n        - `EX/MEM.RegisterRd != 0`\n\n        - `MEM/WB.RegisterRd != 0`\n\n<br>\n\n  \n\n### How to process\n![[02 9.jpg]]\n\n  \n\n- **EX hazards**\n\n    - If (`EX/MEM.RegWrite == 1 && EX/MEM.RegisterRd != 0 && EX/MEM.RegisterRd == ID/EX.RegisterRs`) <Br>**ForwardA = 10**\n\n    - If (`EX/MEM.RegWrite == 1 && EX/MEM.RegisterRd != 0 && EX/MEM.RegisterRd == ID/EX.RegisterRt`) <Br>**ForwardB = 10**\n\n- **MEM hazard**\n\n    - If (`EX/MEM.RegWrite == 1 && EX/MEM.RegisterRd != 0 && MEM/WB.RegisterRd == ID/EX.RegisterRs`) <Br>**ForwardA = 01**\n\n    - If (`EX/MEM.RegWrite == 1 && EX/MEM.RegisterRd != 0 && MEM/WB.RegisterRd == ID/EX.RegisterRt`) <Br>**ForwardB = 01**\n\n- **Both EX & MEM hazards**\n\n    - Use the most recent result **(the result in EX/MEM)**\n\n<br>\n\n  \n\n### Practice\n![[03 7.jpg]]\n![[04 5.jpg]]\n\n<br>\n\n  \n\n## Load-use data hazards\n\nBut, sometimes, we cannot avoid stalls by forwarding<br>\n\nWe need to stall for one cycle when we have to forward the data from MEM/WB registers to ALU stage\n![[08 1.jpg]]\n\n  \n\n### How to detect & when to forward\n\n- **Step 1: Check the following condition**\n\n    - `ID/EX.MemRead == 1 &&` <br>`(ID/EX.RegisterRt == IF/ID.RegisterRs || ID/EX.RegisterRt == IF/ID.RegisterRt)`\n\n- **Step 2: If detect, stall**\n\n    - Prevent PC and IF/ID from changing<br>the same instruction is executed in IF & ID stages\n\n    - Insert `nop` in the EX stage by setting the control signals in ID/EX register to 0\n\n    - `PCWrite = 0`, `IF/IDWrite = 0` (if no load-use data hazards, they are 1)\n\n  \n\n### Practice\n![[05 5.jpg]]\n![[06 3.jpg]]\n\n  \n\n### Code scheduling\n\nReorder code to avoid the load-use data hazards (done by compiler)\n\n#### Algorithm\n\n- Check the existence of load hazards\n\n    - A load hazard occurs when the destination register of a load instruction is used as a source register of its next instruction\n\n- If exists, check whether there is a code that can ve executed after the load instruction\n\n    - This reordering must not change the result of the program, while solving hazard\n\n    - We must consider the instruction dependencies\n\n<br>\n\n  \n\n## Control hazards\n\nIf branch outcome is determined in a MEM stage, there will be three pipeline bubbles\n![[09 2.jpg]]\n\n  \n\n### How to process\n\n- **Simple solution: static branch prediction**\n\n    - Predict that the branch will not be taken (just the next instruction will be executed)\n\n    - If the prediction is correct, there will be no pipeline stall\n\n    - If the prediction is incorrect, flush 3 instructions and insert 3 pipeline bubbles\n\n- **Improving by early comparison in ID stage**\n\n    - Use same prediction\n\n    - If the prediction is correct, there will be no pipeline stall\n\n    - If the prediction is incorrect, flush 1 instruction and insert 1 pipeline bubble\n\n- **Dynamic branch prediction**\n\n    - History-based prediction with BPT(branch prediction table), store a recent branch decision (taken / not taken)\n\n    - Indexed by branch instruction addresses\n\n<br>\n\n  \n\n### Dynamic branch prediction\n\nMake a better branch prediction in a way to reduce the number of misprediction\n\n- Step 1: access a branch prediction table by using the instruction address\n\n- Step 2: Check the prediction value in the table and fetch the next (not taken) or target branch instruction (taken)\n\n- Step 3: If the prediction is wrong, flush pipeline and flip prediction\n\n  \n\n#### 2-bit predictor\n\nOnly change prediction on two successive mispredictions\n![[10.jpg]]\n\n  \n\n#### Branch target buffer\n\nStill, we should experience 1 pipeline stall to compute the target address for a taken branch\n\n- Cache of target address\n\n- Indexed by the address of branch instructions\n\n- When a branch instruction is fetched and its prediction is \"taken\", <br>then check the branch target buffer\n\n    - If there is a target address, fetch the target immediately"},{"excerpt":"contents: 0-1. CA Intro Because the longest delay determines clock period, a single-cycle implementation is not used today  It violates \"make the common case fast\" Pipelining overview With the pipeli…","fields":{"slug":"/4-4. Pipelining overview/"},"frontmatter":{"date":"2024년 08월 18일 12:08","title":"Pipelining overview","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\nBecause the longest delay determines clock period, a single-cycle implementation is not used today <br>\n\nIt violates **\"make the common case fast\"**\n\n  \n\n## Pipelining overview\n\nWith the pipelined approach, the speed up can be equal to the number of stages in an ideal case\n\n- A single task is divided into N stages\n\n- Each stage takes teh same amount of time T\n\n- There are M tasks, where M is large enough\n\n  \n\nTo complete all the tasks\n\n- In non-pipelined approach, we need $N \\times M \\times T$ times\n\n- In pipelined approach, we need $(N + M - 1) \\times T \\approx M \\times T$ time\n\n  \n\n$$\n\nTime\\;between\\;tasks_{pipelined} = \\frac{Time\\;between\\;tasks_{non-pipelined}}{Number\\;of\\;pipeline\\;stages}\n\n$$\n\n<br>\n\n  \n\n### Stage in pipeline\n\nFor different stages, different resources are used.\n\n- Stage 1: IF (Fetching an instruction from memory)\n\n- Stage 2: ID (Decoding the instruction and read registers)\n\n- Stage 3: EX (Executing operation or calculating address)\n\n- Stage 4: MEM (Accessing data in data memory)\n\n- Stage 5: wB (Writing the result back into a register)\n\n<br>\n\n  \n\n### Compared to the single-cycle processor\n\nCompared to the single cycle processor, **clock period in pipelined processor is determined by the longest stage time.**\n![[01 7.jpg]]\n\n\n  \n\n<br>\n\n  \n\n$$\n\nTime\\;between\\;instructions_{pipelined}= the\\;longest\\;stage\\;time \\times (the\\;number\\;of\\;instructions + the\\;number\\;of\\;stages - 1)\n\n$$\n\n  \n\n**If there are a lot of instructions to be executed,**\n\n$$\n\nTime\\;between\\;instructions_{pipelined} = \\frac{Time\\;between\\;instructions_{non-pipelined}}{\\frac{the\\;longest\\;instruction\\;time}{the\\;longest\\;stage\\;time}}\n\n$$\n\n<br>\n\n  \n\n## Hazards in Pipelining\n\n- Structural hazards\n\n    - When a required resources is busy\n\n- Data hazards\n\n    - When we need to wait for previous instruction to complete its data read/write operation\n\n- Control hazards\n\n    - When we need to make a control decision differently depending on the previous instruction\n\n<br>\n\n  \n\n### Structural hazards\n\nWhen a required resource is already used for executing an other instruction\n\n- IF and MEM stages can request to use the same resource at the same time\n\n- it is required to separate instruction / data memories\n\n    - IF and MEM stages use different part of memory (instruction memory, data memory)\n![[02 8.jpg]]\n\n<br>\n\n  \n\n### Data hazards\n\nWhen an instruction depends on the completion of data access by a previous instruction\n![[03 6.jpg]]\n\n  \n\nSolution: **Forwarding** <br>\n\nInstead of waiting for the target date to be stored in a register,<br>\n\nforward the data as soon as possible with extra connections\n![[04 4.jpg]]\n\n\n  \n\n#### Load-use data hazards\n\nBut, sometimes, we cannot avoid stalls by forwarding\n![[05 4.jpg]]\n\n\n  \n\nSolution: **code scheduling**<br>\n\nReorder code to avoid the load-use data hazards (done by compiler)\n![[06 2.jpg]]\nbefore\n<br>![[07 1.jpg]]\nafter\n\n\n  \n\n<br>\n\n  \n\n### Control hazards\n\nHazards with branch instructions <br>\n\nWe should wait until branch outcome is determined before fetching the next instruction\n![[08.jpg]]\n\n  \n\nSolution: **Compare registers and compute target early in the pipeline**\n\n- Especially, by adding hardware to do it in **ID stage**\n\n- But, still there is **one** pipeline bubble\n\n![[09.jpg]]\n  \n\nSolution: **branch prediction**\n\nWith additional HW for early comparison and computation in ID stage\n\n- just fetch instruction with no bubble\n\n    - if prediction correct: keep going\n\n    - if prediction incorrect: cancel the process & add bubble\n\n<br>\n\n  \n\n## Summary\n\n**Pipelining improves performance by increasing instruction throughput**\n\n- Executes multiple instructions in parallel\n\n- The execution time of each instruction is not affected\n\n  \n\n**Pipeline hazards**\n\n- Structural hazards\n\n    - Solution: separate data / instruction memories\n\n- (Load-use) Data hazards\n\n    - Solution: forwarding + code scheduling\n\n- Control hazards\n\n    - Solution: early comparison & computation + branch prediction"},{"excerpt":"contents: 0-1. CA Intro Single-cyle datapath 01 6.jpg\n 02 6.jpg A single-cycle datapath executes instructions in one clock cycle with a clocking methodology.  We will study how this works according t…","fields":{"slug":"/4-3. A single-cycle datapath/"},"frontmatter":{"date":"2024년 08월 17일 12:08","title":"A single-cycle datapath","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Single-cyle datapath\n![[01 6.jpg]]\n</br>\n\n![[02 6.jpg]]\n\n</br>\n\nA single-cycle datapath executes instructions in one clock cycle with a clocking methodology. </br>\n\nWe will study how this works according to instructions\n\n  \n\n### R-format\n\n![[02 7.jpg]]\n\n- don't need to access memory\n\n    - `MemRead` = 0\n\n    - `MemtoReg` = 0\n\n    - `MemWrite` = 0\n\n- have to update value of `rd` register\n\n    - `RegDst` = 1\n\n    - `RegWrite` = 1\n\n- PC just have to be updated +4\n\n    - `branch` = 0\n\n- ALU control determines the arithmetic type according to `ALUOp` and `func code` of instruction\n\n</br>\n\n  \n\n### Load\n\n![[03 5.jpg]]\n  \n\n- need to access memory and read data\n\n    - `MemRead` = 1\n\n    - `MemtoReg` = 1\n\n    - `MemWrite` = 0\n\n- have to get value from memory to `rs` field (destination)\n\n    - `RegDst` = 0 (`rs` to destination)\n\n    - `RegWrite` = 1\n\n- PC just have to be updated +4\n\n    - `branch` = 0\n\n- ALU control determines the arithmetic type according to `ALUOp`\n\n- offset is extended from 16-bit to 32-bit by Sign-extend unit and added with Read data 1 (base addr)\n\n</br>\n\n  \n\n### Branch-on-equal\n\n![[04 3.jpg]]\n\n  \n\n- don't need to access memory\n\n    - `MemRead` = 0\n\n    - `MemtoReg` = 0\n\n    - `MemWrite` = 0\n\n- Calculate target address\n\n    - extend the offset to 32 bit and shift left twice (multiply 4)\n\n    - add with `PC + 4`\n\n- `RegDst` doesn't matter\n\n</br>\n\n  \n\n### More about: jump\n![[05 3.jpg]]\n\n  \n\n- Calculate target address\n\n    - offset is extended to 28-bit\n\n    - concatenate with `0000`\n\n- `Jump signal = 1`"},{"excerpt":"contents: 0-1. CA Intro Controlling a datapath main control Control signals are derived from given instructions\n01 5.jpg  is always being read  is being read except when the instruction is .     - It…","fields":{"slug":"/4-2. Controlling a datapath/"},"frontmatter":{"date":"2024년 08월 16일 12:08","title":"Controlling a datapath","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Controlling a datapath\n\n### main control\n\nControl signals are derived from given instructions\n![[01 5.jpg]]\n\n\n  \n\n- `rs` is always being read\n\n- `rt` is being read except when the instruction is `lw`.\n\n    - It is for loading\n\n  \n![[02 5.jpg]]\n\n\n  \n\n### ALU control\n\n- Load / store instructions: add\n\n- Branch instructions: subtract\n\n- R-format instructions: depends on a function field in the instructions\n\n  \n![[03 4.jpg]]\n  \n\n- Main Control Unit determines the `ALUOp` value\n\n- Whatever the `funct` codes are, if the opcode is `lw`, `sw`, or `beq`, ALU fuction is determined automatically"},{"excerpt":"contents: 0-1. CA Intro Case I will focus on handling a subset of core MIPS instructions (MIPS subset) The arithmetic-logical instructions: , , , ,  The memory-reference instructions: ,  The conditio…","fields":{"slug":"/4-1. Processor Overview/"},"frontmatter":{"date":"2024년 08월 15일 12:08","title":"Processor Overview","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Case\n\nI will focus on handling a subset of core MIPS instructions (MIPS subset)\n\n- The arithmetic-logical instructions: `add`, `sub`, `and`, `or`, `slt`\n\n- The memory-reference instructions: `lw`, `sw`\n\n- The conditional instructions: `beq`, `jump`\n\n  \n\n## Logic design basics\n\nIn the MIPS implementation, the datapath elements consist of\n\n- **Combinational** elements\n\n    - Operate on data values\n\n    - Given inputs, a combinational element produces outputs\n\n    - e.g., ALU(Arithmetic Logic Unit), Adder, Multiplexer, AND-gate\n\n- **State (sequential)** elements\n\n    - Contain state\n\n    - They have some internal storage\n\n    - e.g., instruction and data memory, registers\n\n</br>\n\n  \n\nCombinational elements work with state elements\n\n- Getting inputs from state elements\n\n- Giving outputs to state elements\n\n  \n\n## Clocking methodology\n\nWhen data can be read and written is determined relative to the clock </br>\n\nIn this book, we assume **\"Positive edge-triggered clocking methodology\"**\n\n  \n\nCombinational elements works with state elements </br>\n\n**In a single clock cycle = between clock edges = between rising edges**\n\n- At one rising edge, combinational elements read inputs from state elements\n\n- Before the next rising edge, combinational elements complete operations and produce outputs\n\n- At the next rising edge, state elements are updated with the outputs\n\n- **The longest delay determines clock period**\n![[01 4.jpg]]\n\n\n</br>\n\n  \n\n### State elements with two inputs\n\n**State elements (e.g., registers) take two inputs: update data and a clock signal** </br>\n\nBased on the clock signal, it is determined when to update the data\n\n  \n\nIn positive edge-triggered clocking methodology, </br>\n\nUpdate the data at rising edges (when the clock signal changes from 0 to 1)\n![[02 4.jpg]]\n</br>\n\n  \n\n### State elements with three inputs\n\n**State elements take three inputs: update data and a clock signal with write control** </br>\n\nBased on the clock signal and the write control, it is determined when to update the data\n\n  \n\nIn positive edge-triggered clocking methodology, </br>\n\nUpdate the data at rising edges + **when the write control input is 1**\n\n![[03 3.jpg]]"},{"excerpt":"contents: 0-1. CA Intro Division If the length of Dividend and Divisor is M and N,  the length of Quotient  M - N + 1 & the length of Remainder  N In MIPS-based computers, 32 bits are used to represe…","fields":{"slug":"/3-3. Division/"},"frontmatter":{"date":"2024년 08월 14일 14:08","title":"Division","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Division\n\nIf the length of Dividend and Divisor is **M** and **N**, </br>\n\nthe length of Quotient $\\leqq$ M - N + 1 & the length of Remainder $ \\leqq$ N\n\n- In MIPS-based computers, 32 bits are used to represent both Dividend and Divisor. </br>Therefore, the length of both Quotient and Remainder $\\leqq$ 32\n\n</br>\n\n  \n\n### Optimized version of the division HW\n\n- 32-bit divisor register / ALU\n\n- 64-bit remainder register (dividend and quotient shares a register with remainder)\n\n    - `HI`: Remainder\n\n    - `LO`: Quotient\n![[01 3.jpg]]\n\n\n</br>\n\n  \n\n### Settings\n\n- 0 is stored in the left half of the Remainder register\n\n- The value of dividend is loaded into the right half of the Remainder register\n\n- The value of divisor is loaded into the Divisor register\n\n</br>\n\n  \n\n### Division Algorithm\n![[02 3.jpg]]\n\n\n</br>\n\n  \n\n#### Example\n\nWhen N = 4 (4-bit ALU / divisor, 8-bit product), $7 \\div 3$\n\n- should be **repeated as many bits + 1 as it is**\n![[03 2.jpg]]\n\n</br>\n\n  \n\n### Signed division\n\nDo division after converting both divisor & dividend to positives </br>\n\nAfter the division\n\n- Negate the quotient only if the signs of the divisor and dividend are different\n\n- Remainder's sign follows Dividend's sign\n\n</br>\n\n  \n\n### Instructions\n\n- `div rs, rt / divu rs, rt` : do `$rs` / `$st`\n\n    - The result (remainder and quotient) is stored in `HI` / `LO`\n\n    - No overflow or divide-by-0 checking\n![[04 2.jpg]]\n\n\n</br>\n\n  \n\n#### Example:\n\n- Initially, the value in `$t0` (dividend) is loaded into the `LO` register\n\n- Initially, `$t` (divisor) is used as the divisor register\n\n- Then, do the division and store the remainder and quotient to `HI` and `LO` registers\n\n  \n\n## Summary: Design for arithmetic operations\n\n### Addition & Subtraction\n\nUse the same HW for addition and subtraction\n\n- 32-bit parallel adder\n\n- Additional XOR operators + subtract bit\n![[05 2.jpg]]\n</br>\n\n  \n\n### Multiplication & Division\n\nUse the same optimized HW for Multiplication and Division\n\n- A single 32-bit register for multiplicand and divisor\n\n- A single 32-bit `ALU`\n\n- `HI` and `LO` registers for the results of multiplication and division\n![[06 1.jpg]]"},{"excerpt":"contents: 0-1. CA Intro Multiplication If a multiplicand and a multiplier have m and n digits, the product has at most m + n digits MIPS-based computers use 32-bit word for the arithmetic operations …","fields":{"slug":"/3-2. Multiplication/"},"frontmatter":{"date":"2024년 08월 14일 12:08","title":"Multiplication","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Multiplication\n\nIf a multiplicand and a multiplier have **m** and **n** digits, the product has at most **m + n** digits\n\n- MIPS-based computers use **32-bit** word for the arithmetic operations\n\n- The product in MIPS-based computers has at most **64 digits**\n\n</br>\n\n  \n\n### Optimized version of the multiplication HW\n\n- 32-bit multiplicand register / ALU\n\n- 64-bit product register (multiplier shares a register with product)\n\n    - `HI`: most significant 32 bits\n\n    - `LO`: least significant 32 bits\n\n    - Actually, there is one more bit in the left of the product register to hold the carry out of the adder\n\n![[01 2.jpg]]\n\n</br>\n\n  \n\n### Settings\n\n- 0 is stored in the left half of the product register\n\n- The multiplier value is loaded into the right half of the product register\n\n- The multiplicand value is loaded into the multiplicand register\n\n</br>\n\n  \n\n### Multiplication Algorithm\n![[02 2.jpg]]\n\n  \n\n#### Example\n\nWhen N = 4 (4-bit ALU / multiplicand, 8-bit product), $2 \\times 3$\n\n- should be **repeated as many bits as it is**\n![[03 1.jpg]]\n\n  \n\n### Signed multiplication\n\nDo multiplication after converting both multiplicand & multiplier to positives\n\n- For 31 iterations (except a sign bit)\n\n- After the multiplication, negate the result (if it is required)\n\nBetter solution: Booth's Algorithm\n\n- Supports multiplication of two's complement signed numbers in a more efficient way\n\n- Requires almost same hardware with the multiplication of unsigned numbers\n\n</br>\n\n  \n\n### Instructions\n\n- `mult rs, rt / multu rs, rt` (rs: multiplicand, rt: multiplier)\n\n    - The result (product) is stored in `HI` / `LO`\n![[04 1.jpg]]\n\n\n- `mfhi rd / mflo rd`\n\n    - Move from `HI` / `LO` to rd\n![[05 1.jpg]]\n\n  \n\n#### Example: `mult $t0, $ t1`\n\n- `$t0` (multiplicand) is used as the Multiplicand register\n\n- Initially, the value in `$t1` (multiplier) is loaded into `LO` register\n\n- Then, do the multiplication and store the 64-bit product to `HI` and `LO` registers"},{"excerpt":"contents: 0-1. CA Intro Addition & Subtraction Addition: just do the binary addition with given numbers  Subtraction: do the binary addition with the negation of the second operand Half adder 1-bit a…","fields":{"slug":"/3-1. Addition and Subtraction/"},"frontmatter":{"date":"2024년 08월 13일 12:08","title":"Addition and Subtraction","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Addition & Subtraction\n\n**Addition**: just do the binary addition with given numbers </br>\n\n**Subtraction**: do the binary addition with the negation of the second operand\n\n### Half adder\n\n1-bit adder without carry-input\n\n- Input: two one bit-data A, B\n\n- Output: sum(S), carry(C)\n\n  \n\n### Full adder\n\n1-bit adder with carry-input\n\n- Input: two one bit-data A, B, carry(C$_{in}$)\n\n- Output: sum(S), carry(C$_{out}$)\n\n  \n\n## Circuit design for addition and subtraction\n\n### N-bit parallel binary adder\n\n- Initial carry input is 0\n\n- The i-th adder waits for the carry until it is generated by the (i-1)-th adder\n![[01 1.jpg]]\n\n\n  \n\n### Adder with subtraction (in two's complement)\n\n- Subtract = 0 or 1 (if subtract == 1, B$_i$ is inverted)\n\n- Subtract is also added as the initial carry (if subtract ==1, 1 is added)\n![[02 1.jpg]]\n\n\n  \n\n## Overflow\n\nOverflow occurs when computation results are too large (out of range)\n\n  \n\n### When does it occur?\n\n- Add two positives or negatives + the sign of result is different with sources\n\n- Subtract a negative from a positive + the sign of result is 1\n\n- Subtract a positive from a negative + the sign of result is 0\n\n  \n\n### How to detect Overflow?\n\n- Use `add, addi, sub` instructions\n\n- They cause exceptions on overflow\n\n    - A program jumps to predefined exception handler address\n\n- e.g., Fortran does not allow overflows. So MIPS Fortran compilers always use `add, addi, sub`\n\n  \n\n### How to ignore Overflow?\n\n- Use `addu, addui, subu` instructions (u means unsigned)\n\n- They do not cause exceptions on overflow\n\n- e.g., C ignores overflows. So MIPS C compilers always use `addu, addui, subu`"},{"excerpt":"contents: 0-1. CA Intro MIPS memory allocation To avoid the overlap for managing memory, we use stack, heap, and static space. Stack During the procedure call, both registers and local variables are …","fields":{"slug":"/2-5. MIPS memory allocation & addressing/"},"frontmatter":{"date":"2024년 08월 08일 12:08","title":"MIPS memory allocation & addressing","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## MIPS memory allocation\n\nTo avoid the overlap for managing memory, we use stack, heap, and static space.\n\n  \n\n### Stack\n\nDuring the procedure call, both registers and local variables are stored on stack. </br>\n\nWe call the segment of the stack **activation record** or **procedure frame**\n\n- The frame pointer (`$fp`) points to the first word of the frame\n\n- During the execution of a procedure, `$fp` is stable. So, it is used to reference variables\n![[01.jpg]]\n\n  \n\n- **Activation record**\n\n    - managed in a stack from high address to low address\n\n  \n\n### Heap\n\n- **Dynamically-allocated data**\n\n    - managed in a heap from low addresses to high addresses\n\n  \n\n### Static space\n\n- **Global variables**\n\n    - assigned a fixed address\n\n    - statically allocated\n\n    - all reference to a global variable point to the same object\n\n    - it cannot be stored in an activation record\n\n  \n  \n\n### Code & Data in memory\n![[02.jpg]]\n\n  \n\nThese addresses are only a software convention, and not part of the MIPS architecture.\n\n- The stack pointer (`$sp`) is initialized to `7fff fffc`$_{hex}$ and grows down toward the data segment\n\n- At the other end, the program code starts at `0040 0000`$_{hex}$\n\n    - From `0000 0000`$_{hex}$ to `0040 0000`$_{hex}$ is just reserved\n\n- The static data starts at `1000 0000`$_{hex}$\n\n- The global pointer (`$gp`) is set to an address to make it easy to access data, and initialized to to `1000 8000`$_{hex}$ so that it can access fromm `1000 0000`$_{hex}$ to `1000 ffff`$_{hex}$ using the positive and negative 16-bit offsets from `$gp`\n\n- Dynamic data is grows up toward the stack in an area called heap\n\n\n\n  \n\n## Addressing mode\n\nAfter we decode instructions, we will perform corresponding tasks. </br>\n\nAt this time, we need to **access data or instructions which can be stored in instructions, registers or memory.**\n\n  \n\n### 1. Immediate addressing (with immediate operands)\n\n- by decoding instructions, we can get data **directly**\n\n- last 16 bits are used to represent data\n\n- the operand is 16 bits of the instructions\n\n- don't need to access other place\n![[03.jpg]]\n\n  \n\n#### Supporting 32-bit constants\n\nSometimes, we need to use a 32-bit constants\n\n- `lui` instruction\n\n    - transfers the 16 bit immediate constant field value into the leftmost 16 bits of the register\n\n    - fills the lower 16 bits with `0`s\n\n- `ori` instruction\n\n    - fills the lower 16 bits with given data\n\n</br>\n\n  \n\n### 2. Register addressing (with register operands)\n\n- use 5 bits to represent register number from 0 to 31\n\n    - because there are 32 registers\n\n- work like a pointer\n![[04.jpg]]\n\n</br>\n\n  \n\n### 3. Base addressing (with data transfer instructions)\n\n- `rs` points base address, and last 16 bits represent offset\n\n- 16 bits can represent from `-2`$^{15}$ to `2`$^{15}$`-1`\n\n    - `2`$^{15}$ = `8000`$_{hex}$\n\n    - `$gp` always points `1000 8000`$_{hex}$ which means that, with offset it can access every statically-allocated space\n\n![[05.jpg]]\n\n</br>\n\n  \n\n### 4. PC-relative addressing (with branch instructions)\n\n- there is no base address like data transfer instructions\n\n- Assumption: most branch targets are near from the current instruction\n\n- In HW implementation, `PC` is already incremented by 4 before computing the current instruction\n\n    - `PC` points next instructions\n\n- all instructions are stored in an address that is a multiple of 4.\n\n    - by alignment restrictions, it ends with last 2 bits `00`\n\n    - it increments by 4 which is `00`\n\n    - it always ends with `00`\n\n- to save space, MIPS does not store last 2 bits\n\n    - to calculate offset, we have to multiply by 4\n\n    - actually it can represent up to 18 bits\n\n    - 18 bits can represent from `PC-2`$^{17}$ to `PC+2`$^{17}$`-4`\n![[06.jpg]]\n\n\n</br>\n\n  \n\n### 5. Pseudo-direct addressing (with branch instructions)\n\n- if branch targets are far from the current instruction (over 16 bits)\n\n- last 26 bits are used to represent the address of label\n\n- skip last 2 bits like PC-relative addressing\n\n    - actually it can represent up to 28 bits\n\n- code is stored from `0040 0000`$_{hex}$ to `1000 0000`$_{hex}$\n\n    - `1000 0000`$_{hex}$ = `0001 0000 0000 0000 0000 0000 0000 0000`$_{2}$\n\n    - which means that we have to access up to `0000 1111 1111 1111 1111 1111 1111 1100`$_{2}$\n\n        - always start with `0000`$_{2}$ and end with `00`$_{2}$\n\n        - other 26 bits is important\n\n- So, with 26 bits we can represent up to 28 bits and concatenate `0000`$_{2}$ to the front\n\n![[07.jpg]]\n\n"},{"excerpt":"contents: 0-1. CA Intro Procedures Functions in a program Procedures do calling / returning with other procedures A procedure (caller) calls another procedure (callee) The callee returns values to ca…","fields":{"slug":"/2-4. Supporting procedures in computer HW/"},"frontmatter":{"date":"2024년 08월 07일 12:08","title":"Supporting procedures in computer HW","tags":["컴퓨터구조","study"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Procedures\n\n### Functions in a program\n\nProcedures do calling / returning with other procedures\n\n- A procedure (caller) calls another procedure (callee)\n\n- The callee returns values to caller\n\n  \n\n### Calling / returning process\n\n1. The caller passes input arguments and the return address to the callee\n\n2. The caller transfers control to the callee\n\n3. The callee performs its operations with the given input arguments\n\n4. The callee passes the return values to the caller\n\n5. The callee transfers control to the caller (Return to the given return address)\n\n6. The caller restores the saved things\n\n  \n\n### The way to pass values\n\nUse registers for passing arguments, return address, and return values\n![[register role.jpg]]\n\n\n  \n\nBut, what if different procedures share the same registers? \n**Use stacks to store all the information for operating each procedure** \nStacks are kept in memory\n- The register `$sp` points the top-of-stack in memory\n- By convention, stack grows towards lower addresses\n\n  \n\n### Register saving\nThe values of some registers must be preserved on call \nIt must be possible to recover the values on those registers after calling / returning is completed\n![[register role 2.jpg]]\n\n\nIf a callee uses preserved registers, the callee must\n- Save the values of the registers on its stack **after calling**\n- Restore the saved values **before returning**\n\nIf a caller needs to keep the values in non-preserved registers, the caller must\n- Save the values on its stack **before calling**\n- Restore the saved values **after returning**\n\n## Instructions for procedure calls\n\n**`jal PROCEDURE_LABEL`**\n- Jump And Link\n- The return address of a caller (the address of following instruction) put in `$ra`\n- Jump to the target address (`PROCEDURE_LABEL`)\n\n**`jr $ra`**\n- Jump Register\n- Jump to the address stored in `$ra` (other registers can also be used as an operand)\n\n\n**Push**\n<pre class=\"no-line-numbers language-bash\">\n\n<code class=\"prose-code:text-yellow-400\n\n            prose-code:text-sm\n\n            prose-code:font-normal\">addi $sp, $sp, -4\n\nsw $t0, 0($sp)\n\n</code></pre>\n\n- Push the data stored in `$t0` into the top-of-stack\n\n\n**Pop**\n<pre class=\"no-line-numbers language-bash\">\n\n<code class=\"prose-code:text-yellow-400\n\n            prose-code:text-sm\n\n            prose-code:font-normal\">lw $t0, 0($sp)\n\naddi $sp, $sp, 4\n\n</code></pre>\n\n- Pop the data stored in top-of-stack and store it to `$t0`"},{"excerpt":"contents: 0-1. CA Intro Common HW design for MIPS ISA HW design.jpg CPU, register, and memory Control unit (CU) directs the operation of the processor Arithmetic & logic unit (ALU) does the operation…","fields":{"slug":"/2-3. Representing Instructions in computer/"},"frontmatter":{"date":"2024년 07월 31일 15:07","title":"Representing Instructions in computer","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\n## Common HW design for MIPS ISA\n![[HW design.jpg]]\n\n**CPU, register, and memory**\n- Control unit (CU) directs the operation of the processor\n- Arithmetic & logic unit (ALU) does the operation\n- `$0, ..., $31` hold the value that will be used in the operation (called general purpose register)\n- Program counter (PC) contains the memory address of the instruction will be executed\n- Instruction register (IR) contains the current instruction\n\n**Execution of the instruction**\n- Step 1 (fetch): CU says \"load the instruction from the memory address in PC to IR\"\n- Step 2 (decode): CU says \"the instruction stored in IR means `ADD $s0, $s1, $s2`\n- Step 2 (execute): ALU does the add operation with the values in `$s1` and `$s2` and stores the computation result in `$s0`\n## Operation\n### Arithmetic operations\n**Instructions for arithmetic**\n| Operation | C    | Java | MIPS assembly language | Example             |\n| --------- | ---- | ---- | ---------------------- | ------------------- |\n| Add       | +    | +    | `add` (R), `addi` (I)  | `add $t0, $t1, $t2` |\n| Subtract  | -    | -    | `sub` (R)              | `sub $t0, $t1, $t2` |\n\n### Logical operations\n**Instructions for bitwise manipulation**\n\n| Operation   | C   | Java | MIPS assembly language | Example             |\n| ----------- | --- | ---- | ---------------------- | ------------------- |\n| Bitwise AND | &   | &    | `and`(R), `andi`(I)    | `and $t0, $t1, $t2` |\n| Bitwise OR  | \\|  | \\|   | `or` (R), `ori`(I)     | `or $t0, $t1, $t2`  |\n| Bitwise NOR | ~   | ~    | `nor`(R)               | `nor $t0, $t1, $t2` |\n\n\nMIPS has no NOT instruction \nInstead, it has **NOR R-type** instruction\n- a NOR b == NOT (a OR b)\n- But, we can do the NOT operation with NOR: `nor $t0, $t1, $zero!`\n![[nor.jpg]]\n\n### Shift operations\n| Operation    | C     | Java  | MIPS assembly language | Example                              |\n| :----------- | :---- | :---- | :--------------------- | :----------------------------------- |\n| Shift left   | <<    | <<<   | `sll` (R)              | `sll $s1, $s2, 10 ($s1 = $s2 << 10)` |\n| Shift right  | >>    | >>>   | `srl` (R)              | `srl $s1, $s2, 10 ($s1 = $s2 >> 10)` |\n\n![[shift operation.jpg]]\n- shamt: how many positions to shift\n- Shift left/right logical (sll / srl)\n\t- Shift left/right and fill with 0 bits\n\t- (unsigned only) sll with i bits = multiply by $2^i$\n\t- (unsigned only) srl with i bits = divide by $2^i$\n\n\n### Conditional operations\n\n| Operation            | MIPS assembly language | Example                                           |\n| -------------------- | ---------------------- | ------------------------------------------------- |\n| Conditional branch   | `beq`(I)               | `beq $t0, $t1, LABEL` (if $t0 == $t1, goto LABEL) |\n|                      | `bne`(I)               | `bne $t0, $t1, LABEL` (if $t0 != $t1, goto LABEL) |\n| Unconditional branch | `j`(I)                 | `j LABEL` (goto LABEL)                            |\n\n\n![[bne.jpg]]\n![[j-format.jpg]]\n\n**Instructions for making decisions** \nUsually combined with goto statements and labels \nthere are no branch instructions like blt (less than) and bge (greater than or equal to)\n\n\n**Why?** \n- Handling <, >, <=, >=, ... is slower and more complicate than =, !=\n- It will cause increase of instruction count and clock period or CPI\n\n**Instead, MIPS provides others** \n\n| operation        | MIPS assembly language | Example                                                    |\n| ---------------- | ---------------------- | ---------------------------------------------------------- |\n| Set on less than | slt(R), slti(I)        | slt $t0, $t1, $t2 (if $t1 < $t2, $t0 = 1; else $t0 = 0) |\n\n\n**slt is used in combination with beq and bne**\n```\nslt $t0, $t1, $t2\nbne $t0, $zero, LABEL\nbeq $t0, $zero, LABEL\n```"},{"excerpt":"contents: 0-1. CA Intro The assembly language that has been studied so far is not a form that the processor can understand. Therefore, we need to encode instructions and data in well-formed binary. D…","fields":{"slug":"/2-2. Design principles 4 of MIPS ISA/"},"frontmatter":{"date":"2024년 07월 31일 15:07","title":"Design principles 4 of MIPS ISA","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n\nThe assembly language that has been studied so far is not a form that the processor can understand. \n\nTherefore, we need to **encode instructions and data in well-formed binary.**\n\n## Data representation\n\n### numbers\n- Numbers are kept in computer hardware as a series of 1 and 0\n- They are considered base 2 numbers (binary numbers)\n- Binary numbers are stored in words\n- In MIPS, the words are 34 bits (4 bytes) long + MIPS is big endian\n### unsigned numbers\n- By using n bits, we can represent unsigned numbers from 0 to $2^n-1$\n### signed numbers\n#### Signed Magnitude\n- first bit determines mathematical symbols\n\t- 0 is plus (+)\n\t- 1 is minus (-)\n- others are bit size\n- but, 000 = 100 = 0\n#### One's complement\n- first bit determines mathematical symbols\n\t- 0 is plus (+)\n\t- 1 is minus (-)\n- if first bit is 0\n\t- read it as it is\n- if first bit is 1\n\t- flip 1 to 0, 0 to 1\n- ex) 100 = -3\n- but, 000 = 111 = 0\n#### Two's complement\n- first bit determines mathematical symbols\n\t- 0 is plus (+)\n\t- 1 is minus (-)\n- if first bit is 0\n\t- read it as it is\n- if first bit is 1\n\t- flip 1 to 0, 0 to 1\n\t- plus 1\n- ex) 100 = -4\n- the number of zero is 1\n### Answer\n**two's complement**  \n- we can get the computation result by just doing given arithmetic operations\n    - 000 - 001 = 111 ( 0 - 1 = -1)\n    - 010 + 111 = 001 (2 + (-1) = 1)\n- the number of zero is only 1.\n- by using n bits, we can represent signed numbers from $-2^{n-1}$ to $2^{n-1}-1$\n#### Signed extension\nSometimes, we need to represent n-bit numbers by using more than n bits\n- 16-bit immediate should be converted to 32 bits for arithmetic\n- Instructions `lb/lh` loads byte/halfword from memory space and store it into 32-bit registers\n- Replicate the sign bit to the left\n  ![[signed extension.jpg]]\n## Instruction representation\n**Like data, instructions are also encoded/represented in binary**\nWe call the encoded instructions as **machine instructions**\n\nFor representing instructions, ISA defines instruction format\nIssue: to represent all kinds of instructions, we might need many instrucion formants\n## Design principle 4\n### Good design demands good compromise\nBased on this, MIPS keeps formats as similar as possible (regularity)\n### R-format\nFor the instructions that use only Register operands\n![[r-format.jpg]]\n- `op` (opcode): basic operation of the instruction (what the instruction does)\n- `rs`: the first source register operand\n- `rt`: the second source register operand\n- `rd`: the destination register operand\n- `shamt`: shift amount (used for shift operations)\n- `funct`: function code (the specific variant of the operation)\n>Q. why are the rs, rt, rd 5 bits? \n>\n>A. registers are 32, which means 5 bits are enough to express each register\n\n### I-format\nFor the instructions that use Immediate operands\n![[i-format.jpg]]\n- `op` (opcode): basic operation of the instruction (what the instruction does)\n- `rs`: the first source register operand\n- `rt`: the second source register operand\n- `Constant or address`\n## Summary\nKey underlying design principles\n### Design Principle 1\n#### Simplicity favors regularity\nAll MIPS arithmetic instructions include a single operation & three operands\n- Lower clock period or CPI\n\n## Design Principle 2\n#### Smaller is faster\nOperands of MIPS arithmetic instructions must be chosen in a small number of registers.\nMIPS keeps more complex data in memory and supports data transfer between memory and registers.\n- Lower clock period or CPI\n### Design Principle 3\n#### Make the common case fast\nSupport 16-bit immediate operands for handling small constants + `$zero`\n- Lower Instruction count\n### Design Principle 4\n#### Good design demands goog compromise\nKeep all instructions the same length + keep instruction formats similar as possible. \nData (numbers) are also represented in binary based on two's complement rules.\n- Lower clock period or CPI"},{"excerpt":"contents: 0-1. CA Intro MIPS ISA What is MIPS ISA Microprocessor without Interlocked Pipelined Stages A kind of ISA Design principles Simplicity favors regularity Smaller is faster Make the common ca…","fields":{"slug":"/2-1. Designing principles 1~3 of MIPS ISA/"},"frontmatter":{"date":"2024년 07월 22일 16:07","title":"Design principles 1~3 of MIPS ISA","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n## MIPS ISA\n### What is MIPS ISA\n- Microprocessor without Interlocked Pipelined Stages\n- A kind of ISA\n\n### Design principles\n1. **Simplicity favors regularity**\n2. **Smaller is faster**\n3. **Make the common case fast**\n\n## Design Principle 1\n### Simplicity favors regularity\n- **Regularity**: all MIPS arithmetic instructions include **a single operation & three operands** \n- Regularity makes implementation simpler \n- Simplicity enables higher performance at lower cost\n\n### Examples\n- add a, b, c\n\t- $a = b + c$\n- sub a, a, d\n\t- $a = a - d$\n\n## Design Principle 2\n### Smaller is faster\n- Operands of MIPS arithmetic instructions must be chosen in **a small number of registers**\n- **Register**: Fast locations for data\n- 32 32-bit registers in MIPS\n- 32 is $2^5$ that can be represented by using 5 bits![[registers.jpg]]\n\n## Practice 1\n**C code:**\n```c\nf = (g + h) - (i + j)\n```\n**Compiled MIPS assembly language code:**\n```\nadd $t0, $s1, $s2\nadd $t1, $s3, $s4\nsub $s0, $t0, $t1\n```\n\n## Memory instruction\n### Memory organization\nkeep a small amount data in **registers** and other remaining, complex data in **memory**\n- **Load** values from memory into registers\n- **Store** results from registers to memory\n### Address\nA memory address is an index to the memory array, starting at 0 \nMIPS uses byte addressing (Each address identifies an 8-bit byte)\n\n**But**, most data items are larger than a byte. So, they use \"**words**\" \n- In MIPS, a ward is 32 bits\n- Registers also hold 32-bit of data\n#### Alignment restrictions\n\n- The start address of each data should be multiple of N, where N is the size of the data\n- In MIPS, words must start at a addresses that are multiples of 4\n- Some data items use one or two bytes (halfword)\n#### Byte ordering\n- Big endian(**MIPS**): place the most significant byte first and the least significant byte last\n- Little endian: place the least significant byte first and the most significant byte last  \n### Load/Store\n- **lw reg1 offset(reg2)**: Load 32-bit word from the memory address reg2 + offset into reg1\n- **sw reg1 offset(reg2)**: Store 32-bit word in reg1 at the memory address reg2 + offset\n- **lh/sh** and **lb/sb** instructions load/store halfwords and 8-bit of data\n\n## Practice 2\n**C code:**\n```c\ng = h + A[8]\n```\n- A is an array of 4-bytes words\n- The value of g and h are in `$s1` and `$s2`\n- The base address of A is in `$s3`\n\n**Compiled MIPS assembly language code:**\n```\nlw $t0, 32($s3)\nadd $s1, $s2, $t0\n```\n\n## Practice 2\n**C code:**\n```c\nA[12] = h+ A[8]\n```\n- A is an array of 4-bytes words\n- The value of h is in `$s2`\n- The base address of A is in `$s3`\n\n**Compiled MIPS assembly language code:**\n```\nlw $t0, 32($s3)\nadd $t0, $s2, $t0\nsw $t0, 48($s3)\n```\n\n## Practice 3\n**C code:**\n```c\nf = (g + h) - (i + j)\n```\n- f, g, and h are in `$s0`, `$s1`, and `$2` respectively\n- Halfwords i and j are sequentially stored in memory\n- The start address of i is stored in `$s3`\n\n**Compiled MIPS assembly language code:**\n```\nadd $t0, $s1, $s2\nlh $t1, 0($s3)\nlh $t2, 2($s3)\nadd $t3, $t1, $t2\nsub $s2, $t0, $t3\n```\n\n## Design Principle 3\n### Make the common case fast\n**Common case :** a program uses a small constant in an operation many times \n\n**Solution: support** \n- **16-bit immediate operands** for handling the constants\n\t- no need to access memory to load the constants\n\t- `addi $t0, $t0, 4` : addi is an add immediate instruction\n\n- **MIPS register 0 (`$zero`)** contains the constant 0\n\t- `add $t0, $t1, $zero` : move values between two registers `$t0` and `t1`\n\n## Practice 4\n**C code:**\n```c\nf = A[10] - i + 4\n```\n- `A` is an array of bytes and its base address is stored in `$s0`\n- `f` and `i` are stored in `$s1` and `$s2` respectively\n\n**Compiled MIPS assembly language code:**\n```\nlb $t0, 10($s0)\nsub $t1, $t0, $s2\naddi $s1, $t1, 4\n```\n  \n\n## Summary: MIPS ISA\n\n### Key underlying design principles\n\n- Design principle 1. Simplicity favors regularity\n\t- All MIPS arithmetic instructions include a single operation & three operands\n- Design principle 2. Smaller is faster\n\t- Operands of MIPS arithmetic instructions must be chosen in a small number of registers\n\t- MIPS keeps more complex data in memory and supports data transfer between memory and registers\n- Design principle 3. Make the common case faster\n\t- Support 16-bit immediate operands for handling small constants + `$zero`\n"},{"excerpt":"contents: 0-1. CA Intro Measuring CPU performance Clock period: the duration of a clock cycle How long the computer takes to perform a single basic operation Clock rate (frequency):  How many basic o…","fields":{"slug":"/1-2. Measuring Performance/"},"frontmatter":{"date":"2024년 07월 22일 15:07","title":"Measuring Performance","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n## Measuring CPU performance\n- Clock period: the duration of a clock cycle\n\t- How long the computer takes to perform a single basic operation\n- Clock rate (frequency): $cycles\\;per\\;second = \\frac{1}{clock\\;period}$\n\t- How many basic operations can be performed in a second\n$$\n\nCPU\\;time = Clock\\;cycles \\times Clock\\;period \\\\ = Clock\\;cycles \\times \\frac{1}{Clock\\;rate}\n\n$$\n### What is CPI?\n**Clock Cycles per instruction**\n: Average number of clock cycles per instruction for a program or program fragment \n$$\n\nCPU\\;time = Clock\\;cycles \\times \\frac{1}{Clock\\;rate} \\\\= Instruction\\;count \\times CPI \\times \\frac{1}{Clock\\;rate}\n\n$$\n**CPI** can be affected by\n1) Cost for each instruction type: $CPI_i$\n2) The frequency of each type of instructions: $F_i = \\frac{Instruction\\;count_i}{Instruction\\;count}$\n$$\n\n\\displaystyle CPI = \\sum_{i=1}^{n}{CPI_i \\times F_i}\n\n$$\n\n## More about\n### Benchmark\n: **a tool for measuring the performance of computers**\n- Metric: **Geometric Mean**\n$$\n\n Performance = \\frac{1}{\\sqrt[n]{\\prod_{i=1}^{n}{Execution\\;time\\;ratio_i}}} \\\\ = \\frac{1}{\\sqrt[n]{\\prod_{i=1}^{n}{\\frac{Execution\\;time_{X,i}}{Execution\\;time_{REF,i}}}}} \n \\\\  = \\sqrt[n]{\\textstyle \\prod_{i=1}^{n}{\\frac{Execution\\;time_{REF,i}}{Execution\\;time_{X,i}}}}\n\n$$\n\n### Amdahl's law\n$Execution\\;time\\;after\\;improvement$ \n\n$= \\frac{Execution\\;time\\;affected\\;by\\;improvement}{Amount\\;of\\;improvement} + Execution\\;time\\;unaffected$\n\n"},{"excerpt":"contents: 0-1. CA Intro Two metrics for defining computer performances Response time The time between the start and completion of a task related to single task e.g., how long it takes to do a single …","fields":{"slug":"/1-1. Defining Performance/"},"frontmatter":{"date":"2024년 07월 22일 15:07","title":"Defining Performance","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n## Two metrics for defining computer performances\n1. Response time\n\t- The time between the start and completion of a task\n\t- related to single task\n\t- e.g., how long it takes to do a single task\n1. Throughput\n\t- A total amount of works done per unit time\n\t- related to multiple tasks\n\t- e.g., tasks per hour\n  \n\n**Q. If we replace the processor in a computer with ad faster version**\n- Response time **decrease**\n- Throughput **increase**\n\n**Q. If we add more processors to a system**\n- Response time **maintain or increase** (more lanes more complex)\n- Throughput **increase**\n\n## Defining performance\n\n- $Performance = \\frac{1}{execution\\;time\\,(reponse\\;time)}$\n- Relative performance: **X is N time faster than Y**\n- $\\frac{Performance_x}{Performance_y} = \\frac{Execution time_y}{Execution time_x} = N$\n\n![[performance.jpg]]\n\n- Elapsed time = system performance = **t1 + t2 + t3 + t4**\n\t- total time between the start and completion of a task, **including everything**\n- CPU time = CPU performance = **t1 + t4** *(Only this in this class)*\n\t- The time spent **processing** a given task **on a processor**\n\n$$\nPerformance = CPU\\;performance = \\frac{1}{CPU\\;time}\n$$\n\nThe CPU time can be further divided into\n- **User CPU time**\n\t- spent for processing the code of the program (some functions)\n- **System CPU time**\n\t- spent in the operating system performing tasks for the program (OS)"},{"excerpt":"contents: 0-1. CA Intro Below your program A simplified view of hardware and software Applications software Written in high-level language Systems software Compilers: translate high-level language to…","fields":{"slug":"/0-2. CA Overview/"},"frontmatter":{"date":"2024년 07월 22일 14:07","title":"CA Overview","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"contents: [[0-1. CA Intro]]\n### Below your program\n\nA simplified view of hardware and software\n- **Applications software**\n\t- Written in high-level language\n- **Systems software**\n\t- **Compilers**: translate high-level language to machine language\n\t- **Operating Systems**\n\t\t- Handle input/output operations\n\t\t- Manage resources (e.g., storage, memory)\n\t\t- Schedule tasks (processes)\n- **Hardware**\n    - processors memory, I/O devices\n    \n\n## Execution of programs\n### Step 1: Translating language\n- From high-level language\n\t- Designed for specific domain\n\t- Provides for productivity and portability\n- To hardware machine language\n\t- Binary digits\n\t- Encoded instructions\n\n### Step 2: Inputting, outputting, processing, and storing data\n**4 Fundamental HW components**\n- Processor\n\t- Datapath + control, our primary focus\n- Memory\n- Input device\n\t- Keyboard, mouse, ...\n- Output device\n\t- Screen, speaker\n\n**8 STEPS**\n1) Loading: programs are stored in memory\n2) Inputting: input device write data to memory\n3) Fetching: processor fetches instructions and data from memory\n4) Decoding: processor (control) decodes the instructions and determine what to do\n5) Executing : processor (datapath) executes the instructions & stores the computation result to memory\n6) Outputting: output device sends the result by reading output data from memory\n\n## Understanding program performance\n\n- Algorithm\n\t- Determines the number of operations executed\n- Programming language, compiler, and instruction set architecture (ISA)\n\t- Determine the number of machine instructions executed per operation\n- Processor and memory system\n\t- Determine how fast instructions can be executed\n- I/O system (including OS)\n\t- Determines how fast I/O operations are executed\n\n## What is ISA (Instruction Set Architecture)\n- An interface between SW snd HW (includes a set of machine instruction)\n\t- SW is translated into the machine instructions included in the ISA\n\t- HW is designed to support the instructions in ISA\n\n## 8 great ideas for designing better computer architecture\n- Design for **Moore's Law**\n\t- Anticipate where the technology will be when the design finishes\n- Provide **abstraction** to simplify design\n\t- Hide low-level details for the ease of SW development\n- Make **the common case** fast\n\t- Enhance performance of the common case instead of optimizing the rare case.\n- Perform via **parallelism**\n\t- Perform operations in parallel\n- Performance via **pipelining**\n\t- Use a particular patten of parallelism, called pipelining\n- Performance via **prediction**\n\t- Start working with prediction, stead of waiting until you know for sure\n- **Hierarchy** of memories\n\t- Use the fastest, smallest, and most expensive memory at the top of the hierarchy and the slowest, largest, and cheapest memory at the bottom\n\t- cache > RAM > Large SSD\n- Dependability via **redundancy**\n\t- Include redundant components that can take over when failure occurs"},{"excerpt":"Course Description 본 스터디에서는 컴퓨터 시스템이 어떻게 구성되어있고 디자인되어있는지 공부합니다.\n특히 CPU, memory를 포함한 하드웨어 시스템에 적용되고 있는 디자인 특성들을 알아봅니다. Prerequisites and Co-requisites C 프로그래밍, 논리회로, 어셈블리어를 알면 더욱 좋습니다. Textbooks 본 페이지…","fields":{"slug":"/0-1. CA Intro/"},"frontmatter":{"date":"2024년 07월 22일 12:07","title":"Computer Architecture Intro","tags":["study","컴퓨터구조"]},"rawMarkdownBody":"## Course Description\n\n본 스터디에서는 컴퓨터 시스템이 어떻게 구성되어있고 디자인되어있는지 공부합니다. \n특히 CPU, memory를 포함한 하드웨어 시스템에 적용되고 있는 디자인 특성들을 알아봅니다.\n\n## Prerequisites and Co-requisites\n\nC 프로그래밍, 논리회로, 어셈블리어를 알면 더욱 좋습니다.\n\n## Textbooks\n\n본 페이지에 작성될 내용의 기반은 아래의 책에 있습니다.\n![[computer-architecture-textbook.jpg]]Computer Organization and Design 5th Edition (Asian Edition)\n\n## Course Schedule\n- 0. Intro\n\t- [[0-1. CA Intro]]\n\t- [[0-2. CA Overview]]\n- 1. Computer Abstractions and Technology\n\t- [[1-1. Defining Performance]]\n\t- [[1-2. Measuring Performance]]\n- 2. Instructions: Language of the Computer\n\t- [[2-1. Designing principles 1~3 of MIPS ISA]]\n\t- [[2-2. Design principles 4 of MIPS ISA]]\n\t- [[2-3. Representing Instructions in computer]]\n\t- [[2-4. Supporting procedures in computer hardware]]\n\t- [[2-5. MIPS memory allocation & addressing]]\n- 3. Arithmetic for Computers\n\t- [[3-1. Addition and Subtraction]]\n\t- [[3-2. Multiplication]]\n\t- [[3-3. Division]]\n- 4. The Processor\n\t- [[4-1. Processor Overview]]\n\t- [[4-2. Controlling a datapath]]\n\t- [[4-3. A single-cycle datapath]]\n\t- [[4-4. Pipelining overview]]\n\t- [[4-5. Handling hazards]]\n\t- [[4-6. Exceptions]]\n- 5. Memory Hierarchy\n\t- [[5-1. Cache overview]]\n\t- [[5-2. Improving cache performance]]\n\t- [[5-3. Vitual memory Part 1]]\n\t- [[5-4. Vitual memory Part 2]]\n"},{"excerpt":"지난 회고: retrospect-2023 어느덧 24년 상반기가 지나갔다. 2주 전에 전역도 하고 한창 바쁘게 살고 있는 요즘이다. 물론 공부를 그렇게 한다는 건 아니고 자취 준비도 하고 못 만났던 사람들도 열심히 만나고 있다. 학교는 아직 4차 학기밖에 안 끝낸 상태인데 엇복학은 힘들 것 같아서 내년에 복학할 예정이고 대신 학부연구생은 하반기부터 진행할…","fields":{"slug":"/retrospect-2024-1/"},"frontmatter":{"date":"2024년 07월 20일 20:07","title":"2024년 상반기 회고","tags":["회고"]},"rawMarkdownBody":"지난 회고: [[retrospect-2023]]\n\n어느덧 24년 상반기가 지나갔다. 2주 전에 전역도 하고 한창 바쁘게 살고 있는 요즘이다. 물론 공부를 그렇게 한다는 건 아니고 자취 준비도 하고 못 만났던 사람들도 열심히 만나고 있다. 학교는 아직 4차 학기밖에 안 끝낸 상태인데 엇복학은 힘들 것 같아서 내년에 복학할 예정이고 대신 학부연구생은 하반기부터 진행할 예정이다.\n\n우선 이번 반기 목표는 아래와 같다.\n> - 운동 꾸준히 하기 (체중80 골격근량43 목표)\n> - 코테 준비하기\n> - 좋아하는 분야 찾기\n> - 일찍 자고 일찍 일어나기 \n\n\n## 운동 꾸준히 하기\n입대 후부터 지금까지 습관처럼 운동을 해오고 있는데 이제는 안하면 스트레스를 받는 정도인 것 같다. 좋은 건지, 안 좋은 건지는 모르겠지만 점점 욕심도 생기고 변해가는 모습이 마음에 든다. \n\n지금은 학교도 안다니고 약속도 정해진 게 없어서 운동을 오전에 해치우고 있는데 학부연구생을 시작하거나 복학하고 나서는 언제 운동을 가야할 지 모르겠다. 운동하는 직장인분들 보면 저녁 늦게 오시는 것 같던데 다들 일정 다 끝내고 힘든 와중에 어떻게들 하는지... 대단한 것 같다.\n![[inbody.jpg]]\n위 사진이 6월말 인바디 결과다. 예전에 비해서는 체중도 많이 늘고 골격근량도 증가해서 진짜 좋아진 편인데 하다보니 욕심이 생겨서... 올해 안으로 체중 80kg, 골격근량 43kg 만드는 게 목표다. 체지방도 많이 필요해보이긴 하는데 그렇다고 지금 복근이 선명하게 보일정도로 마르지도 않아서 더 찌워도 되나... 하는 생각이 든다. 근데 찌우고 싶어도 살이 찌지는 않더라..\n\n지금은 4분할 운동하고 하루 또는 상황이 여의치 않으면 이틀 쉬어주고 있는데 하반기에도 유지하는 게 목표다. 꾸준히 하자!\n\n## 코딩테스트 준비\n군복무를 하면서 코테 준비만큼은 목표를 달성하지 못한 것 같다. 지금 상태는 어떤 알고리즘을 써야하는지 보면 어찌저찌 풀 수 있는 정도인데 그 알고리즘 마저도 온전히 내 걸로 만들지도 못했다. 아직 많이 부족한 분야라고 생각이 들고 그만큼 내가 그동안 피해왔던 분야라고 생각이 든다. \n\n어떤 종류의 알고리즘을 써야하는지 안보면서 푸는 연습, 푸는 방식을 정했으면 스스로 구현하는 연습을 처음부터 기초를 다진다는 생각으로 해야할 것 같고 공부 과정을 여기에 잘 남기도록 해야겠다/ \n\n## 좋아하는 분야 찾기 (미래 계획)\n학부연구생을 하는 것도 이 목표의 일환이기도 한데, 난 내가 생각했을 때 아직은 어떤 분야를 깊게 알고싶은지 모르는 것 같다. 관심사도 계절 바뀌듯이 바뀌어서 넓고 얕은 지식 상태를 유지하고 있는 상황이다. 최근엔 HCI (Human Computer Interactions)에 관심이 생겼다. 그래서 [중앙대 김효수 교수님 연구실](https://sites.google.com/view/hcslab-cau/home?authuser=0)에서 학부연구생을 하기로 했고, 아직은 그곳에서 내가 무엇을 할지는 모르겠지만 내 바람은 연구 분위기도 경험해보면서 내가 선택한 분야가 나와 과연 잘 맞는가, 내가 계속 호기심을 갖고 접근하는가, 이런 일련의 과정들을 계속 해갈 수 있을지에 대한 답을 찾아가고 싶다.\n\n주변에 학교를 졸업하는 사람이 하나 둘 생기면서 과연 난 학사 졸업 후에 무엇을 할 지에 대한 막연한 고민들이 생기기 시작했다. 대학원을 가고 싶은지, 취업을 하고 싶은지, 창업을 하고 싶은지 아무것도 모르는 상태다. 고등학생 때는 당연히 대입이라는 어떻게 보면 정해진 미래 덕분에, 혹은 아직은 미성년자라는 것 때문에 미래에 대한 고민들이 없었지만 대학생이라는 신분은 좀 애매한 것 같다. 법적상 성인이긴 하지만 과연 그만큼의 책임감을 우리가 느끼고 있느냐, 난 개인적으론 아닌 것 같다. 아직은 철 없다고 느끼는 순간도 많고 애처럼 책임을 회피하는 순간들이 종종 있는데, 남은 반기동안에는 졸업 후의 모습에 대해서, 내가 진짜 하고 싶은게 무엇인지 고민할 수 있는 시간을 많이 가져야겠다고 생각이 든다.\n\n## 일찍 자고 일찍 일어나기\n전역 후에 자연스럽게  늦게 자고 늦게 일어나는... 입대 전 생활로 돌아가고 있다. 그렇다고 새벽까지 생산적인 일을 하는 것도 아니라서 온전히 활용하는 시간이 적다. 오전 시간을 활용하려고 하고 있고 지금도 일찍 자고 일찍 일어나서 운동을 가는 루틴을 습관화하려고 하는데 유지하자. \n\n## 마무리하며\n지나고나서야 군대에 있는 1년 반이 짧게 느껴지는 것 같다. 그동안 못해왔던 공부를 다시 할 생각에 막막하기도 하고 기대도 되는 시점인데 절반도 안남은 24년을 후회없이 보내고 싶다. 전에도 쓴 것 같은데 기록의 중요성을 다시 한 번 느끼면서 하반기에는 공부 뿐이 아니라 여러 활동들, 생각들을 적으려고 노력해봐야겠다. "},{"excerpt":"항상 기록의 중요성을 느끼고 있었다. 내가 어떤 걸 배우고 해냈다라는 걸 뽑내기 보다는 내 생각들과 학습한 내용들을 구조화해서 나중에 다시 쉽게 찾아볼 수 있도록, 그리고 그게 또 하나의 내 자산이 되기를 원했다. 그래서 제작년부터 이런 저런 툴을 사용해보며 블로깅을 해왔는데 결국은 하나같이 다 마음에 들지 않았다. 생산성 내가 원한 건 생산성 딱 하나였…","fields":{"slug":"/why-obsidian/"},"frontmatter":{"date":"2024년 01월 10일 13:01","title":"기존 블로그 대신 Obsidian을 택한 이유","tags":["obsidian"]},"rawMarkdownBody":"항상 기록의 중요성을 느끼고 있었다. 내가 어떤 걸 배우고 해냈다라는 걸 뽑내기 보다는 내 생각들과 학습한 내용들을 구조화해서 나중에 다시 쉽게 찾아볼 수 있도록, 그리고 그게 또 하나의 내 자산이 되기를 원했다. 그래서 제작년부터 이런 저런 툴을 사용해보며 블로깅을 해왔는데 결국은 하나같이 다 마음에 들지 않았다.\n## 생산성\n내가 원한 건 생산성 딱 하나였다. 블로깅을 하는 유일한 목적이 결국은 스쳐지나가는 생각들을 메모해두기 위함인데 기존에 사용하던 [Nuxt로 개발된 블로그](https://github.com/theminjunchoi/ex-blog)는 생산성 측면에서 부족했던 것 같다. 글 하나를 쓰기 위해 노트북을 열어야했고 괜히 나도 있어보이는 글을 쓰기 위해 억지로 분량을 늘리고 이쁜 문장들을 찾았다. 공부 내용을 기록할 때도 학습에 초점을 둔 기록이기보단 정리에 초점을 둔 기록들 투성이었다. 지금 생각해보면 모든 요소 하나하나가 너무 많은 시간을 잡아먹는 것 같았다. 그러던 와중에 obsidian을 발견했다.\n## 현재 블로그\n### obsidian\n세컨드브레인이라는 책을 읽다가 obsidian이라는 툴을 알게 됐다. 글과 글 사이에 관계를 나타내기 좋아서 사용하기 시작했는데 여러 플러그인들도 많아서 내가 사용하는 용도에 맞게 커스텀하기 좋은 것 같다. 플러그인은 아래의 것들을 사용하고 있다.\n- Omnisearch\n- Templater\n- Update time on edit\n- Outliner\n- Checklist\n- Calendar\n- MindMap\n- Obsidian git\n### Gatsby\n기존 블로그는 Nuxt로 개발된 정적 웹페이지였다. Nuxt에서 Gatsby로 넘어간 이유는 2가지다.\n\n첫째는 원래 사용하던 블로그는 Nuxt2로 개발되었는데 내가 군대를 간 사이에 Nuxt3가 나왔다. 처음에는 마이그레이션을 해보려고 해봤는데 생각만큼 그리 단순하지 않았다. 가장 큰 문제는 아래에서도 간단하게 언급하겠지만 Nuxt가 버전업이 되면서 이를 지원하던 노드 모듈들도 이에 맞게 수정이 되어야하는데 vue 생태계가 그렇게 반응이 빠르지 않았다. 그래서 내가 마이그레이션을 해도 기존에 쓰던 기능들을 못 쓰게 되고 내가 노드 모듈을 직접 건드려보기도 했는데 도저히 휴가 때 할 수 있는 양이 아니었다.\n\n두 번째 이유는 단순히 vue 기반의 프레임워크랑 react 기반의 프레임워크를 비교해보고 싶었다. 여러 프레임워크를 쓰면서 나한테 맞고 편한 프레임워크를 찾아보고 싶었고 얼마나 많이 다른지 단순 호기심에서 시작했다. 좀 더 써봐야 알겠지만 프레임워크를 지원하는 생태계는 역시 vue보단 react가 좀 더 좋은 것 같다. 지원하는 노드 모듈들이 많은 것도 틀린 말은 아닌데 그것보다는 프레임워크의 버전업을 노드 모듈들이 빠르게 반응해서 맞춰주는 건 react가 더 편한 것 같다. 사실 차이가 그렇게 크지는 않겠지만 그래도 아직 익숙한 건 아직까지 vue인 것 같다. \n### 동기화: Working Copy\nobsidian에서 obsidian sync라는 기능으로 유료 구독제를 결제하면 여러 기기간의 동기화를 지원해주고 있다. 하지만 나는 Working copy라는 어플로 노트북과 아이패드, 아이폰을 동기화 해주고 있다.  결국은 Github로 동기화를 해주고 있는 건데 조금은 불편할지라도 내가 원할 때 커밋을 올리고 버전관리가 더 쉬울 것 같아서 이렇게 사용하고 있다."},{"excerpt":"지난 회고: retrospect-2022-2 이제 막 옵시디언으로 넘어왔는데 이 글이 옵시디언으로 기록하는 첫 번째 글이 되지 않을까싶다. 원래 2023년은 군대로 모든 시간을 보내서 회고를 안쓰려고 했는데 오늘이 입대한 지 딱 1년이 됐고, 그 1년동안 내가 무슨 생각을 가지고 살았는지, 전역 후에 내가 어떤 목표를 가지고 살아야하는지 한 번쯤은 정리해…","fields":{"slug":"/retrospect-2023/"},"frontmatter":{"date":"2024년 01월 08일 12:01","title":"2023년 회고","tags":["회고"]},"rawMarkdownBody":"지난 회고: [[retrospect-2022-2]]\n\n이제 막 옵시디언으로 넘어왔는데 이 글이 옵시디언으로 기록하는 첫 번째 글이 되지 않을까싶다. 원래 2023년은 군대로 모든 시간을 보내서 회고를 안쓰려고 했는데 오늘이 입대한 지 딱 1년이 됐고, 그 1년동안 내가 무슨 생각을 가지고 살았는지, 전역 후에 내가 어떤 목표를 가지고 살아야하는지 한 번쯤은 정리해보려고 늦었지만 휴가를 나와서 23년 회고를 작성하기로 했다.\n## 2023년 과연 난 뭘 했을까?\n사실 한 게 별로 없다. 머리 밀고 훈련소 들어가서 열심히 훈련받고, 자대 배치받고, 흘러가는 시간에 몸을 맡긴 채 하루하루를 녹이고 있는 날들의 연속이었다. 그래도 그 속에서 1년 반이라는 시간이 내 20대의 공백으로만 남는 건 허락하지 못하기에 이거저거 시도를 해봤다.\n### 독서\n사실 난 책과는 그리 친한 편은 아닌데, 훈련소를 들어가면 쉬는 시간에 너무나도 할 게 없었다. 그래서 진중문고에 올라와있던 책을 한 두권씩 읽었는데 난 책이 그렇게 재밌다는 걸 훈련소에서 알았다. 그렇게 훈련소에서 한 두권 읽다가 자대 배치를 받고 핸드폰이라는 신문물을 발견해서 초반에는 열심히 밀린 핸드폰을 하다가 그거마저 지쳐버려서 다시 또 책을 읽기 시작했다. 당직을 서야할 때나 주말에도 꽤 많이 읽었는데 지금 다시 생각하면 막상 기억에 남는 건 몇 개 없는 것 같다.\n- 우리는 모두 각자의 별에서 빛난다 - 이광형\n- 세컨드브레인 - 티아고포르테\n다음 휴가 때는 이 2권이라도 책 리뷰를 써볼까한다.\n### 운동\n요즘은 운동을 안하면 불안할 정도로 습관이 된 것 같다. 주변 형들이 군대를 다녀오면 남는 건 군적금과 몸밖에 없다고 하길래 시작했는데 여러모로 군생활을 버티게끔 해준 유일한 취미생활이 된 것 같다. 군생활에 현타가 올 때마다 운동하다보니 재미도 붙어서 주 5회 1시간 이상씩 꾸준히 하고 있다. 전역 후에도 유지할 수 있도록 해야겠다.\n### 코딩\n난 내가 군대에서도 코딩을 할 줄 알았다. 어떻게든 꾸역꾸역 할 줄 알았는데 지금 막상 돌아보면 별로 못한 것 같다. pc가 4대 밖에 없는 사지방에서 차가운 손 녹여가며 해봤는데 집중도 안되고 군e러닝도 하다보니까 당장 눈 앞에 놓인 학점 따기 바빴던 것 같다. 남은 기간 동안에는 군e러닝도 안들으니까 적어도 코테준비를 해야겠다.\n### 군e러닝\n군복무를 하면서 군e러닝을 들을 수 있다. 각 학교에서 군 휴학생을 위해 몇몇 강의들을 개설해주는데 나는 23-1에는 **소비의문화와역사**, 23-2에는 그 놈의 **실용한자**를 수강했다. 타 학교에 비해 중앙대가 개설해주는 강의가 별로 없어서 아쉽긴 했지만 실용한자가 군e러닝으로 들을 수 있어서 다행이었다. 아직 실용한자를 수강하지 않은 중대 미필분들은 군대에서 끝내버리세요 :)\n\n생각보다 뺏기는 시간도 많았고 시험에, 과제에 준비해야할 것들은 군 휴학생이라고 배려해주는 건 별로 없지만 그래도 무의미하게 군생활을 보내지 않고 학점이라도 채운 것 같다.\n### 창업아이디어경진대회\n23년 2월, 8월 2번에 걸쳐서 창업아이디어경진대회에 나갔다. 물론 포상휴가에 눈이 멀어 나갔지만 그래도 반복되는 군생활 가운데 새로운 바람을 불어넣어준 활동이었다. 2월에는 본선에서 떨어져서 8월에 좀 더 열심히 준비해서 다시 도전했다. 이 활동이 어떤 지식의 도약을 일으켜 준 건 아니었지만 지금 생각해보면 군복무하면서 이거저거 시도해보면서 바쁘게 생활한 것 같아서 뿌듯하다.\n\n![[presentation.png]]\n## 2024년 목표\n군대에 있으면서 '개발자로서 나' 라는 부분에 대해 생각을 많이 해오고 있다. 혼자 고민할 수 있는 시간이 많다보니 이런저런 생각을 하곤 하는데 요즘 난 나라는 개발자가 뭘 좋아하는지, 무엇을 잘하고 어떤 일을 할 때 행복해하는지 고민을 하고 있는 것 같다.\n\n사실 내가 스스로를 개발자라고 칭할 수 있나? 라는 생각이 들기도 한다. 아직 내 이름을 걸고 보여줄 수 있는 프로젝트도 없고 이룬 게 별로 없는 것 같아서 조바심도 나고 얼른 다시 학교로 가고 싶다는 생각이 든다.\n\n그래서 2024년의 목표는 커리어 성장과 가치 높이기다. 내년이면 올해보다 회고할 게 많은 내가 되면 좋겠다. 그때까지 옵시디언으로 꾸준히 기록을 해나가면서 유의미한 한 해를 보내고 싶다.\n\n이렇게 보니 군생활하면서 후회하지 않을 정도로 열심히 산 것 같다. 내년 이맘때도 1년 동안 정말 열심히 살았구나라는 생각을 할 수 있길 바라며 23년 회고와 24년 목표를 기록해본다.\n"},{"excerpt":"😄 Introduction Hey, I'm Minjun Choi — a problem solver who thrives on cutting through ambiguity to align teams and move fast. I don’t just stay in my lane — I jump in wherever needed to make things w…","fields":{"slug":"/readme/"},"frontmatter":{"date":"2024년 01월 01일 22:01","title":"README","tags":null},"rawMarkdownBody":"\n## 😄 Introduction  \nHey, I'm Minjun Choi — a problem solver who thrives on cutting through ambiguity to align teams and move fast. I don’t just stay in my lane — I jump in wherever needed to make things work. I’m cautious about overengineering, but I obsess over keeping systems clean enough for the team to iterate without losing their minds. Curious about what I’m working on? Check out my [blog](https://minjun.blog/)!\n\n\n## ✏️ Education \n* [Software (Computer Science & Engineering)](https://cse.cau.ac.kr/main.php), Chung-Ang University (2021.03. ~ )\n  \n  \n## 💻 Activity\n* GDGoC CAU 5th Organizer (2025.09. ~ )\n* Woowacourse 7th BE (2025.02. ~ 2025.11.)\n* GDGoC CAU 4th Core Member (2024.09. ~ 2025.08.)\n* CECOM Member (2024.09. ~ )\n* Undergraduate researcher at [HCSLAB of Chung-Ang Univ.](https://sites.google.com/view/hcslab-cau/home?authuser=0) (2024.09. ~ 2025.01.)\n* CAU ZeroPage 32nd vice-President (2022.03. ~ 2023.02.)\n* GDSC CAU 1st Member (2021.06. ~ 2022.07.)\n* CAU ZeroPage 31st Regular Member (2021.03. ~ )\n\n\n## 🚀 Projects\n* [ZZOL](https://github.com/woowacourse-teams/2025-zzol) - A luck-based game that even clumsy players can enjoy! (2025.07. ~ )"},{"excerpt":"기존 블로그에서 이전해온 글입니다. 지난 회고: retrospect-2022-1 들어가기 전에 어느덧 연말이 다가왔다. 상반기 회고를 쓴 게 엊그제 같은데 다시금 회고를 써야한다는 것을 깨닫고 나서야 연말이 다가왔음을 느꼈다.\n2022년 하반기 회고를 작성하기 전에, 지난 9월에 작성했던 상반기 회고를 다시 읽어봤다. 내가 무슨 생각을 해왔었는지, 하반기…","fields":{"slug":"/retrospect-2022-2/"},"frontmatter":{"date":"2022년 12월 23일 12:12","title":"2022년 하반기 회고","tags":["회고"]},"rawMarkdownBody":"\n*[기존 블로그](https://choiminjun.netlify.app/blog/retrospect-2022-2)에서 이전해온 글입니다.*\n\n지난 회고: [[retrospect-2022-1]]\n\n## 들어가기 전에\n어느덧 연말이 다가왔다. 상반기 회고를 쓴 게 엊그제 같은데 다시금 회고를 써야한다는 것을 깨닫고 나서야 연말이 다가왔음을 느꼈다.\n2022년 하반기 회고를 작성하기 전에, 지난 9월에 작성했던 [상반기 회고](https://minjun.blog/retrospect-2022-1)를 다시 읽어봤다. 내가 무슨 생각을 해왔었는지, 하반기에 새운 목표들은 잘 이루었는지 확인해봤다. 다 읽고 가장 먼저 생각이 든 건, **내 사고의 기록은 더 구체적으로, 목표는 더더욱 구체적으로 적어야겠다는 것이**었다. 나름 한 학기 동안 내가 느꼈던 것들을 자세히 적었다고 생각했는데 지금 다시 보니 그 순간의 기억을 다시 불러내기엔 조금 부족한 것 같다. 이번 회고는 보다 더 다양한 내 기억들을 저장하고자 한다.\n\n## 학교 수업\n이번 학기엔 전공 수업이 5개였다. 컴퓨터구조, 컴퓨터통신, 객체지향프로그래밍, 오토마타와 형식언어, 데이터베이스설계, 이렇게 총 5개를 들었다. 생각보다 전공 수업을 5개나 듣는 건 쉬운 일이 아니었다. 강의 자체를 오프라인으로 오랜시간동안 듣는 게 너무도 오랜만이었기 때문에 학기 초에는 몸이 적응하기 힘들었었다. 그럼에도 난 시간을 쪼개면 내 개인 개발 공부를 할 수 있는 시간이 있을거라고 생각했는데 학교 수업을 너무 재밌있게 들어서 그런지 그 둘을 병행하기엔 물리적으로 불가능했었다. \n\n![[Computer-Architecture.jpg]]\n\n\n특히 컴퓨터구조와 컴퓨터통신 과목을 배우면서 검은색화면 뒤로, 우리 눈에 보이지 않는 방식으로 일어나고 있는 일들을 얕게나마 알아가는 과정이 흥미로웠다. 컴퓨터구조를 공부하면서 수업 자료 이외에도 원서도 많이 읽었는데, 학교 강의에서는 다뤄주지 않는 내용들도 궁금해하고 찾아보면서 잠시나마 대학원에 가면 어떨까.. 하는 생각을 했다. 나도 저런 책을 쓸 만큼의 연구를 해보고 싶기도 했고, 책을 읽으면서 나라면 이런 문제를 다르게 접근하지 않았을까.. 혹은 더 효율적인 뱡향으로 풀 수 있지 않을까.. 하는 건방진 생각을 하기도 했다.\n\n## ZeroPage\n\n![[zp-angelscamp-site.jpg]]\n![[zp-지금그때-site.jpg]]\n\n\nZeroPage의 모든 굵지막한 행사들이 끝이 났다. 엔젤스캠프, 지금그때를 진행했고, 1월 초에 다같이 기년회를 할 예정이다. 그때가서도 말할 예정이지만, 나에게 ZeroPage는 가장 자극을 많이 받을 수 있는 곳이었다. 각자 자리에서 열심히 사는 그들을 보며 순수한 열정을 불태울 수 있는, 내가 학교 생활에서 가장 아끼던 부분이었다. \n\n기년회를 끝으로 공식적인 회장단 활동이 끝이 난다. 한 동아리의 회장단은 참 해야할 일이 많다는 걸 깨달은 한 해였지만, 그럼에도 너무 재미있었던 1년이었다. 사람 만나는 재미를 알게 되고 내 생각을 누군가와 공유한다는 느낌을 받을 수 있던 자리였다. \n\n1년 사이에 동아리에 대한 애정이 많이 커졌다. 내가 보고 듣고 느끼고 배운 게 많았던 곳이어서 그런지, 회장단이 끝난다는 게 왠지 모르게 시원섭섭한 느낌이다. 동아리 사람들에게 올해의 ZeroPage가 어떻게 기억될지는 모르겠지만, 다들 이 동아리로 하여금 나처럼 배우고 느낀 점이 많으면 그걸로 만족할 수 있을 것 같다.\n\n32대 회장단을 같이 이끌어온 친구들에게도 너무 수고했다고 고맙다고 전해주고 싶다.\n\n## 2023년\n적은 건 몇 개 없지만 모니터 앞에서는 몇 시간을 넘게 그동안의 시간들을 쭉 되새겨보았다. 올해는 공부도 열심히 하고 노는 것도 열심히 해서 그런지 시간이 너무 빠르다고 느껴질만큼 바쁘게, 재밌게 보낸 것 같다. 내년엔, 잠시 하던 걸 멈춰두고 2023년 1월 9일에 입대를 하기로 했다. 사실 공부도 더 하고 싶고, 학교 생활도 더 하고 싶고, 더 자극받고 성장하고 싶은데 갑작스럽게 가는 것 같아서 많이 아쉬운 건 사실이다. 하지만 더 늦어질 수도 없고 오히려 하고 싶은 게 너무나도 많아서 하루 빨리 가기로 결정을 하기도 했다. 전역 후에 하고 싶은 게 너무도 많기에, 좀 더 빨리 입대하고 좀 더 빨리 전역할 생각이다. \n\n군대에서의 계획은 아직 잘 모르겠다. 원래는 토플도 공부하고 알고리즘도 공부하겠다는 목표를 적으려고 했지만, 가봐야 생각이 정리될 수 있을 것 같다. 20살이 돼도 학교 수업과 별개로 열심히 자기 계발하고 공부했었다. 한 번쯤 쉬는 것도 나쁘지 않을 것 같다는 생각이 이 글을 쓰면서 문득 떠올랐다. 대신, 나한테 2023년은 어느때보다 느리게 가겠지만 그래도 인생에 있어서 의미없는 1년으로 만들지 말자는 게 내 작은 목표이다.\n\n## 2022년의 나\n나는 학교 수업 이외에도 이런 저런 활동 하는 것을 좋아하고, 사람들을 만나서 배우고 같이 공부하는 과정을 좋아하며 그로 인해 얻게 되는 시너지와 에너지를 좋아하는 사람이다. 하지만 올해에는 부족한 점도 있었다. \n\n어느 순간 팀플 과제를 하는 내 모습이 내가 원하던 모습이 아니었다는 것을 깨달았다. 성적에 대한 욕심 때문에 기분이 내 태도가 되어버린 순간들이 몇몇 있었다. 팀 프로젝트를 하면서 가장 아쉬운 순간은, 팀원들이 나만큼 이 과제에 진심이 아니었다는 걸 깨달은 순간이다. 데일 카네기는 인간관계의 기본원칙을 설명하면서 마지막으로 \"상대방에게 열렬한 욕망을 불러일으켜라.\"라고 한다. 수도 없이 읽은 구절인데 팀원들에게 미안하기도 하고 아직은 부족한 나에게 실망한 순간이었다. \n\n반대로 올해의 내가 잘한 점은, 나에게 집중할 수 있는 시간이 많았다는 것이다. 해외프로그램을 다녀온 이후로 나한테 보다 더 집중할 수 있었다. 관심과 욕심은 내가 성장할 수 있게하는 내 동력원인데 항상 그 관심의 영역에는 내가 없음을 깨달을 수 있었다. 내가 잘하고 못하는 게 무엇인지, 내 관심사와 시선은 어디로 향하는지 알 수 있었고 이외에도 감정적으로, 또 그 밖으로도 느낀 게 너무 많은 올해였다. \n\n## 마무리하며\n회고를 하면서 올해는 돌아봤는데 알차게, 또 후회없이 보낸 것 같아서 다행이었다. 나를 성장시킬 수 있었던 한 해였고, 동기부여가 많이 됐던 한 해였다. 다음 회고는 아마 24년 하반기 회고가 될 것 같은데 얼른 그 회고를 쓰는 날이 다가왔으면 좋겠다"},{"excerpt":"기존 블로그에서 이전해온 글입니다. What is 지금그때? ZeroPage.svg 현재 내가 32대 회장단으로 있는 중앙대학교 소프트웨어학부 학술동아리 ZeroPage에는 매년 주기적으로 열리는 행사가 크게 4개가 있다. 오늘은 마지막 행사인 '지금그때'를 진행했다. 이 행사는 졸업하신 선배분들과 재학생이 만나 선배분들의 그때와 우리들의 지금을 서로 공…","fields":{"slug":"/ZeroPage_지금그때_2022/"},"frontmatter":{"date":"2022년 11월 26일 20:11","title":"2022 ZeroPage 지금그때","tags":["ZeroPage"]},"rawMarkdownBody":"\n*[기존 블로그](https://choiminjun.netlify.app/blog/after-jigeumgeuddae)에서 이전해온 글입니다.*\n\n## What is 지금그때?\n![[ZeroPage.svg]]\n\n현재 내가 32대 회장단으로 있는 중앙대학교 소프트웨어학부 학술동아리 ZeroPage에는 매년 주기적으로 열리는 행사가 크게 4개가 있다. 오늘은 마지막 행사인 ['지금그때'](https://zp-portal.org/jigeumgeuddae/)를 진행했다. \n\n이 행사는 졸업하신 선배분들과 재학생이 만나 선배분들의 그때와 우리들의 지금을 서로 공유하고 엿볼 수 있는 자리다. 후배분들은 학업이나 학교생활에 대한 본인의 고민을 털어 놓을 수 있고 이에 대한 조언이나 선배분들의 경험을 들을 수 있다. 반대로 선배분들은 그런 질문들에 기꺼이 조언을 아끼지 않아주시고 요즘은 어떤 공부를 하는지, 학교 생활은 무엇이 달라졌는지 서로 이야기를 나눌 수 있는 자리이다.\n\n작년에도 내가 1학년일 때 이 행사를 참여했었는데 선배분들과 이야기를 하면서 학교 수업에서는 얻을 수 없던 이야기들을 나눌 수 있었고, 취업이나 대학원 뿐이 아니라 개발자라는 종류의 사람이 무엇인지, 앞으로의 공부 방향성을 어떻게 확립해나가야 하는지를 알 수 있었다.\n\n올해는 이 동아리의 회장단으로서 행사를 준비하고 운영하고 참여했다.\n\n### 진행 방법\n우선 간단히 아이스 브레이킹을 하고 본격적으로 시작이 됐다. 대략 한 시간씩 3타임이 운영이 됐고 각 타임에는 본인이 관심이 있는 주제가 있는 자리에 가서 편하게 대화를 하면 된다.\n\n자세한 타임테이블은 아래와 같다.\n| Time          | Activity       |\n| ------------- | -------------- |\n| 13:30 - 14:00 | 참가자 등록     |\n| 14:00 - 14:30 | 개회사          |\n| 14:30 - 15:00 | 아이스브레이킹  |\n| 15:00 - 16:00 | 월드카페 1부    |\n| 16:00 - 17:00 | 월드카페 2부    |\n| 14:30 - 15:00 | 월드카페 3부    |\n| 18:00         | 후기 및 폐막    |\n| 18:30         | 회식            |\n\n\n주제는 신청하신 분들이 원하는 것을 바탕으로 총 12개를 만들었다.\n- 무슨 공부를 해야하는가, 학부생때 해야할 것들에 대한 추천\n- 학교 수업을 따라가는 것이 중요한가\n- 졸업생으로서 가장 유용하게 생각하는 과목\n- 취업을 위해 준비해야할 것들\n- 대학원에 대한 조언\n- 관심 분야를 어떻게 정했는지\n- 지금 하는 일이 즐거운 이유\n- 컴퓨터 전공자는 어떤 유형으로 사회에 진출하는가\n- ZeroPage가 나에게 미친 영향\n- 시간, 멘탈 체력 등의 관리\n- 방학에는 무엇을 하는 게 좋은가\n- 개발자와 커뮤니케이션에 대해\n\n## 어떤 주제에 참여했는가\n꼭 한 타임에 한 주제에 머물러 있을 필요는 없었는데 자리에서 이야기를 하다보니 물어볼 것도 많았고 들을 내용도 많아서 총 3개의 주제에 참여를 했다.\n\n### 학교 수업을 따라가는 것이 중요한가\n첫 번째 타임에 참여한 주제다. 사실 이 주제는 내가 1학년 때부터 재학생 선배분들께 많이 물어보며 다녔고 이에 대한 답도 알지만, 오늘 처음 본 선배분들, 특히 현업에 종사하신 분들의 생각은 어떤지 궁금해서 자리를 찾아갔다.\n\n당연히, 다들 중요하다고 대답해주셨다. 근데 그거에 덧붙여서 이야기 해주신게 기억이 남았다. 내 기억에 남는대로 재해석을 하자면, 학교에서 배운 내용은 일종의 지도 같은 역할을 한다고 하셨다. 당장은 현업에서 쓰이지 않고 내가 필요로 하지는 않을 수도 있지만, 언젠가 내가 그 지식이 필요할 때 그 길을 찾는데 유리하다고 한다. 또한 본인이 취직을 하든, 연구를 하든 무엇을 할 지 아무도 알 수 없기에 기회비용일 수도 있지만 잘 만들어진 학교 커리큘럼을 따라가는 게 맞다고 하셨다.\n\n하지만 오히려 반대로 학점은 그리 중요하지 않았다. 대학원을 준비하지 않는 이상, 취업을 할 때는 학점보다는 그 과목을 본인이 자신의 말로 설명할 수 있는지, 얼만큼 자기의 지식으로 만들었는지를 판별하기 때문에 학점에 그리 목 메이지 않아도 된다고 한다.\n\n그래서 나는 요즘 기업에서 신입을 뽑을 때 학점보다는 프로젝트를 더 중요하게 생각하냐고 여쭤봤고, 거기 계신 세 분의 선배들 모두 얼추 맞다고 대답하셨다. 대신 우리들이 프로젝트를 통해서 어떤 특정한 모습을 뽑내려고 안해도 된다고 하셨다. 지원자들을 보면, 프로젝트를 통해 본인의 특장점을 억지로 어필하려는 모습이 보인다고 하는데 이러한 점보다는 오히려 **본인이 문제를 정의하고, 몰두하고, 해결해나가는 과정 속에서 생기는 고민이나 선택들에 대한 이유를 본인만의 생각으로 논리적이게 풀이할 수 있고 그 과정을 제시할 수 있으면 된다고 했다.** 단순히 예를 들자면, 왜 React를 안쓰고 Nuxt로 개발을 하는지에 대한 본인만의 생각이 있고 말을 할 수 있으면 그걸로 충분하다는 얘기다. 실제 현업에서도 예시와 경우가 많기 때문에 이런 상황에는 지원자가 어떤 이유로 왜 이런 선택을 하는지 알아가는 과정인 것이었다. 또 더불어서 **학교에서 배운 내용들을 본인의 프로젝트에 적용하려는 시도를 하면 좋을 것 같다고 하셨다.** 개념적이고 추상적인 CS 지식을 프로젝트에 적용하는 게 쉽지는 않지만 low level를 다루면서 양질의 프로젝트를 만들 수 있거나 문제를 해결할 수 있는 근본적인 해결책을 찾을 수도 있다고 하셨다.\n\n### 관심 분야를 어떻게 정했는지\n두 번째 타임에 참여한 주제다. 입학 전부터, 나는 문제를 찾아 공학적인 기술로 해결해나가는 것을 좋아했다. 그렇다보니 프로젝트성 공부를 지속했었다. 문제를 해결해나가는 과정에서 앱이 필요하면 앱 개발 공부를 했고, 웹이 필요할 것 같으면 그때부터 웹을 공부하기 시작했다. 필요성에 의해 공부를 하다보니 여러 분야를 어느정도 경험은 해봤지만 특정 분야에 대한 깊은 지식이나 내가 그 분야를 제대로 잘 안다고 말을 할 수는 없었던 것 같았다. 그래서 최근에는 내가 좋아하는 분야를 찾아서 깊게 파보고 싶다는 생각이 문득 들었고 선배분들은 어떻게 본인의 분야를 정했는지 궁금했다.\n\n여러 선배들의 조언을 정리하면 아래와 같다.\n\n우선 다양한 경험을 해봐야한다는 것이었다. 동아리 내에서 스터디를 하든, 더 몰입감 있게 공모전을 나가든 어느정도의 강제성을 부여한 채로 여러 분야를 접해야한다는 것이다. 사실 지금 관심 분야를 찾아도 실제 현업에 나가면 자신이 관심있어 하는 분야를 다루는 경우는 일부기 때문에 한 분야를 깊게 파는 것이 물론 개인의 성장에 도움은 되지만, 관심 분야를 못 정했다고 불안해할 필요는 없다고 하셨다. 다만 오래 방황을 할 경우에는 학교 공부를 더 열심히 해야한다고 하셨다. 학교에서 배우는 CS 지식이 현업에서 일하는 지금까지도 도움이 되기 때문에 기본 중에 기본이 되는 내용들은 탄탄히 쌓을 필요가 있다고 했다. \n\n사실 너무 당연한 얘기였다. 오히려 선배분께서 지금처럼 필요에 의해 찾아 공부하고 고민하는 시간이 필요한 게 당연하다고 하셨다. 그 말에 안심이 되기도 했고, 지금처럼 지치지 말고 여러 자극을 받으며 살아야겠다고 생각했다.\n### 방학에는 무엇을 하는 게 좋은가\n세 번째 타임에 참여한 주제다. 사실 세 번째 타임에는 조언을 들으러 간 게 아니라 1학년분들이 계셔서 고민을 들어주려고 갔었다. 그래봤자 1년 차이라 도움이 될 지는 모르겠지만, 그래도 쉬지 않고 바쁘게 1학년을 보냈다고 말할 수 있어서 좋았던 점, 또 아쉬웠던 점을 들려주려고 갔다.\n\n내가 말한 내용만 정리를 하면 아래와 같다.\n\n난 하나의 기술 스택을 공부해보거나, 학교에서 지원해주는 외부 프로그램을 해보라고 추천했었다. 경험에서 오는 차이만큼 확실한 게 없다고 생각을 해와서 방학만큼은 학기 중에 병행하기 어려웠던 개발공부를 하거나, 해외 프로그램에 참여하는 게 도움이 많이 될 것 같았다. 또한 본인이 졸업 전에 하고 싶은 것에 대한 계획을 세울 필요가 있다고 말해줬다. 교환학생만 해도, 적어도 1년 전부터는 어학성적을 준비해야한다. 외부 동아리도 코딩 테스트를 통과하려면 몇 달을 할애해야한다. 나도 이런 점에 있어서는 부족했고 아쉬웠기에 후배분들은 더 낫길 바라는 마음에 말해줬다.\n## 2022 지금그때 회고\n![[2022 지금그때.jpg]]\n\n올해에도 작년과 마찬가지로 여러 생각이 들었고 다양한 감정들을 느낄 수 있었다. 참여자로서, 또 이 행사를 준비했던 회장단으로서도 느낀점이 있었다. \n\n우선 장소가 급히 바뀌어 예상했던 방향대로 안흘러가서 좀 아쉬웠다. 그럼에도 다른 회장단들이 열심히 같이 준비해줘서 다행이었고 무사히 진행됐다는 점에서 뿌듯하기도 했다. 이럴 때마다 회장단하길 잘한 것 같다는 생각이 든다.\n\n1년동안 학교 생활을 하다보면 자연스럽게 진로에 관한 이런저런 고민들이 쌓이게 된다. 오히려 난 방향성 없게 입에 넣어주는 공부만 하면 안된다고 생각하고 본인이 학교를 다니면서 진로나, 학업, 개발 등 본인만의 여러 고민들이 생겨야한다고 생각한다. 나는 그럴 때마다 물어볼 곳이 없었는데 졸업을 하셔도 여전히 관심을 가져주시는 분들 덕분에 동아리 운영도 되고 나와 같은 재학생들의 고민이 조금은 덜어지는 것 같다. 선배분들께 질문을 하고, 이야기를 하다보면 내 로드맵을 잠시 먼 시점에서 관찰하는 느낌이 든다. 미로에서 잠시 나와 탈출구가 어딨는지 확인하는 느낌이었다. 평상시에 갖고 있던 여러 고민들이 하나하나 풀려서 그런가 다시금 방향성이 잡히고 새로운 자극을 찾은 느낌이 들었다.\n\n학부 차원에서 이런 이벤트를 유지를 못시켜서 더욱 동아리 선배분들께 감사하기도했다. 다만 아쉬운 건, 1학년분들도 나와 같은 기분을 느끼셨으면 했다. 듣는 것에만 익숙해진 분들이 꽤 있으셨는데 기회를 놓치지 않고 이런 저런 질문을 더 많이 했으면 어땟을까.. 라는 생각이 들었다.\n\n추가로 선배분들이 어떤 일을 하는지, 어느 분야를 공부하고 계신지 여쭤봤었는데 그럴 때마다 난 **대체 불가능 한 사람, 개발자를 위한 개발자**라는 타이틀을 내밀 수 있는 사림이 되어야겠다고 생각했다. 본인이 지금 무엇을 하고 있는지, 자신 있게 보여주고 설명하는 모습이 내가 바라는 모습이기도 했다. 지금 내가 하고자 하는 분야를 뚜렷히 못정해서 저런 생각이 들은 것 같기도 했다. 앞으로도 많은 자극들을 받으며 아직 접해보지 못한 것들을 경험해보고 싶었고, 지금 도움을 받은 만큼 나의 지금이 그때가 될 때 후배분들의 지금에 도움이 될 수 있는 사람이 되어야겠다는 생각을 했다.\n"},{"excerpt":"기존 블로그에서 이전해온 글입니다. Nuxt.png 삽질 배경 내 개인페이지는 올해 초에 처음 개발되기 시작했었다. 그때도 markdown에 수식을 적용하기 위해 이것저것 시도해보다가 포기했었는데 며칠 전부터 스터디 페이지를 개발하면서 markdown에 수식을 적어야 할 일이 또 생기고 말았다. 문제 상황 본 페이지는 Nuxt content와 tailwi…","fields":{"slug":"/nuxt-katex/"},"frontmatter":{"date":"2022년 09월 13일 22:09","title":"Nuxt content에 Mathtype 사용하기","tags":["Nuxt","Katex"]},"rawMarkdownBody":"\n*[기존 블로그](https://choiminjun.netlify.app/blog/nuxt-katex)에서 이전해온 글입니다.*\n\n\n![[Nuxt.png]]\n## 삽질 배경\n내 개인페이지는 올해 초에 처음 개발되기 시작했었다. 그때도 markdown에 수식을 적용하기 위해 이것저것 시도해보다가 포기했었는데 며칠 전부터 [스터디 페이지](https://choiminjun.netlify.app/study/computer-architecture/0-1)를 개발하면서 markdown에 수식을 적어야 할 일이 또 생기고 말았다.\n\n### 문제 상황\n본 페이지는 Nuxt content와 tailwindcss typography로 개발되었는데 둘 다 markdown에서 수식을 기본적으로 지원해주지 않기 때문에 내가 추가적으로 \n플러그인이나 패키지를 다운받아 적용시켜줘야했다. 구글링을 하다보면 이 [GitHub Issue](https://github.com/nuxt/content/issues/102)가 그나마 제일 믿을 만한 정보가 많았는데 이 페이지뿐만 아니라 거의 모든 사이트들이 `rehype-katex`와 `remark-math` package를 다운받아 적용하라고 한다. 근데 문제는 `nuxt/content`, `rehype-katex`, `remark-math` package들이 새롭게 업데이트 되면서 서로 호환이 되도록 작업을 안해놨기 때문에 전부 다 최신 버전으로 다운 받아 사용할 경우 수식 적용 자체가 되지를 않는다. \n\n## 정답\n### 삽질 방법\n일단 Nuxt content에서 katex를 지원해주는 방법에 대한 거의 모든 글을 읽어봤을만큼 몇 시간동안 구글링을 해보고 모든 버전들끼리 조합을 해본 뒤에 정답을 찾았다. 또한 `nuxt/content`을 바꿔주게 되면 수식이 필요없는 파일들에게도 영향이 갈 수 있어서 `rehype-katex`, `remark-math` package들만 버전 조합을 찾아봤다. npm downgrade를 하면 쉬운데 에러가 많이 나서 매번 **노드 모듈**들을 지워주고 **package.json**을 수정한다음에 새롭게 모듈들을 깔아보면서 로컬에서 실행해보며 확인해주었다.\n\n### 결론\n\n```javascript\n\"dependencies\": {\n    \"@nuxt/content\": \"^1.15.1\",\n    \"rehype-katex\": \"^4.0.0\",\n    \"remark-math\": \"^4.0.0\",\n    \"katex\": \"^0.15.3\",\n  },\n``` \n<center>package.json</center>\n<br>\n\n우선 위에서부터 언급한 3가지 package들은 저 버전들로 설치를 해놔야 호환이 된다. 특히 `rehype-katex`는 5버전, `remark-math`는 4버전을 넘기면 안된다. 추가로 `katex` package도 필요한데, 이 package가 없으면 수식을 인식하긴하는데 우리가 원하는대로 깔끔하게 적용되지 않는다.\n\n\n\n```javascript\ncss: [\n    {\n      src: 'katex/dist/katex.min.css',\n      defer: true\n    },\n    \"@/assets/css/main.css\"\n  ],\ncontent: {\n    markdown: {\n      remarkPlugins: ['remark-math'],\n      rehypePlugins: ['rehype-katex']\n    },\n  },\n```\n<center>nuxt.config.js</center>\n<br>\n\n그리고 나서 **nuxt.config.js** 파일에 가서 위와 같이 적용을 시켜줘야한다.\n\n\n## 마무리\n아무리 구글링을 해도 답이 안나오길래 Github에 Nuxt content로 빌드된 페이지 레포 중에 markdown에서 수식을 지원해줄 수 있게 작업한 것들을 찾아봤다. 유일하게 한 개가 있었는데 그 레포에서는 `katex` package를 추가로 설치해서 적용해주길래 똑같이 적용시켜보았다. \n\n이럴 때 보면 확실히 Nuxt가 React에 비해 커뮤니티 활성도가 조금 낮은 듯하다. 지금은 Nuxt가 너무 익숙해져서 넘어갈 생각은 없지만 프로그래밍을 하는데에 있어 커뮤니티가 기여하는 점이 크다는 것을 알았다. \n\n적게 잡아도 5시간정도는 이 작업만 한 것 같다. 중간에 던질까 생각도 많았는데 모든 경우를 시도해보지 않으면 나중에 후회할 것 같아서 광기어린 눈으로 지구끝까지 삽질을 해보았다. 나처럼 Nuxt content에 mathtype을 적용하고자 하는 사람이 많을 것 같은데 도움이 됐으면 좋겠다.\n"},{"excerpt":"기존 블로그에서 이전해온 글입니다. 들어가기전에 이 글을 작성하는 오늘은 9월 5일, 하반기에 접어들고 벌써 2학년 2학기를 이제 막 시작하는 날이다.\n사실 회고를 작성해야겠다고 생각한 건 꽤 오래되었다. 내가 그동안 어떤 생각을 했고 어떻게 그것들을 달성해나갔는지 되돌아보는 것 자체만으로도 스스로 많은 자극이 되었기에 회고를 작성하는 습관을 들여야겠다고…","fields":{"slug":"/retrospect-2022-1/"},"frontmatter":{"date":"2022년 09월 05일 12:09","title":"2022년 상반기 회고","tags":["회고","ZeroPage","GDG"]},"rawMarkdownBody":"\n*[기존 블로그](https://choiminjun.netlify.app/blog/retrospect-2022-1)에서 이전해온 글입니다.*\n\n## 들어가기전에\n이 글을 작성하는 오늘은 9월 5일, 하반기에 접어들고 벌써 2학년 2학기를 이제 막 시작하는 날이다. \n사실 회고를 작성해야겠다고 생각한 건 꽤 오래되었다. 내가 그동안 어떤 생각을 했고 어떻게 그것들을 달성해나갔는지 되돌아보는 것 자체만으로도 스스로 많은 자극이 되었기에 회고를 작성하는 습관을 들여야겠다고 꾸준히 생각했었는데 내 마음에 들 때까지 내 페이지를 개발하는 게 우선인 것 같아서 조금 늦은 감이 없진 않지만 지금에서야 작성해보고자한다. \n\n## Google Developer Student Club CAU\n\n\n![[GDSC.svg]]\n\n\n\n### 열정적인 사람들을 만나며\n2021년 9월쯤, 우연히 학교 에브리타임에서 GDSC CAU 1기를 모집한다는 글을 보았다. 홍보글을 보았을 때 '이 동아리는 개발을 잘하는 사람만\n들어갈 수 있는 곳인가?' 라는 의문이 제일 먼저 들면서 나도 모르게 움츠러들었었다. 그런 나에게 반항심이라도 들었는지 떨어져도 본전이라는 마음으로, 한 편으로는 이 동아리를 통해 나도 개발을 잘하는 사람이라는 가치에 한 발자국 더 다가가고자 하는 마음으로 지원을 했고 운이 좋았는지는 모르겠지만 합격을 해서 1년을 열심히 활동하고 얼마전 수료식을 했다.\n\n21년도에 중앙대학교 소프트웨어학부에 입학을 하고 입학과 동시에 전부 비대면 수업을 들었던 나는 자연스레 학교 생활과는 멀어졌었고 학교 수업만 따라가고 있었다. 그러다가 처음으로 동아리라는 것을 해보고 환경의 중요성을 더욱 실감했던 것 같다. 온라인이었지만 정모에 나가고 스터디를 하고 프로젝트를 진행하면서 나와 같은 목표를 가진, 또 나와 같은 열정을 가진, 어쩌면 나보다도 더욱 큰 꿈을 가진 사람들을 만나면서 그들로부터 동기와 열정을 느끼고 나 또한 다시 내가 하고 싶었던 것들에 몰두할 수 있었다.\n\n### 나를 성장시키는 힘\n이 동아리를 통해 기술적으로 배운 것들도 많았지만 더욱 중요하게, 나라는 사람을 성장시킬 수 있는 방법을 깨달았다.\n그건 바로 **불편함에 익숙해져야한다는 것**이다. GDSC에서 나는 Flutter를 공부하고 앱 개발을 했는데 매 순간 고민의 연속이었고 기존에 내가 하던 것과는 완전 다른 느낌의 코딩이기에 쉬운 것이 하나 없었다. 이처럼 새로운 언어와 프레임워크를 접하면서 누구나 당연히 불편함을 느낄거라 생각을 한다. 하지만 그 불편함을 느끼는 과정이 학습의 동기가 되고 성장의 과정이라는 것을 배웠다. 2학년인 지금도 새롭게 배우고 접하는 것들이 많지만 앞으로도 다를 것 같지는 않아보였다. 중요한 건 그런 과정 속에서 나를 둘러싼 불편함을 받아드리고 적응하는 것임을 배울 수 있었다.\n\n또 다른 것으로는, **새로움에 주저하지 말자는 것**이다. 아무것도 모르는 1학년 학부생이 무작정 동아리에 들어가고 FE/BE 경험도 없으면서 Flutter를 시작하는 것이 누가 보기엔 살짝 무모하다 할 수 있지만 그럼에도 생각을 실천으로 옮기는 것 또한 나를 성장시키는 방법이라고 생각했다. 처음 동아리에 들어갔을 때 내가 유일한 1학년이었다. '내가 잘 따라갈 수 있을까' 걱정도 했지만 새로움에 도전하는 걸 어느순간 내가 즐기고 있음을 느꼈던 것 같다. 처음에는 쉬운 것조차 어떻게 하는지 몰라서 많이 헤매고 시도때도 없이 선배들한테 질문을 했는데 지금 생각해도 본인 일처럼 친절하게 알려준 선배들께 감사하다.\n\n## ZeroPage | 중앙대학교 소프트웨어학부 학술연구회\n\n![[ZeroPage.svg]]\n### 회장단 상반기 회고\nGDSC에서 가깝게 지낸 사람들이 대부분 중앙대학교 소프트웨어학부 학술연구회인 ZeroPage 소속이었다. 그들과 지내면서 자연스레 나도 ZeroPage에 가입을 했고 작년 하반기에 열심히 활동을 하면서 이 동아리를 이어나가고자 올해 초 회장단에 지원을 했다.\n\n회장단으로 한 학기를 보내고 되돌아봤을 때 잘한 점도 있는 것 같고 아쉬운 점도 몇몇 있는 것 같다. 우선 대면으로 조금씩 허용되면서 그동안의 행사들과 동아리 분위기를 바꾸고자 나름대로 노력을 했다. 최근에는 Devils Camp를 대면으로 진행했는데 마침 내가 그때 코로나에 걸려 못 간 게 아쉬웠다. 또한 동아리를 유지하기 위해서는 회원들을 꾸준히 모집하는 것도 중요한데 그래도 노력한만큼 동아리가 유지되고 있는 것 같아서 다행인 것 같다.\n\n최근에 후배분들 중 한 분이 동아리 회장단을 하는 게 부담스럽지 않냐고 물어봐주셨다. 30년 넘게 유지되고 있는 동아리라 초반에는 부담도 됐지만 지금은 조금이나마 편해진 것 같다. 그럼에도 불구하고 나는 그 후배분께 본인이 애정을 쏟고 싶은 곳이 있다면 회장단만큼 유대감을 크게 느낄 수 있는 방법이 몇 없을 거라고 말을 해줬다. 매주 정모를 하고 함께 스터디를 해나가면서 같이 성장해나가는 기분은 말로 설명할 수 없을 무언가가 있는 것 같다고 말이다. 아직 상반기밖에 안지났지만 여전히 하루하루 느끼는 게 많은 것 같다. 요즘 하는 생각은 '**어렵지 않은 사람이 되자**'이다. 여러 사람을 만나며 소통을 해나가는 과정 속에서 처음의 진입장벽을 허무는 게 중요한 것 같다. 그래서 앞으로는 스터디도 더 자주 개최하고 보다 활동적인 동아리를 만들려고 계획 중이다. \n\n\n## 해외인턴프로그램\n얼마 전, 여름방학에 미국 LA로 한 달간 인턴프로그램을 다녀왔다. 본 프로그램을 통해 창업이라는 개념에 벽이 조금은 허물어진 것 같고, 진지하게 교환학생에 대해서 생각을 해보았다. 다른 문화 속에서 내가 좋아하는 분야를 공부해보고 싶다. 대학원을 해외로 가는 방법도 있지만, 그건 차후에 내가 공부하고 싶은 분야를 뚜렷이 찾으면 고민해볼 것 같다. \n\n## 운동\n내 책상 바로 옆에 풀업을 할 수 있는 치닝디핑(턱걸이 기구)과 덤벨이 있다. 작년 초부터 지금까지 못해도 일주일에 3번이상 꾸준히 운동을 해오고 있는데 점점 개수가 느는 게 보인다. 책상에 앉아있는 시간이 많아질 수록 체력 또한 중요하다고 생각해서 눈에 보이면 일단 하나 당기고 본다. 앞으로는 더 바빠질 것을 대비해서 오전 시간을 최대한 활용해보고자 한다. \n\n## 앞으로의 목표\n지난 한 학기, 크게는 1년을 돌아보며 나는 다양한 사람들과 만나면서 다양한 방면으로 성장하고 있음을 느꼈다. 이렇게 회고를 하다보니 뿌듯하기도 하고 새롭게 자극받는 기분이 든다. 2학년 2학기를 시작하고 있는 지금, 전공을 5개나 듣고 있지만 또 새로운 것에 도전하고 새로운 환경에서 또 다른 사람들을 만나보고 싶다는 생각이 드는 요즘이다. 아직 정확히 무엇을 더 할지는 모르겠지만 올해 하반기에는 좀 더 많은 자극을 받으며 열심히 살고 싶다. "}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}