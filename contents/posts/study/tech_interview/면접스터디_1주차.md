---
title: DB 부하의 원인을해결해보자!
date: 2025-02-11 09:44:21
updated: 2025-09-14 21:08:09
publish:
tags:
series:
---
![[스크린샷 2025-09-14 오후 3.38.40.png]]

![[스크린샷 2025-09-14 오후 3.38.51.png]]

## 문제 원인 분석
- 매 시간 10분 단위로 발생, 특정 Key만 문제 발생
	- 캐시의 TTL 이 1시간이고, 특정 인기 데이터들이 같은 시점에 캐시 설정됨
	- 9시 10분에 캐싱됨, 10시 10분에 캐시 만료되고 다시 캐싱, 11시 10분에 캐시 만료되고 다시 캐싱, ...
- 30초 후 자동 복구
	- 새롭게 캐싱이 되면서 정상화
이런 문제를 Cache Stampede 라고 부름

## 해결 전략
### TTL Jitter: 랜덤하게 만료하도록 설정
- 모든 핫 데이터가 매 시간 10분에 동일하게 만료되는 걸 랜덤하게 조정해서 만료 시점을 분산시킴
- 이때 실시간성이 중요한 데이터일수록 Jitter를 작게
- 하지만 각 시점별 트래픽이 여전히 기준치보다 크면 문제는 여전히 발생

### Single Flight Pattern: N개 동시 요청 중 1개만 DB 호출, 나머지는 대기
- 첫 번째 요청 실패 시 연쇄적으로 나머지 전부 실패
- 응답 시간 증가
	- 요청 1: DB 호출 (5초 소요)
	- 요청 2~1000 : 5초 대기
- DB 요청이 자주 생긴다?
	- Circuit Breaker 도입
	- 요청 실패가 5번 누적이 되면, 그 이후 요청들은 빠르게 실패처리 후 응답보냄
	- 그동안 DB 복구하고 1분뒤 자동으로 재시도하게끔
하지만 여전히 캐시 만료는 발생하고, Single Flight Pattern을 도입하더라도 첫 번째 요청을 제외한 나머지 요청은 대기해야함. Circuit Breaker 작동하더라도 서비스 품질 이상함.
### Proactive Refresh: TTL 20% 남았을 때 백그라운드 캐싱
- 캐시 만료 자체를 없앰, 사용자 요청 시에는 항상 캐시 있음
- 간헐적 지연 상황 안생김, 일정한 성능 보장

## 그럼 Proactive Refresh 만 하면 되지, 나머지 전략은 왜 필요해?
### 1. 갑작스런 새 인기 데이터 등장
```
# 평소에는 조용했던 데이터가 갑자기 핫해짐
16:00 - 어떤 상품이 SNS에서 갑자기 바이럴
16:01 - 해당 상품 메타데이터에 요청 폭주 (10000 TPS)
16:02 - 캐시에 없음 → Proactive Refresh 대상도 아님
16:03 - 썬더링 허드 발생! 💥
```
### 2. Proactive Refresh 자체 실패
```
# 백그라운드 갱신 중 실패 상황
15:50 - 백그라운드에서 캐시 갱신 시도
15:51 - DB 일시적 장애로 갱신 실패
15:52 - 재시도해도 계속 실패
16:00 - 결국 캐시 만료됨
16:01 - 사용자 요청 들어옴 → 캐시 없음 → 썬더링 허드 💥
```
### 3. 콜드 스타트
```
# 서버 재시작 시
09:00 - 서버 재부팅 (배포 등)
09:01 - 캐시 모두 비워짐
09:02 - 출근 시간 트래픽 몰림
09:03 - 모든 데이터가 캐시 미스 → 대규모 썬더링 허드 💥
```
### 4. 트래픽 패턴 예측 실패
```
# 예상치 못한 이벤트
평소: "이 데이터는 하루에 100번 정도 조회되네"
갑자기: 마케팅팀이 광고 때림 → 1분에 10000번 조회
결과: Proactive Refresh 주기 (5분마다)로는 따라갈 수 없음
```
## 실제 장애 시나리오

### Case 1: 마케팅 이벤트
```
14:00 - 마케팅팀이 갑자기 이벤트 오픈
14:01 - 특정 상품에 요청 폭주 (평소의 1000배)
14:02 - Proactive Refresh로는 감당 안 됨
14:03 - Single Flight 없었다면? → DB 뻗음 💥
14:03 - Single Flight 있어서 → 1개 요청만 DB, 나머지 대기 ✅
```
### Case 2: DB 장애
```
15:00 - Primary DB 장애 발생
15:10 - Proactive Refresh 계속 실패
15:20 - 캐시들 하나둘 만료 시작
15:30 - Circuit Breaker 없다면? → 모든 요청 타임아웃 💥
15:30 - Circuit Breaker 있어서 → 즉시 실패, Stale Cache 반환 ✅
```
### Case 3: 코드 배포
```
16:00 - 새 버전 배포로 서버 재시작
16:01 - 모든 캐시 날라감 (Redis 외부 캐시 제외)
16:02 - 저녁 시간 트래픽 시작
16:03 - 모든 조합 필요함:
        - Jitter: 캐시 재생성 시점 분산
        - Single Flight: 중복 호출 방지  
        - Circuit Breaker: DB 보호
        - Proactive: 이후 안정화
```
## 보험의 개념
```
# 자동차 보험 비유
proactive_refresh = "안전 운전"     # 99% 사고 방지
circuit_breaker = "에어백"         # 사고 시 피해 최소화  
single_flight = "브레이크"         # 위험 상황 대응
ttl_jitter = "안전거리"           # 연쇄 추돌 방지
```
### 99% vs 99.99%의 차이
- **Proactive Refresh만**: 99% 안정성
- **4개 조합**: 99.99% 안정성
**0.99%의 차이**가 별거 아닌 것 같지만:
- 하루 100만 요청 → 1000번 장애
- 한 달 → 30,000번 장애
- **매월 8시간씩 서비스 불안정**
대규모 서비스에서는 **이 차이가 엄청남**.
## + 캐시무효화

**데이터 일관성** 문제 때문에 필요함
```
# 문제 상황
10:00 - 상품 가격: 10,000원 (DB + 캐시 둘 다)
10:30 - 관리자가 가격 변경: 15,000원 (DB만 업데이트)
10:31 - 사용자가 조회 → 캐시에서 10,000원 반환 😡

# 사용자: "어? 결제할 때는 15,000원이네? 사기당한 기분"
```
**캐시와 DB 데이터가 달라지는 문제**를 해결하는 게 캐시 무효화임.
### 주요 캐시 무효화 전략들

#### 1. TTL (Time To Live) 기반
**가장 단순한 방법**: 시간 지나면 자동 삭제
- **자주 변하지 않는 데이터** (사용자 프로필, 상품 기본 정보)
- **약간의 지연 허용 가능**한 경우
#### 2. Manual Invalidation (수동 무효화)
**데이터 변경 시 직접 캐시 삭제**
- 데이터 일관성 보장 
- 연관 캐시 다 찾아서 지워야 함 → 실수하기 쉬움
#### 3. Write-Through 패턴
**DB 쓸 때 캐시도 같이 업데이트**
- 캐시 항상 최신 
- 쓰기 성능 느려짐 (DB + 캐시 둘 다 써야함)
#### 4. Write-Behind (Write-Back) 패턴
**캐시만 먼저 업데이트, DB는 나중에**
- 쓰기 성능 좋음 
- 캐시 장애 시 데이터 손실** 위험
#### 5. Event-Driven Invalidation
**DB 변경 이벤트 감지해서 캐시 무효화**
- 자동화, 놓치는 캐시 없음 
- 구현 복잡, 이벤트 시스템 필요
#### 6. Tag-Based Invalidation
**캐시에 태그 붙여서 관련된 것들 한 번에 삭제**
- 관련 캐시 찾기 쉬움 
- 태그 관리 복잡, Redis에서 기본 지원 안 함
#### 7. Refresh-Ahead (사전 갱신)
**만료되기 전에 미리 새 데이터로 교체**
- 사용자는 항상 빠른 응답 
- 백그라운드 작업 필요

## 참고자료
https://toss.tech/article/cache-traffic-tip
https://channel.io/ko/team/blog/articles/tech-cache-rdb-4cc0bbf4