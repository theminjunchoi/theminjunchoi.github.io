---
title:
date: 2025-02-11 09:44:21
updated: 2025-10-12 16:16:30
publish:
tags:
series:
---

![[스크린샷 2025-10-12 오후 2.54.20.png]]![[스크린샷 2025-10-12 오후 2.54.30.png]]
### 전체 아키텍처 한 줄 요약

```
RDB → CDC → Kafka → Flink(1분 윈도우 집계) → Redis(캐시) → 리스크 판단 → 알림
```

---

### 1. 데이터 수집

- **CDC(Debezium)로 RDB Binlog 읽어서 Kafka로 전송**
- 왜? RDB 직접 폴링(SELECT)하면 TPS 5000에 DB 터짐

### 2. 실시간 처리

- **Kafka 파티션 50개** (거래점 ID 기준 파티셔닝)
- **Flink로 1분 윈도우 집계**
    - 거래점별 취소율, 거래액 계산
    - State Backend(RocksDB)로 중간 상태 관리

### 3. 데이터 저장

**Redis (Hot Cache):**

- 최근 1시간: 1분 단위 집계
- 최근 7일: 일 단위 평균 취소율 (배치로 미리 계산)
- 전일 10억 이상 거래점 목록

**TimescaleDB (분석용):**

- 히스토리 데이터 적재

### 4. 리스크 판단

**조건1: 취소율 2배 증가**

- 최근 1시간 취소율 vs 7일 평균 비교
- 7일 평균은 배치로 미리 계산해서 Redis 캐싱

**조건2: 거래액 50% 급감**

- 전일 10억 이상 거래점만 체크
- 당일 누적 vs 전일 비교 (같은 시간대 기준)

### 5. 스케일링

- **롱테일 대응**: 상위 1% 거래점은 Salting으로 Key 분산
- **병렬 처리**: Flink Parallelism 50, Task Manager 10대,,.... 몰라
- **Redis Cluster**: 샤딩으로 부하 분산

---

## Q&A

**Q: 왜 CDC 써야 함?** 
A: RDB 폴링하면 SELECT 쿼리로 DB 부하 터짐. CDC는 Binlog만 읽어서 부하 없음.

**Q: 왜 Kafka?** 
A:
1. 버퍼 역할 (Flink 죽어도 데이터 유실 X)
2. 파티셔닝으로 병렬 처리 (TPS 5000 감당)
3. 순서 보장 (같은 거래점 순차 처리)

**Q: 1분마다 10만 거래점 체크하면 Redis 부하는?** 
A: 7일 평균은 배치로 미리 계산. 실시간엔 단순 조회만. Redis sub-ms라 10만 건도 OK.

**Q: Hot Key 문제는?** 
A: 상위 1% 거래점은 merchant_id에 랜덤 suffix 붙여서 파티션 분산. 읽을 땐 여러 Key 합산.
아니면 동적 파티션?

**Q: 장애 시 데이터 유실은?** 
A: Flink Checkpointing 3분마다 + Kafka 3일 보관. 최악 3분치만 재처리.

---
## 뭘 원하냐

### 1. 대용량 트래픽 처리 경험 (최우선)

**보려는 것:**

- TPS 5000 같은 숫자 보고 **"어 이거 병렬 처리 해야겠네"** 바로 떠올리는지
- 단일 서버로 안 된다는 걸 아는지

**체크 포인트:**

- 파티셔닝, 샤딩 개념
- 병렬 처리 (Kafka 파티션, Flink Parallelism)
- Hot Key 문제 인지 여부

**못 하면:**

- "음... DB에서 1분마다 SELECT 하면 되지 않을까요?" ← 떨어짐 ㅋㅋ

---

### 2. 실시간 vs 배치 구분 (중요)

**보려는 것:**

- "1분 단위"라는 말 보고 **실시간 스트리밍 처리**임을 인지하는지
- 배치로 해결 못 한다는 걸 아는지

**체크 포인트:**

- 실시간: Kafka, Flink/Spark Streaming
- 배치: Airflow, Spark Batch
- **근데 7일 평균은 배치로 미리 계산**하는 하이브리드 사고

**못 하면:**

- "배치 스케줄러로 1분마다 돌리면 되지 않나요?" ← 이것도 아웃 ㅋ

---

### 3. 데이터 저장소 선택 (핵심)

**보려는 것:**

- RDB, Redis, TimeSeries DB 각각 **언제 쓰는지** 아는지
- "왜 그 DB를 선택했어?" 물어봤을 때 대답 가능한지

**체크 포인트:**

|저장소|용도|이유|
|---|---|---|
|Redis|Hot Cache (최근 1시간)|빠름, TTL 지원|
|TimescaleDB|히스토리 분석|Time-series 특화|
|RDB (원본)|거래 데이터|ACID, 신뢰성|

**못 하면:**

- "다 MySQL에 넣으면 안 돼요?" ← MySQL로 1분마다 10만 거래점 조회? ㅂㅂ

---

### 4. 시스템 설계 trade-off 이해

**보려는 것:**

- "완벽한 설계"는 없음. **트레이드오프**를 이해하는지
- 장단점 말하면서 **왜 이 선택을 했는지** 설명 가능한지

**예시:**

**Q: CDC vs API 이벤트 발행 방식?**

- CDC: DB 로직 안 건드림, 운영 포인트 증가
- API: 깔끔한데 거래 서버 수정 필요

**Q: Kafka vs RabbitMQ?**

- Kafka: 처리량 높음, 운영 복잡
- RabbitMQ: 간단한데 느림

---

### 5. 장애 대응 

**보려는 것:**

- "Flink 죽으면?" 같은 질문에 답하는지
- **SPOF(Single Point of Failure)** 없는 설계인지

**체크 포인트:**

- Kafka Replication
- Flink Checkpointing
- Redis Cluster (Master-Replica)
- 데이터 재처리 방안 (Kafka 메시지 보관)


---

### 6. 성능 병목 지점 파악 

**보려는 것:**

- "어디가 병목일까?" 스스로 찾아내는지
- **롱테일 분포** 같은 힌트 보고 Hot Key 문제 떠올리는지

**체크 포인트:**

- 상위 1% 거래점에 트래픽 집중 → Salting 필요
- Redis 메모리 계산 (10만 거래점 × 7일 = ?)
- Kafka Lag 모니터링


---

### 7. 도구/기술 이해도 (기본)

**필수로 알아야 하는 것:**

- Kafka 기본 개념 (Topic, Partition, Consumer Group)
- Redis 자료구조 (String, Set, Sorted Set)
- Flink/Spark Streaming 차이
- CDC가 뭔지

**있으면 좋은 것:**

- Debezium 설정 경험
- Flink Windowing (Tumbling, Sliding)
- TimescaleDB, ClickHouse 같은 Time-series DB
